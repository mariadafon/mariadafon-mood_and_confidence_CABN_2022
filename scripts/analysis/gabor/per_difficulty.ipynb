{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis per difficulty\n",
    "\n",
    "## Across subjects & sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/gabor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, main_path+'/scr')\n",
    "import my_functions as myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2\n",
    "\n",
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]\n",
    "unique_signals = [1,2,3]\n",
    "excluded_miss = ['1011_11', '1011_18', '1014_12']\n",
    "excluded_time = ['1008_2','1009_9']\n",
    "\n",
    "excluded = excluded_miss+excluded_time\n",
    "\n",
    "adf = pd.read_csv(path_results+'preanalyzed.csv')  \n",
    "userids = adf['userID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas=adf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = {}\n",
    "ind = 0\n",
    "for part in userids:\n",
    "    ind += 1\n",
    "    RT, DO, SO = [],[],[]\n",
    "    for Day in fday:\n",
    "        for Ses in fsession:\n",
    "            sessionid = 2*Day-2+Ses\n",
    "            if str(part)+'_'+str(sessionid) not in excluded:\n",
    "                filename = path_results+'day'+str(Day)+'/session'+str(Ses)+'/diff_Sub'+str(part)+'_Day'+str(Day)+'_Sess'+str(Ses)+'.json'   \n",
    "                with open(filename) as f:\n",
    "                    data = json.load(f)\n",
    "                RT.append(data['RT_no'])\n",
    "                DO.append(data['Doptout'])\n",
    "                SO.append(data['Soptout'])\n",
    "    mas.update({part: {'RTas': np.nanmean(RT,axis=0),'DOas': np.nanmean(DO,axis=0),'SOas': np.nanmean(SO,axis=0)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['RT_no','Doptout','Dperf_oo','Sperf_oo','perf_no','DRT_oo','SRT_oo','DRT_OKoo','SRT_OKoo','RT_noNOK',\\\n",
    "             'Soptout']\n",
    "\n",
    "df = pd.DataFrame(columns=col_names+['RTeff','DOeff','SOeff','difficulty','sessionID_x','userID'])\n",
    "\n",
    "dfANOVA = pd.DataFrame(columns=['perf','type','difficulty','sessionID_x','userID'])\n",
    "\n",
    "df_LR = pd.DataFrame(columns=['slope_RT','slope_DO','slope_SO','intercept_RT','intercept_DO','intercept_SO',\\\n",
    "                              'sessionID_x','userID','user_sessionID_x'])\n",
    "ind = 0\n",
    "for part in userids:\n",
    "    ind += 1\n",
    "    dict_,dANOVA = {},{}\n",
    "    for Day in fday:\n",
    "        for Ses in fsession:\n",
    "            sessionid = 2*Day-2+Ses\n",
    "            user_sessionID = str(part)+'_'+str(sessionid)\n",
    "            if user_sessionID not in excluded:\n",
    "                filename = path_results+'day'+str(Day)+'/session'+str(Ses)+'/diff_Sub'+str(part)+'_Day'+str(Day)+'_Sess'+str(Ses)+'.json'   \n",
    "                with open(filename) as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                diff_vals = np.array([1, 2, 3])\n",
    "                diff_list = [1, 2, 3]\n",
    "                num_diff = len(diff_list)\n",
    "\n",
    "                for key in col_names:\n",
    "                    dict_[key] = data[key]\n",
    "                dict_.update({'RTeff':np.array(data['RT_no'])-mas[part]['RTas'],\\\n",
    "                                       'DOeff':np.array(data['Doptout'])-mas[part]['DOas'],\\\n",
    "                                       'SOeff':np.array(data['Soptout'])-mas[part]['SOas'],\\\n",
    "                                       'difficulty':diff_list,'sessionID_x':[sessionid]*num_diff,\\\n",
    "                                       'userID':[part]*num_diff})\n",
    "                dANOVA = {'perf':data['perf_no']+data['Dperf_oo']+data['Sperf_oo'],\\\n",
    "                          'type':['NO']*num_diff+['DO']*num_diff+['SO']*num_diff,\\\n",
    "                          'difficulty':diff_list*3,'sessionID_x':[sessionid]*num_diff*3,'userID':[part]*num_diff*3}\n",
    "\n",
    "                df_new = pd.DataFrame(dict_)\n",
    "                dfANOVA_new = pd.DataFrame(dANOVA)\n",
    "\n",
    "                RT = np.array(data['RT_no'])\n",
    "                DO = np.array(data['Doptout'])\n",
    "                SO = np.array(data['Soptout'])\n",
    "\n",
    "                slope_RT,intercept_RT,r_RT,p_RT,se_RT = stats.linregress(np.log(diff_vals[~np.isnan(RT)]), RT[~np.isnan(RT)])\n",
    "                slope_DO,intercept_DO,r_DO,p_DO,se_DO = stats.linregress(np.log(diff_vals[~np.isnan(DO)]), DO[~np.isnan(DO)])\n",
    "                slope_SO,intercept_SO,r_SO,p_SO,se_SO = stats.linregress(np.log(diff_vals[~np.isnan(SO)]), SO[~np.isnan(SO)])\n",
    "\n",
    "                df_LR_new = pd.DataFrame({'slope_RT':[slope_RT],'slope_DO':[slope_DO],'slope_SO':[slope_SO],\n",
    "                            'intercept_RT':[intercept_RT],'intercept_DO':[intercept_DO],'intercept_SO':[intercept_SO],\\\n",
    "                            'session':[sessionid],'subject':[part],'user_sessionID_x':[user_sessionID]})\n",
    "            \n",
    "            \n",
    "                df = (pd.concat([df, df_new], ignore_index=True).reindex(columns=df.columns))\n",
    "                dfANOVA = (pd.concat([dfANOVA, dfANOVA_new], ignore_index=True).reindex(columns=dfANOVA.columns))\n",
    "                df_LR = (pd.concat([df_LR, df_LR_new], ignore_index=True).reindex(columns=df_LR.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLR = df_LR[['slope_RT', 'slope_DO', 'slope_SO', 'intercept_RT', 'intercept_DO',\n",
    "       'intercept_SO', 'user_sessionID_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLR.rename(columns={\"user_sessionID_x\": \"user_sessionID\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "dfLR.to_csv(path_results+'linearRegr_diff.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "df.to_csv(path_results+'per_difficulty.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "dfANOVA.to_csv(path_results+'forANOVA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for Day in fday:\n",
    "    for Ses in fsession:\n",
    "        sessionid = 2*Day-2+Ses\n",
    "        path = path_results+'day'+str(Day)+'/session'+str(Ses)+'/'\n",
    "        \n",
    "        # sort files\n",
    "        diff_files = [f for f in os.listdir(path) if f.startswith('diff')]\n",
    "        subj_diff = [int(re.search('%s(.*)%s' % ('diff_Sub', '_Day'), f).group(1)) for f in diff_files]\n",
    "        sorted_subj_diff = sorted(subj_diff)\n",
    "        index_subj_diff = [subj_diff.index(elem) for elem in sorted_subj_diff]\n",
    "        sorted_diff_files = [diff_files[i] for i in index_subj_diff]\n",
    "        ind = -1\n",
    "        \n",
    "        for part in sorted_diff_files:\n",
    "            dict_ = {}\n",
    "            ind += 1\n",
    "            partid = sorted_subj_diff[ind]\n",
    "            part_sessid = str(partid)+'_'+str(sessionid)\n",
    "\n",
    "            f = sorted_diff_files[ind]\n",
    "            filename=path+f\n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "            data_names = []\n",
    "            for k, v in data.items():\n",
    "                globals()[k]=v\n",
    "                if part=='diff_Sub1014_Day10_Sess2.json' and ('se' not in k) and ('sd' not in k):\n",
    "                    data_names.append(k)\n",
    "                for i in range(len(v)):\n",
    "                    dict_.update({k+'_'+str(i):v[i],'user_sessionID': part_sessid,'userID':partid,'sessionID':sessionid})\n",
    "            df = df.append(dict_,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids = df['sessionID'].unique()\n",
    "userids = df['userID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['1011_11', '1011_18', '1014_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in excluded:\n",
    "    df = df[df['user_sessionID']!=elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_names = list(df.columns)\n",
    "# delete from column_names list those columns we keep their value\n",
    "column_names = [x for x in df_column_names if x not in ['sessionID','userID','user_sessionID']]\n",
    "# create dictionary with nan values \n",
    "nan_dict = {}\n",
    "for i in column_names:\n",
    "    nan_dict[i] = np.nan\n",
    "# dictionaries for each excluded participant_session\n",
    "replace = [{'sessionID':int(elem.split('_')[1]),'userID':int(elem.split('_')[0]),\\\n",
    "             'user_sessionID':elem} for elem in excluded]\n",
    "\n",
    "for i in range(len(replace)):\n",
    "    replace[i].update(nan_dict)\n",
    "# append nan dict to df  \n",
    "for elem in replace:\n",
    "    df = df.append(elem, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "df.to_csv(path_results+'per_difficulty.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, se = {},{}\n",
    "for (var, op) in [(ap, np.nanmean), (se, myf.sem)]:\n",
    "    for key in data_names:\n",
    "        var[key] = [op(np.array(df[key+'_'+str(diff-1)])) for diff in unique_signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_ap=path_results+'ap_diff.json'\n",
    "filename_se=path_results+'se_diff.json'\n",
    "# Serializing json  \n",
    "json_object_ap = json.dumps(ap) \n",
    "json_object_se = json.dumps(se)\n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_ap, \"w\") as outfile: \n",
    "    outfile.write(json_object_ap) \n",
    "with open(filename_se, \"w\") as outfile: \n",
    "    outfile.write(json_object_se) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
    "plt.subplots_adjust(wspace = 0.3)  \n",
    "ax[0].errorbar(unique_signals,ap['perf_no'],se['perf_no'],c='g')\n",
    "ax[0].errorbar(unique_signals,ap['Dperf_oo'],se['Dperf_oo'],c='r')\n",
    "ax[0].errorbar(unique_signals,ap['Sperf_oo'],se['Sperf_oo'],c='b')\n",
    "ax[0].set_ylabel('performance')\n",
    "ax[0].set_xlabel('Difficulty')\n",
    "ax[0].legend((\"non-optout\",\"Doptout\",\"Soptout\"),loc='upper right', shadow=True)\n",
    "\n",
    "\n",
    "ax[1].errorbar(unique_signals,ap['RT_no'],se['RT_no'],c='g')\n",
    "ax[1].errorbar(unique_signals,ap['RT_noNOK'],se['RT_noNOK'],c='m')\n",
    "ax[1].errorbar(unique_signals,ap['DRT_OKoo'],se['DRT_OKoo'],c='r')\n",
    "ax[1].errorbar(unique_signals,ap['SRT_OKoo'],se['SRT_OKoo'],c='b')\n",
    "ax[1].errorbar(unique_signals,ap['DRT_oo'],se['DRT_oo'],c='r',ls='--')\n",
    "ax[1].errorbar(unique_signals,ap['SRT_oo'],se['SRT_oo'],c='b',ls='--')\n",
    "ax[1].set_ylabel('Reaction Time')\n",
    "ax[1].set_xlabel('Difficulty')\n",
    "ax[1].legend((\"correct non-optout\",\"incorrect non-optout\",\"correct Doptout\",\"correct Soptout\",\\\n",
    "             \"Doptout\",\"Soptout\"),loc='upper right', shadow=True)\n",
    "ax[1].set_ylim(0.9,1.6)\n",
    "\n",
    "ax[2].errorbar(unique_signals,ap['Doptout'],se['Doptout'],c='r')\n",
    "ax[2].errorbar(unique_signals,ap['Soptout'],se['Soptout'],c='b')\n",
    "ax[2].set_ylabel('Optout')\n",
    "ax[2].set_xlabel('Difficulty')\n",
    "ax[2].legend((\"Doptout\",\"Soptout\"),loc='upper left', shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1**: Mean and standard error across subjects and sessions of psychometric variables vs. difficulty. Left panel: perfomance. Middle panel: normalized eaction time. Right panel: Optout election. Green: non-optout trials. Red: DO optout trials. Blue: SO optout trials. Correct trials for reaction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the result in file\n",
    "filename_ap=path_results+'mean_per_difficulty.json'\n",
    "filename_se=path_results+'se_per_difficulty.json'\n",
    "# Serializing json  \n",
    "json_object_ap = json.dumps(ap) \n",
    "json_object_se = json.dumps(se)\n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_ap, \"w\") as outfile: \n",
    "    outfile.write(json_object_ap) \n",
    "with open(filename_se, \"w\") as outfile: \n",
    "    outfile.write(json_object_se) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Across sessions\n",
    "\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_names = [elem for elem in data_names if 'perf' in elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "ind = -1\n",
    "for part in userids:\n",
    "    subset = df[df['userID']==part]\n",
    "    ap, se = {},{}\n",
    "    for (var, op) in [(ap, np.nanmean), (se, myf.sem)]:\n",
    "        for key in perf_names:\n",
    "            var[key] = [op(np.array(subset[key+'_'+str(diff-1)])) for diff in unique_signals]\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['perf_no'],se['perf_no'],c='g')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['Dperf_oo'],se['Dperf_oo'],c='r')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['Sperf_oo'],se['Sperf_oo'],c='b')\n",
    "    ax[ind1,ind2].set_title('participant '+str(int(part)))\n",
    "    ax[ind1,ind2].set_ylim(25,103)\n",
    "    ax[ind1,0].set_ylabel('Performance')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "ax[5,3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**: Mean and standard deviation across sessions of performance vs. difficulty for every subject. Green: non-optout trials. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo_names = [elem for elem in data_names if 'optout' in elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "ind = -1\n",
    "for part in userids:\n",
    "    subset = df[df['userID']==part]\n",
    "    ap, se = {},{}\n",
    "    for (var, op) in [(ap, np.nanmean), (se, myf.sem)]:\n",
    "        for key in oo_names:\n",
    "            var[key] = [op(np.array(subset[key+'_'+str(diff-1)])) for diff in unique_signals]\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['Doptout'],se['Doptout'],c='r')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['Soptout'],se['Soptout'],c='b')\n",
    "    ax[ind1,ind2].set_title('participant '+str(int(part)))\n",
    "    ax[ind1,ind2].set_ylim(25,103)\n",
    "    ax[ind1,0].set_ylabel('Optout')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "    ax[ind1,ind2].set_ylim(0,103)\n",
    "ax[5,3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3**: Mean and standard deviation across sessions of optout election vs. difficulty for every subject. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_names = [elem for elem in data_names if 'RT' in elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "ind = -1\n",
    "for part in userids:\n",
    "    subset = df[df['userID']==part]\n",
    "    ap, se = {},{}\n",
    "    for (var, op) in [(ap, np.nanmean), (se, myf.sem)]:\n",
    "        for key in RT_names:\n",
    "            var[key] = [op(np.array(subset[key+'_'+str(diff-1)])) for diff in unique_signals]\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['RT_no'],se['RT_no'],c='g')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['RT_noNOK'],se['RT_noNOK'],c='m')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['DRT_OKoo'],se['DRT_OKoo'],c='r')\n",
    "    ax[ind1,ind2].errorbar(unique_signals,ap['SRT_OKoo'],se['SRT_OKoo'],c='b')\n",
    "    ax[ind1,ind2].set_title('participant '+str(int(part)))\n",
    "    ax[ind1,0].set_ylabel('Reaction Time')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "ax[5,3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4**: Mean and standard deviation across sessions of normalized reaction time vs. difficulty for every subject. Green: non-optout correct trials. Magenta: non-optout incorrect trials. Red: DO optout correct trials. Blue: SO optout correct trials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
