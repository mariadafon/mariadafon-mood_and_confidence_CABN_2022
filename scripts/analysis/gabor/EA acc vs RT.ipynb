{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats,signal\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 1\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 1\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 1\n",
    "mpl.rcParams['ytick.major.width'] = 1\n",
    "mpl.rcParams['ytick.minor.width'] = 1\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]\n",
    "excluded_miss = [(1011,11), (1011,18), (1014,12)]\n",
    "excluded_time = [(1008,2),(1009,9)]\n",
    "excluded = excluded_miss+excluded_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/gabor/'\n",
    "path_data = main_path+'/data/jatos_gabor_data/tanda1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeWithZero(domain, xlista, ylista):\n",
    "    if len(domain)==len(xlista):\n",
    "        return ylista\n",
    "    elif len(domain)<len(xlista):\n",
    "        print(domain,xlista)\n",
    "        return 'Error'\n",
    "    else:\n",
    "        set1 = set(domain)\n",
    "        set2 = set(xlista)\n",
    "        # missed values\n",
    "        missing = list(sorted(set1 - set2))\n",
    "        # index of missed values\n",
    "        index = []\n",
    "        [index.append(domain.index(elem)) for elem in missing]\n",
    "        # insert zero in ylista\n",
    "        [ylista.insert(elem,0) for elem in index]\n",
    "        return ylista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of participants \n",
    "participants = [3051+i for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "accQ,accF,accS,DaccNO,SaccNO,accNO = [],[],[],[],[],[] # list of arrays of acc per RT quartile for every subject and session\n",
    "for day in fday:\n",
    "    for session in fsession:\n",
    "        sessionid = 2*day-2+session\n",
    "        \n",
    "        path = path_data+'day'+str(day)+'/session'+str(session)+'/'\n",
    "        data_files = [f for f in os.listdir(path) if f.endswith('_day'+str(day)+'_session'+str(session))]\n",
    "        \n",
    "        # sort files\n",
    "        subj_data = [int(re.search('%s(.*)%s' % ('', '_day'), f).group(1)) for f in data_files]\n",
    "        sorted_subj_data = sorted(subj_data)\n",
    "        index_subj_data = [subj_data.index(elem) for elem in sorted_subj_data]\n",
    "        sorted_data_files = [data_files[i] for i in index_subj_data]\n",
    "\n",
    "        Ddf,Sdf = {},{}\n",
    "        for name in sorted_subj_data: \n",
    "            Ddf[name] = pd.DataFrame()\n",
    "            Sdf[name] = pd.DataFrame()\n",
    "                       \n",
    "        ind = -1\n",
    "        for ses in sorted_data_files:\n",
    "            ind += 1\n",
    "            data = [] \n",
    "            for line in open(path+ses, 'r'):\n",
    "                if line.strip():\n",
    "                    data.append(json.loads(line))\n",
    "\n",
    "            if day==1 and session==1:\n",
    "                if len(data)==5:\n",
    "                    deterministic = data[3]\n",
    "                    stochastic = data[4]\n",
    "                else:\n",
    "                    deterministic = data[len(data)-2]\n",
    "                    stochastic = data[len(data)-1]\n",
    "            else:\n",
    "                if len(data)==4:\n",
    "                    deterministic = data[2]\n",
    "                    stochastic = data[3]\n",
    "                elif len(data)>4:\n",
    "                    deterministic = data[len(data)-2]\n",
    "                    stochastic = data[len(data)-1]\n",
    "                    print('participant '+ str(sorted_subj_data[ind])+' has repeated practice '+str(len(data)-3))\n",
    "                    pract = []\n",
    "                    for j in range(len(data)):\n",
    "                        if len(data[j])==10:\n",
    "                            pract.append(data[j])\n",
    "                else: \n",
    "                    for dd in range(len(data)):\n",
    "                        print(len(data[dd]))\n",
    "                    deterministic = data[2]\n",
    "                    print('participant '+ str(sorted_subj_data[ind])+' missed stochastic')       \n",
    "            Ddf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(deterministic)\n",
    "            Sdf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(stochastic)\n",
    "\n",
    "        for part in sorted_subj_data:\n",
    "            if (part,sessionid) not in excluded:\n",
    "                ## deterministic dataframe\n",
    "                # discrimination RT\n",
    "                discrimination_RT = np.array(list(Ddf[part].discrimination_t_keydown))-np.array(list(Ddf[part].t_offset))\n",
    "                Ddf[part][\"discrimination_RT\"] = discrimination_RT \n",
    "                Dnoise = np.array(list(Ddf[part]['noise']))/100\n",
    "                side_list = list(Ddf[part]['side_trial'])\n",
    "\n",
    "                orientation_list = []\n",
    "                for elem in side_list:\n",
    "                    # left trial\n",
    "                    if elem == 0 or elem == 2:\n",
    "                        orientation_list.append(0)\n",
    "                    # right trial\n",
    "                    else:\n",
    "                        orientation_list.append(1)   \n",
    "                Ddf[part]['orientation'] = orientation_list\n",
    "\n",
    "                Denergy = [1-elem for elem in Dnoise]\n",
    "                signed_Denergy = []\n",
    "                ind_0 = -1\n",
    "                for elem in Denergy:\n",
    "                    ind_0 += 1\n",
    "                    if orientation_list[ind_0]==0:\n",
    "                        signed_Denergy.append(-elem)\n",
    "                    else:\n",
    "                        signed_Denergy.append(elem)\n",
    "                Ddf[part]['signed_stim'] = signed_Denergy\n",
    "\n",
    "                correct_list = list(Ddf[part]['discrimination_is_correct'])\n",
    "                Doptout_list = list(Ddf[part][\"optout\"])\n",
    "                bool_correct_list = [elem==1 for elem in correct_list]\n",
    "                bool_orientation_list = [elem==1 for elem in orientation_list]\n",
    "                xor = np.logical_xor(bool_correct_list,np.logical_not(bool_orientation_list))\n",
    "                Dresp = []\n",
    "                ind_1 = -1\n",
    "                for elem in Doptout_list:\n",
    "                    ind_1 += 1\n",
    "                    if elem==False and xor[ind_1]==True:\n",
    "                        Dresp.append(1)\n",
    "                    elif elem==False and xor[ind_1]==False:\n",
    "                        Dresp.append(0)\n",
    "                    elif elem==True: \n",
    "                        Dresp.append(2)\n",
    "                Ddf[part]['resp_is_R'] = [elem==1 for elem in Dresp]\n",
    "                Ddf[part]['resp_is_R'] = Ddf[part]['resp_is_R'].astype(int)\n",
    "                Ddf[part]['answer'] = Dresp\n",
    "\n",
    "                ## stochastic dataframe\n",
    "                # discrimination RT\n",
    "                discrimination_RT = np.array(list(Sdf[part].discrimination_t_keydown))-np.array(list(Sdf[part].t_offset))\n",
    "                Sdf[part][\"discrimination_RT\"] = discrimination_RT \n",
    "                Snoise = np.array(list(Sdf[part]['noise']))/100\n",
    "                Sside_list = list(Sdf[part]['side_trial'])\n",
    "\n",
    "                Sorientation_list = []\n",
    "                for elem in Sside_list:\n",
    "                    # left trial\n",
    "                    if elem == 0 or elem == 2:\n",
    "                        Sorientation_list.append(0)\n",
    "                    # right trial\n",
    "                    else:\n",
    "                        Sorientation_list.append(1)  \n",
    "                Sdf[part]['orientation'] = Sorientation_list\n",
    "\n",
    "                Senergy = [1-elem for elem in Snoise]\n",
    "                signed_Senergy = []\n",
    "                ind_0 = -1\n",
    "                for elem in Senergy:\n",
    "                    ind_0 += 1\n",
    "                    if Sorientation_list[ind_0]==0:\n",
    "                        signed_Senergy.append(-elem)\n",
    "                    else:\n",
    "                        signed_Senergy.append(elem)\n",
    "                Sdf[part]['signed_stim'] = signed_Senergy\n",
    "\n",
    "                Scorrect_list = Sdf[part]['discrimination_is_correct']\n",
    "                Soptout_list = list(Sdf[part][\"optout\"])\n",
    "                Sbool_correct_list = [elem==1 for elem in Scorrect_list]\n",
    "                Sbool_orientation_list = [elem==1 for elem in Sorientation_list]\n",
    "                Sxor = np.logical_xor(Sbool_correct_list,np.logical_not(Sbool_orientation_list))   \n",
    "                Sresp = []\n",
    "                ind_1 = -1\n",
    "                for elem in Soptout_list:\n",
    "                    ind_1 += 1\n",
    "                    if elem==False and Sxor[ind_1]==True:\n",
    "                        Sresp.append(1)\n",
    "                    elif elem==False and Sxor[ind_1]==False:\n",
    "                        Sresp.append(0)\n",
    "                    elif elem==True: \n",
    "                        Sresp.append(2)\n",
    "                Sdf[part]['resp_is_R'] = [elem==1 for elem in Sresp]\n",
    "                Sdf[part]['resp_is_R'] = Sdf[part]['resp_is_R'].astype(int)\n",
    "                Sdf[part]['answer'] = Sresp\n",
    "\n",
    "        # deterministic non-optout & optout df\n",
    "        Ddf_no,Ddf_oo = {},{}\n",
    "        for name in sorted_subj_data: \n",
    "            Ddf_no[name] = pd.DataFrame()\n",
    "            Ddf_oo[name] = pd.DataFrame()\n",
    "        for part in sorted_subj_data:\n",
    "            Ddf_no[part] = Ddf[part][(Ddf[part]['focus']==0)]\n",
    "            Ddf_oo[part] = Ddf[part][(Ddf[part]['focus']==1)]\n",
    "        # columns to average\n",
    "        cols2mean = ['discrimination_is_correct','discrimination_t_keydown']\n",
    "        \n",
    "        '''\n",
    "        Ddf_no[part] = Ddf_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "        dfDdiffNO = Ddf_no[part].groupby(['difficulty'])[cols2mean].mean().reset_index()\n",
    "        dfDdiffNO = dfDdiffNO.sort_values('difficulty')\n",
    "        # accuracy in deterministic NO trials\n",
    "        DaccNO.append(100*dfDdiffNO['discrimination_is_correct'])\n",
    "        '''\n",
    "                \n",
    "        # stochastic non-optout & optout df\n",
    "        Sdf_no,Sdf_oo = {},{}\n",
    "        for name in sorted_subj_data: \n",
    "            Sdf_no[name] = pd.DataFrame()\n",
    "            Sdf_oo[name] = pd.DataFrame()\n",
    "        for part in sorted_subj_data:\n",
    "            Sdf_no[part] = Sdf[part][(Sdf[part]['focus']==0)]\n",
    "            Sdf_oo[part] = Sdf[part][(Sdf[part]['focus']==1)]\n",
    "        \n",
    "        '''\n",
    "        Sdf_no[part] = Sdf_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "        dfSdiffNO = Sdf_no[part].groupby(['difficulty'])[cols2mean].mean().reset_index()\n",
    "        dfSdiffNO = dfSdiffNO.sort_values('difficulty')\n",
    "        # accuracy in stochastic NO trials\n",
    "        SaccNO.append(100*dfSdiffNO['discrimination_is_correct'])\n",
    "        '''\n",
    "\n",
    "        # non-optout df for each participant\n",
    "        df_no = {}\n",
    "        for name in sorted_subj_data: \n",
    "            df_no[name] = pd.DataFrame()\n",
    "          \n",
    "        for part in sorted_subj_data:\n",
    "            if (part,sessionid) not in excluded:\n",
    "                \n",
    "                df_no[part] = pd.concat([Ddf_no[part],Sdf_no[part]])\n",
    "                \n",
    "                df_no[part] = df_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "                dfdiffNO = df_no[part].groupby(['difficulty'])[['discrimination_is_correct']].mean().reset_index()\n",
    "                dfdiffNO = dfdiffNO.sort_values('difficulty')\n",
    "                accNO.append(100*dfdiffNO['discrimination_is_correct'])\n",
    "                \n",
    "                Ddf_no[part] = Ddf_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "                dfDdiffNO = Ddf_no[part].groupby(['difficulty'])[['discrimination_is_correct']].mean().reset_index()\n",
    "                dfDdiffNO = dfDdiffNO.sort_values('difficulty')\n",
    "                # accuracy in deterministic NO trials\n",
    "                DaccNO.append(100*dfDdiffNO['discrimination_is_correct'])\n",
    "                \n",
    "                Sdf_no[part] = Sdf_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "                dfSdiffNO = Sdf_no[part].groupby(['difficulty'])[['discrimination_is_correct']].mean().reset_index()\n",
    "                dfSdiffNO = dfSdiffNO.sort_values('difficulty')\n",
    "                # accuracy in stochastic NO trials\n",
    "                SaccNO.append(100*dfSdiffNO['discrimination_is_correct'])\n",
    "\n",
    "                # medianRT\n",
    "                RT_list = list(df_no[part]['discrimination_t_keydown'])+list(Ddf_oo[part]['discrimination_t_keydown'])+\\\n",
    "                list(Sdf_oo[part]['discrimination_t_keydown'])\n",
    "                # global median RT for this participant\n",
    "                medianRT = np.nanmedian(RT_list)\n",
    "                \n",
    "\n",
    "                # normalized RT \n",
    "                df_no[part]['norm_NO_RT'] = df_no[part]['discrimination_t_keydown']*(1./medianRT)\n",
    "                # sort rows by normalized NO RT\n",
    "                df_no[part] = df_no[part].sort_values('norm_NO_RT') \n",
    "                # index for each element\n",
    "                df_no[part]['idx'] = np.arange(df_no[part].shape[0])\n",
    "                # cast index in interval 0 - 100\n",
    "                df_no[part]['idx'] = df_no[part]['idx']/(df_no[part]['idx'].max()+1)*100 \n",
    "                # convert discrimination_is_correct and signed_signal to float\n",
    "                df_no[part] = df_no[part].astype({'discrimination_is_correct': 'float'})\n",
    "                #df_no[part] = df_no[part].astype({'signed_signal': 'float'})\n",
    "                # columns to average\n",
    "                cols2mean = ['discrimination_is_correct','discrimination_t_keydown','norm_NO_RT']\n",
    "                \n",
    "                # select the chosen trials\n",
    "                df_no_copy = df_no[part].copy()\n",
    "\n",
    "                # fast and slow dfs\n",
    "                dfS, dfF = df_no[part][(mask:=df_no[part]['idx'] >= 50)], df_no[part][~mask]\n",
    "\n",
    "                '''\n",
    "                # mean of every column group group by signed_signal\n",
    "                dfSsig = dfS.groupby(['signed_signal'])[cols2mean].mean().reset_index()\n",
    "                dfSsig = dfSsig.sort_values('signed_signal') \n",
    "                dfFsig = dfF.groupby(['signed_signal'])[cols2mean].mean().reset_index()\n",
    "                dfFsig = dfFsig.sort_values('signed_signal') \n",
    "                # mean accuracy per signed signal\n",
    "                accSmean = list(100*dfSsig['discrimination_is_correct'])\n",
    "                accFmean = list(100*dfFsig['discrimination_is_correct'])\n",
    "\n",
    "                # every values for signed signal\n",
    "                signed_signals = [-0.14, -0.1 , -0.06, -0.02,  0.02,  0.06,  0.1 ,  0.14]\n",
    "                # unique signed signal\n",
    "                Sunique = list(dfSsig['signed_signal'].unique())\n",
    "                Funique = list(dfFsig['signed_signal'].unique())\n",
    "\n",
    "                accSmean = completeWithZero(signed_signals, Sunique, accSmean)\n",
    "                accFmean = completeWithZero(signed_signals, Funique, accFmean)\n",
    "                '''\n",
    "\n",
    "                # mean of every column group group by difficulty\n",
    "                dfSsig = dfS.groupby(['difficulty'])[cols2mean].mean().reset_index()\n",
    "                dfSsig = dfSsig.sort_values('difficulty') \n",
    "                dfFsig = dfF.groupby(['difficulty'])[cols2mean].mean().reset_index()\n",
    "                dfFsig = dfFsig.sort_values('difficulty')             \n",
    "                # mean accuracy per signed signal\n",
    "                accSmean = list(100*dfSsig['discrimination_is_correct'])\n",
    "                accFmean = list(100*dfFsig['discrimination_is_correct'])\n",
    "\n",
    "                # every values for difficulty\n",
    "                diff_values = [1,2,3]\n",
    "                # unique difficulty\n",
    "                Sunique = list(dfSsig['difficulty'].unique())\n",
    "                Funique = list(dfFsig['difficulty'].unique())\n",
    "\n",
    "                accSmean = completeWithZero(diff_values, Sunique, accSmean)\n",
    "                accFmean = completeWithZero(diff_values, Funique, accFmean)\n",
    "\n",
    "                accS.append(accSmean)\n",
    "                accF.append(accFmean)\n",
    "\n",
    "                # define quartiles\n",
    "                df_no_copy['quartile'] = df_no_copy['idx'] // 25 \n",
    "                # mean of every column group by RT quartile \n",
    "                dfQ = df_no_copy.groupby(['quartile'])[cols2mean].mean().reset_index()\n",
    "                # mean accuracy per quartile of RT\n",
    "                accQ.append(np.array(100*dfQ['discrimination_is_correct']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for diff in np.arange(3):\n",
    "    ttest = stats.ttest_rel(np.array(DaccNO)[:,diff],np.array(SaccNO)[:,diff])\n",
    "    print(ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACC_DNO = np.array(DaccNO).mean(axis=0) \n",
    "semACC_DNO = np.array(DaccNO).std(axis=0)/np.sqrt(len(DaccNO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACC_SNO = np.array(SaccNO).mean(axis=0) \n",
    "semACC_SNO = np.array(SaccNO).std(axis=0)/np.sqrt(len(SaccNO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(3)+1,meanACC_DNO,color=[1,0,0.4])\n",
    "plt.fill_between(np.arange(3)+1,np.array(meanACC_DNO)-np.array(semACC_DNO), \n",
    "                                 np.array(meanACC_DNO)+np.array(semACC_DNO), alpha=0.2, color = [1,0,0.4])\n",
    "plt.plot(np.arange(3)+1,meanACC_SNO,color=[0.4,0,1])\n",
    "plt.fill_between(np.arange(3)+1,np.array(meanACC_SNO)-np.array(semACC_SNO), \n",
    "                                 np.array(meanACC_SNO)+np.array(semACC_SNO), alpha=0.2, color = [0.4,0,1])\n",
    "# plt.ylabel('accuracy (%)')\n",
    "plt.xlabel('difficulty')\n",
    "plt.xticks([1,2,3],labels=[1,2,3])\n",
    "plt.ylim(45,99)\n",
    "plt.yticks([60,80],labels=[])\n",
    "plt.legend(['DO','SO'],loc='best', shadow=True,fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('acc_NO_D&S.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACC_NO = np.array(accNO).mean(axis=0) \n",
    "semACC_NO = np.array(accNO).std(axis=0)/np.sqrt(len(accNO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(3)+1,meanACC_NO,color='k')\n",
    "plt.fill_between(np.arange(3)+1,np.array(meanACC_NO)-np.array(semACC_NO), \n",
    "                                 np.array(meanACC_NO)+np.array(semACC_NO), alpha=0.2, color = 'k')\n",
    "\n",
    "# plt.ylabel('accuracy (%)')\n",
    "plt.xlabel('difficulty')\n",
    "plt.xticks([1,2,3],labels=[1,2,3])\n",
    "plt.ylim(45,99)\n",
    "plt.yticks([60,80],labels=[])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('acc_NO_D&S.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(meanACC_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACC_DNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACC_SNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACCS = np.array(accS).mean(axis=0) \n",
    "semACCS = np.array(accS).std(axis=0)/np.sqrt(len(accS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACCF = np.array(accF).mean(axis=0) \n",
    "semACCF = np.array(accF).std(axis=0)/np.sqrt(len(accS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(3)+1,meanACCF,color='gray')\n",
    "plt.fill_between(np.arange(3)+1,np.array(meanACCF)-np.array(semACCF), \n",
    "                                 np.array(meanACCF)+np.array(semACCF), alpha=0.2, color = 'grey')\n",
    "plt.plot(np.arange(3)+1,meanACCS,color='k')\n",
    "plt.fill_between(np.arange(3)+1,np.array(meanACCS)-np.array(semACCS), \n",
    "                                 np.array(meanACCS)+np.array(semACCS), alpha=0.2, color = 'k')\n",
    "\n",
    "# plt.ylabel('accuracy (%)')\n",
    "plt.xlabel('difficulty')\n",
    "plt.ylim(45,99)\n",
    "plt.xticks([1,2,3],labels=[1,2,3])\n",
    "plt.yticks([60,80],labels=[])\n",
    "plt.legend(['fast','slow'],loc='best', shadow=True,fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('acc_fast&slow_diff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanACCQ = np.array(accQ).mean(axis=0) \n",
    "semACCQ = np.array(accQ).std(axis=0)/np.sqrt(len(accQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4],meanACCQ,color='k')\n",
    "plt.fill_between([1,2,3,4],np.array(meanACCQ)-np.array(semACCQ), \n",
    "                                 np.array(meanACCQ)+np.array(semACCQ), alpha=0.2, color = 'k')\n",
    "plt.ylabel('accuracy (%)')\n",
    "plt.ylim(45,99)\n",
    "plt.xlabel('RT')\n",
    "plt.tight_layout()\n",
    "plt.xticks([1,2,3,4],labels=['q1','q2','q3','q4'])\n",
    "plt.savefig('acc_RTquartiles.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'NOdetermistic':{'mean':list(meanACC_DNO),'sem':list(semACC_DNO)},\\\n",
    "         'NOstochastic':{'mean':list(meanACC_SNO),'sem':list(semACC_SNO)},\\\n",
    "        'accFast':{'mean':list(meanACCF),'sem':list(semACCF)},\\\n",
    "        'accSlow':{'mean':list(meanACCS),'sem':list(semACCS)},\n",
    "        'accRTquartile':{'mean':list(meanACCQ),'sem':list(semACCQ)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN AGAIN !!!\n",
    "\n",
    "# write the result in file\n",
    "filename=path_results+'confidence_extra_analysis.json'\n",
    "# Serializing json  \n",
    "json_object_ = json.dumps(dict_) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename, \"w\") as outfile: \n",
    "    outfile.write(json_object_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "accF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaccNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-crawford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-reminder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_no[part]['quartile'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[part]['quartile'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[part].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(accQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[part]['discrimination_is_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_no[3062])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[3062] = df_no[3062].sort_values('v2') # Ordenas por el valor\n",
    "d['idx'] = np.arange(d.shape[0]) # le ponés un índice a cada elemento\n",
    "d['idx'] = d['idx'] / (d['idx'].max() + 1) * 100 # llevas esos índices al intervalo 0 ... 100\n",
    "d['quartile'] = d['idx'] // 25 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ddf[3062])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[3062].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100_000\n",
    "by = 18_000\n",
    "df = pd.DataFrame(np.random.uniform(0, 1, (n, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df.groupby(df.index // by).apply(pd.DataFrame.quantile, .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df.index // by).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
