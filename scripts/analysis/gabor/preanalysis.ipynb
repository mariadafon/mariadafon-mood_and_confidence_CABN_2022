{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prenalysis to final df\n",
    "\n",
    "From single_session_analysis.ipynb results of every session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats,signal\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2\n",
    "\n",
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/gabor/'\n",
    "path_data = main_path+'/data/jatos_gabor_data/tanda1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_list = []\n",
    "for Day in fday:\n",
    "    for Ses in fsession:\n",
    "        path = path_data+'day'+str(Day)+'/session'+str(Ses)+'/'\n",
    "        data_files = [f for f in os.listdir(path) if f.endswith('_day'+str(Day)+'_session'+str(Ses))]\n",
    "        # sort files\n",
    "        subj_data = [int(re.search('%s(.*)%s' % ('', '_day'), f).group(1)) for f in data_files]\n",
    "        sorted_subj_data = sorted(subj_data)\n",
    "        index_subj_data = [subj_data.index(elem) for elem in sorted_subj_data]\n",
    "        sorted_data_files = [data_files[i] for i in index_subj_data]\n",
    "        # reports, staircase, deterministic and stochastic df for each participant\n",
    "        Rdf = {}\n",
    "        for name in sorted_subj_data: \n",
    "            Rdf[name] = {}\n",
    "        ind = -1\n",
    "        for ses in sorted_data_files:\n",
    "            ind += 1\n",
    "            #print(sorted_subj_data[ind])\n",
    "            data = []\n",
    "            for line in open(path+ses, 'r'):\n",
    "                if line.strip():\n",
    "                    data.append(json.loads(line))\n",
    "            if Day==1 and Ses==1:\n",
    "                reports = data[1]\n",
    "            else:\n",
    "                reports = data[0]\n",
    "            part = reports['userID']\n",
    "            if int(part)>1015 and int(part)<1201:\n",
    "                part = str(int(part)-186)\n",
    "            elif int(part)>1201:\n",
    "                part = str(int(part)-217)\n",
    "\n",
    "            if reports['sessionID']%2==0:\n",
    "                session = 2\n",
    "            else:\n",
    "                session = 1\n",
    "                \n",
    "            Rdf[sorted_subj_data[ind]] = reports   \n",
    "            del Rdf[sorted_subj_data[ind]]['date']\n",
    "            rep_list.append(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf = pd.DataFrame(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf['userID'] = Rdf['userID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename userID refered to the first deployment userID\n",
    "secondIDs = [elem for elem in Rdf['userID'].unique() if elem>1015 and elem<1201]\n",
    "thirdIDs = [elem for elem in Rdf['userID'].unique() if elem>1201]\n",
    "\n",
    "for ids in secondIDs:\n",
    "    Rdf.loc[Rdf.userID == ids, 'userID'] = ids-186\n",
    "for ids in thirdIDs:\n",
    "    Rdf.loc[Rdf.userID == ids, 'userID'] = ids-217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_list = list(Rdf['stress'])\n",
    "real_stress = [1-elem for elem in stress_list]\n",
    "Rdf['real_stress'] = real_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf['sessionID'] = Rdf['sessionID'].astype(int)\n",
    "Rdf['userID'] = Rdf['userID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_userID = list(Rdf['userID'])\n",
    "rep_sessionID = list(Rdf['sessionID'])\n",
    "rep_user_sessionID = []\n",
    "for i in range(len(rep_userID)):\n",
    "    rep_user_sessionID.append(str(rep_userID[i])+'_'+str(rep_sessionID[i]))\n",
    "Rdf['user_sessionID']=rep_user_sessionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf_sin_nan = Rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf['sessionID'] = Rdf['sessionID'].astype(int)\n",
    "Rdf['userID'] = Rdf['userID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = path_results+'across_sessions/'\n",
    "\n",
    "data_files = [f for f in os.listdir(path_df) if f.startswith('average')]\n",
    "df = {}\n",
    "for f in data_files:\n",
    "    data = [json.loads(line) for line in open(path_df+f, 'r')]\n",
    "    df[data[0]['sessionID'][0]]=pd.DataFrame.from_dict(data[0])\n",
    "\n",
    "DF = pd.concat([df[elem] for elem in range(1,len(data_files)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['sessionID'] = DF['sessionID'].astype(int)\n",
    "DF['participantID'] = DF['participantID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_user_sessionID=[]\n",
    "gabor_userID = list(DF['participantID'])\n",
    "gabor_sessionID = list(DF['sessionID'])\n",
    "for i in range(len(gabor_userID)):\n",
    "    gabor_user_sessionID.append(str(gabor_userID[i])+'_'+str(gabor_sessionID[i]))\n",
    "DF['user_sessionID']=gabor_user_sessionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename userID refered to the first deployment userID\n",
    "secondIDs = [elem for elem in DF['participantID'].unique() if elem>1015 and elem<1201]\n",
    "thirdIDs = [elem for elem in DF['participantID'].unique() if elem>1201]\n",
    "for ids in secondIDs:\n",
    "    DF.loc[DF.userID == ids, 'participantID'] = ids-186\n",
    "for ids in thirdIDs:\n",
    "    DF.loc[DF.userID == ids, 'participantID'] = ids-217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.merge(Rdf,DF,on='user_sessionID',how='outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Hopt = pd.DataFrame(columns=['user_sessionID','HRopt_','SO_HRopt'])\n",
    "for Day in fday:\n",
    "    for Ses in fsession:\n",
    "        sessionid = 2*Day-2+Ses\n",
    "        path = path_results+'day'+str(Day)+'/session'+str(Ses)+'/'\n",
    "        optimalH_files = [f for f in os.listdir(path) if f.startswith('optimalH')]\n",
    "        subj_optimalH = [int(re.search('%s(.*)%s' % ('optimalH_Sub', '_Day'), f).group(1)) for f in optimalH_files]\n",
    "        sorted_subj_optimalH = sorted(subj_optimalH)\n",
    "        index_subj_optimalH = [subj_optimalH.index(elem) for elem in sorted_subj_optimalH]\n",
    "        sorted_optimalH_files = [optimalH_files[i] for i in index_subj_optimalH]\n",
    "        for filename in sorted_optimalH_files:\n",
    "            # optimalH\n",
    "            f = filename\n",
    "            filename=path+f\n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "            for k, v in data.items():\n",
    "                globals()[k]=v\n",
    "            df_Hopt = df_Hopt.append({'HRopt_': HRopt_,'SO_HRopt_': SO_HRopt_,\"user_sessionID\":part_sessid},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.merge(adf,df_Hopt,on='user_sessionID',how='outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PCfit = pd.DataFrame()\n",
    "for Day in fday:\n",
    "    for Ses in fsession:\n",
    "        sessionid = 2*Day-2+Ses\n",
    "        path = path_results++'day'+str(Day)+'/session'+str(Ses)+'/'\n",
    "        # Deterministic PC fit\n",
    "        DOfit_files = [f for f in os.listdir(path) if f.startswith('DO_fit')]\n",
    "        aux = [f.replace('DO_fit_oo_Sub','') for f in DOfit_files]\n",
    "        subj_DOfit = [int(f.replace('_Day'+str(Day)+'_Sess'+str(Ses)+'.json','')) for f in aux]\n",
    "        sorted_subj_DOfit = sorted(subj_DOfit)\n",
    "        index_subj_DOfit = [subj_DOfit.index(elem) for elem in sorted_subj_DOfit]\n",
    "        sorted_DOfit_files = [DOfit_files[i] for i in index_subj_DOfit]\n",
    "        \n",
    "        # NO PC fit\n",
    "        NOfit_files = [f for f in os.listdir(path) if f.startswith('NO_fit')]\n",
    "        auxNO = [f.replace('NO_fit_Sub','') for f in NOfit_files]\n",
    "        subj_NOfit = [int(f.replace('_Day'+str(Day)+'_Sess'+str(Ses)+'.json','')) for f in auxNO]\n",
    "        sorted_subj_NOfit = sorted(subj_NOfit)\n",
    "        index_subj_NOfit = [subj_NOfit.index(elem) for elem in sorted_subj_NOfit]\n",
    "        sorted_NOfit_files = [NOfit_files[i] for i in index_subj_NOfit]\n",
    "        \n",
    "        # Stochastic PC fit\n",
    "        SOfit_files = [f for f in os.listdir(path) if f.startswith('SO_fit')]\n",
    "        auxSO = [f.replace('SO_fit_oo_Sub','') for f in SOfit_files]\n",
    "        subj_SOfit = [int(f.replace('_Day'+str(Day)+'_Sess'+str(Ses)+'.json','')) for f in auxSO]\n",
    "        sorted_subj_SOfit = sorted(subj_SOfit)\n",
    "        index_subj_SOfit = [subj_SOfit.index(elem) for elem in sorted_subj_SOfit]\n",
    "        sorted_SOfit_files = [SOfit_files[i] for i in index_subj_SOfit]\n",
    "        \n",
    "        ind = -1\n",
    "        for filename in sorted_DOfit_files:\n",
    "            ind += 1\n",
    "            partid = sorted_subj_DOfit[ind]\n",
    "            part_sessid = str(partid)+'_'+str(sessionid)\n",
    "            # deterministic PC fit\n",
    "            f = filename\n",
    "            filename=path+f\n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "            for k, v in data.items():\n",
    "                globals()[k]=v\n",
    "                \n",
    "            # psychometric curve NON-optout\n",
    "            fNO = sorted_NOfit_files[ind]\n",
    "            filename=path+fNO\n",
    "            with open(filename) as fNO:\n",
    "                dataNO = json.load(fNO)\n",
    "            for k, v in dataNO.items():\n",
    "                globals()[k]=v     \n",
    "                \n",
    "            # stochastic PC fit\n",
    "            fSO = sorted_SOfit_files[ind]\n",
    "            filename=path+fSO\n",
    "            with open(filename) as fSO:\n",
    "                dataSO = json.load(fSO)\n",
    "            for k, v in dataSO.items():\n",
    "                globals()[k]=v   \n",
    "                \n",
    "            df_PCfit = df_PCfit.append({'DHR_oo': DHR_oo,'DHL_oo':DHL_oo,'Dsigma_oo':Dsigma_oo,\\\n",
    "                                        'SHR_oo': SHR_oo,'SHL_oo':SHL_oo,'Ssigma_oo':Ssigma_oo,\\\n",
    "                                        'no_sigma':Sigma, 'no_bias':Hno,\\\n",
    "                                        \"user_sessionID\":part_sessid},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PCfit['HmiddleDO']=(df_PCfit['DHR_oo']+df_PCfit['DHL_oo'])/2\n",
    "df_PCfit['HmiddleSO']=(df_PCfit['SHR_oo']+df_PCfit['SHL_oo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.merge(adf,df_PCfit,on='user_sessionID',how='outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['risk_av'] = (adf['Dsubj_perf_oo']-adf['Ssubj_perf_oo'])/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['DoverConf'] = (np.abs(2*adf['HRopt_'])-np.abs(adf['DHL_oo']-adf['DHR_oo']))/(np.abs(2*adf['HRopt_'])+np.abs(adf['DHL_oo']-adf['DHR_oo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['SoverConf'] = (np.abs(2*adf['SO_HRopt_'])-np.abs(adf['SHL_oo']-adf['SHR_oo']))/(np.abs(2*adf['SO_HRopt_'])+np.abs(adf['SHL_oo']-adf['SHR_oo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss a session\n",
    "\n",
    "excluded_miss = ['1011_11', '1011_18', '1014_12']\n",
    "adf = adf[~adf['user_sessionID'].isin(excluded_miss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_column_names = list(adf.columns)\n",
    "\n",
    "column_names = [x for x in adf_column_names if x not in ['sessionID_x','sessionID_y','userID','userID_y',\\\n",
    "                                                         'participantID','user_sessionID']]\n",
    "\n",
    "nan_dict = {}\n",
    "for i in column_names:\n",
    "    nan_dict[i] = np.nan\n",
    "\n",
    "replace = [{'sessionID_x':int(elem.split('_')[1]),'sessionID_y':int(elem.split('_')[1]), \\\n",
    "             'userID':int(elem.split('_')[0]), 'userID_y':int(elem.split('_')[0]),\\\n",
    "            'participantID':int(elem.split('_')[0]),'user_sessionID':elem} for elem in excluded_miss]\n",
    "\n",
    "for i in range(len(replace)):\n",
    "    replace[i].update(nan_dict)\n",
    "    \n",
    "for elem in replace:\n",
    "    adf = adf.append(elem, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude 2 sessions because the meedian RT for some difficulties was greater than 2 s\n",
    "\n",
    "excluded_time = ['1008_2','1009_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf = adf[~adf['user_sessionID'].isin(excluded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_column_names = list(adf.columns)\n",
    "\n",
    "column_names = [x for x in adf_column_names if x not in ['userID','sessionID_x','sessionID_y','userID_x','userID_y',\\\n",
    "                                                         'participantID','user_sessionID']]\n",
    "\n",
    "for ex in excluded_time:\n",
    "    for col in column_names:\n",
    "        adf.loc[adf.user_sessionID == ex, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.groupby(['userID']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf[adf['userID']==1011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = adf.sort_values(by = ['userID', 'sessionID_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['real_OK_NO_RT'] = adf['OKubj_RT_no']*adf['medianRT']\n",
    "adf['real_OK_DO_RT'] = adf['OKDsubj_RT_oo']*adf['medianRT']\n",
    "adf['real_OK_SO_RT'] = adf['OKSsubj_RT_oo']*adf['medianRT']\n",
    "adf['real_NOK_NO_RT'] = adf['NOKubj_RT_no']*adf['medianRT']\n",
    "adf['real_DO_RT'] = adf['Dsubj_RT_oo']*adf['medianRT']\n",
    "adf['real_SO_RT'] = adf['Ssubj_RT_oo']*adf['medianRT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['sessionID_x'] = adf['sessionID_x'].astype(int)\n",
    "adf['userID'] = adf['userID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf[adf['userID']==1011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.to_csv(path_results+'preanalyzed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
