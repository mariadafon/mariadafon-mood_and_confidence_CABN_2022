{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/gabor/'\n",
    "path_data = main_path+'/data/jatos_gabor_data/tanda1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, main_path+'/scr')\n",
    "import my_functions as myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2\n",
    "\n",
    "fday = 3\n",
    "fsession = 2\n",
    "\n",
    "path = path_data+'day'+str(fday)+'/session'+str(fsession)+'/'\n",
    "filename_average=path_results+'across_sessions/average_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "# path to save results\n",
    "path_fit = path_results+'day'+str(fday)+'/session'+str(fsession)+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of participants \n",
    "participants = [991+i for i in range(24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [f for f in os.listdir(path) if f.endswith('_day'+str(fday)+'_session'+str(fsession))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files\n",
    "subj_data = [int(re.search('%s(.*)%s' % ('', '_day'), f).group(1)) for f in data_files]\n",
    "sorted_subj_data = sorted(subj_data)\n",
    "index_subj_data = [subj_data.index(elem) for elem in sorted_subj_data]\n",
    "sorted_data_files = [data_files[i] for i in index_subj_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reports, staircase, deterministic and stochastic df for each participant\n",
    "\n",
    "Rdf,Cdf,Ddf,Sdf = {},{},{},{}\n",
    "for name in sorted_subj_data: \n",
    "    Rdf[name] = {}\n",
    "    Cdf[name] = pd.DataFrame()\n",
    "    Ddf[name] = pd.DataFrame()\n",
    "    Sdf[name] = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "for ses in sorted_data_files:\n",
    "    ind += 1\n",
    "    data = [] \n",
    "    for line in open(path+ses, 'r'):\n",
    "        if line.strip():\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    if fday==1 and fsession==1:\n",
    "        if len(data)==6:\n",
    "            demographics = data[0]\n",
    "            reports = data[1]\n",
    "            practice = data[2]\n",
    "            staircase = data[3]\n",
    "            deterministic = data[4]\n",
    "            stochastic = data[5]\n",
    "        else:\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('this participant has repeated some stage')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "    else:\n",
    "        if len(data)==4:\n",
    "            reports = data[0]\n",
    "            staircase = data[1]\n",
    "            deterministic = data[2]\n",
    "            stochastic = data[3]\n",
    "        elif len(data)>4:\n",
    "            reports = data[0]\n",
    "            staircase = data[len(data)-3]\n",
    "            deterministic = data[len(data)-2]\n",
    "            stochastic = data[len(data)-1]\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('participant '+ str(sorted_subj_data[ind])+' has repeated staircase '+str(len(data)-3))\n",
    "            stair = []\n",
    "            for j in range(len(data)):\n",
    "                if len(data[j])==60:\n",
    "                    stair.append(data[j])\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "        else: \n",
    "            for dd in range(len(data)):\n",
    "                print(len(data[dd]))\n",
    "            reports = data[0]\n",
    "            staircase = data[1]\n",
    "            deterministic = data[2]\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('participant '+ str(sorted_subj_data[ind])+' missed stochastic')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')\n",
    "            print('!!!!!!!!!!!!!!!!!!')           \n",
    "            \n",
    "        \n",
    "    part = reports['userID']\n",
    "    if int(part)>1015 and int(part)<1200:\n",
    "        part = str(int(part)-186)\n",
    "    elif int(part)>1200:\n",
    "        part = str(int(part)-217)\n",
    "    if reports['sessionID']%2==0:\n",
    "        session = 2\n",
    "    else:\n",
    "        session = 1\n",
    "    \n",
    "    if (part!=str(sorted_subj_data[ind])):\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('INCORRECT')\n",
    "        print('participant',part,'file participant',sorted_subj_data[ind])\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "    if (session!=fsession):\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('INCORRECT')\n",
    "        print('session',session,'file session',fsession)\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "    Rdf[sorted_subj_data[ind]] = reports\n",
    "    Cdf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(staircase)\n",
    "    Ddf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(deterministic)\n",
    "    Sdf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(stochastic)\n",
    "    print('participant: ',part,'initial datetime stamp: ',reports['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staircase analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "for part in sorted_subj_data:\n",
    "    Cresult = list(Cdf[part].discrimination_is_correct)\n",
    "    Cnoise = list(Cdf[part].noise)\n",
    "    Cnoise = np.array(Cnoise)/100\n",
    "    Cdf[part]['stim'] = Cnoise\n",
    "    Energy = [1-elem for elem in Cnoise]\n",
    "    mean_diff_energy_last10trials = np.mean(Energy[-10:])\n",
    "    \n",
    "    samples = list(Cdf[part]['gabor_sample'])\n",
    "    noise_list = list(Cdf[part]['noise'])\n",
    "    \n",
    "    # write the result in file\n",
    "    filename=path_fit+'staircase_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"Cresult\":list(Cresult),\n",
    "        \"Cnoise\":list(Cnoise),\n",
    "        \"last_diff_energy\":Energy[len(Energy)-1],\n",
    "        \"mean_diff_energy_last10trials\": mean_diff_energy_last10trials\n",
    "    }\n",
    "    # Serializing json  \n",
    "    json_object = json.dumps(dict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(filename, \"w\") as outfile: \n",
    "        outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "stair_files = [f for f in os.listdir(path_fit) if f.startswith('staircase_')]\n",
    "aux_st = [f.replace('staircase_Sub','') for f in stair_files]\n",
    "subj_stair = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in aux_st]\n",
    "sorted_subj_stair = sorted(subj_stair)\n",
    "index_subj_stair = [subj_stair.index(elem) for elem in sorted_subj_stair]\n",
    "sorted_stair_files = [stair_files[i] for i in index_subj_stair]\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.2)\n",
    "plt.subplots_adjust(hspace = 0.6)\n",
    "for part in sorted_subj_data:\n",
    "    # stochastic PC fit\n",
    "    f_stair = sorted_stair_files[ind]\n",
    "    filename=path_fit+f_stair\n",
    "    with open(filename) as f_stair:\n",
    "        data_stair = json.load(f_stair)\n",
    "    for k, v in data_stair.items():\n",
    "        globals()[k]=v  \n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].set_title('participante:'+str(part))\n",
    "    ax[ind1,ind2].plot(np.arange(1,61),Cresult,'ok')\n",
    "    ax[ind1,ind2].plot(np.arange(1,61),Cnoise,'r')\n",
    "    ax[ind1,0].set_ylabel('Staircase result')\n",
    "    ax[5,ind2].set_xlabel('Trial number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic dataframe\n",
    "for part in sorted_subj_data:\n",
    "    discrimination_RT = np.array(list(Ddf[part].discrimination_t_keydown))-np.array(list(Ddf[part].t_offset))\n",
    "    Ddf[part][\"discrimination_RT\"] = discrimination_RT \n",
    "    Dnoise = np.array(list(Ddf[part]['noise']))/100\n",
    "    side_list = list(Ddf[part]['side_trial'])\n",
    "    \n",
    "    orientation_list = []\n",
    "    for elem in side_list:\n",
    "        # left trial\n",
    "        if elem == 0 or elem == 2:\n",
    "            orientation_list.append(0)\n",
    "        # right trial\n",
    "        else:\n",
    "            orientation_list.append(1)   \n",
    "    Ddf[part]['orientation'] = orientation_list\n",
    "    \n",
    "    Denergy = [1-elem for elem in Dnoise]\n",
    "    signed_Denergy = []\n",
    "    ind_0 = -1\n",
    "    for elem in Denergy:\n",
    "        ind_0 += 1\n",
    "        if orientation_list[ind_0]==0:\n",
    "            signed_Denergy.append(-elem)\n",
    "        else:\n",
    "            signed_Denergy.append(elem)\n",
    "    Ddf[part]['signed_stim'] = signed_Denergy\n",
    "    \n",
    "    correct_list = list(Ddf[part]['discrimination_is_correct'])\n",
    "    Doptout_list = list(Ddf[part][\"optout\"])\n",
    "    bool_correct_list = [elem==1 for elem in correct_list]\n",
    "    bool_orientation_list = [elem==1 for elem in orientation_list]\n",
    "    xor = np.logical_xor(bool_correct_list,np.logical_not(bool_orientation_list))\n",
    "    Dresp = []\n",
    "    ind_1 = -1\n",
    "    for elem in Doptout_list:\n",
    "        ind_1 += 1\n",
    "        if elem==False and xor[ind_1]==True:\n",
    "            Dresp.append(1)\n",
    "        elif elem==False and xor[ind_1]==False:\n",
    "            Dresp.append(0)\n",
    "        elif elem==True: \n",
    "            Dresp.append(2)\n",
    "    Ddf[part]['resp_is_R'] = [elem==1 for elem in Dresp]\n",
    "    Ddf[part]['resp_is_R'] = Ddf[part]['resp_is_R'].astype(int)\n",
    "    Ddf[part]['answer'] = Dresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtoffset = []\n",
    "for part in sorted_subj_data:\n",
    "    Dtoffset.append(Ddf[part]['t_offset'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Dtoffset)\n",
    "ax.set_xticks(np.arange(1,len(sorted_subj_data)+1))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('deterministic time offset (stim display)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ddiscrimination_t_keydown = []\n",
    "for part in sorted_subj_data:\n",
    "    Ddiscrimination_t_keydown.append(Ddf[part]['discrimination_t_keydown'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Ddiscrimination_t_keydown)\n",
    "ax.set_xticks(np.arange(1,len(sorted_subj_data)+1))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('reaction time (discrimination_t_keydown)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_time = np.array(Ddf[991].discrimination_t_onset)-np.array(Ddf[991].t_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_time = np.array(Ddf[991].t_offset)-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(delay_time,dead_time)\n",
    "plt.title('participant 991')\n",
    "plt.xlabel('delay time (ms)')\n",
    "plt.ylabel('dead time (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard t offset greater than 350 ms\n",
    "for name in sorted_subj_data: \n",
    "    Ddf[name] = Ddf[name][Ddf[name]['t_offset']<=350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic non-optout & optout df\n",
    "Ddf_no,Ddf_oo = {},{}\n",
    "for name in sorted_subj_data: \n",
    "    Ddf_no[name] = pd.DataFrame()\n",
    "    Ddf_oo[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    Ddf_no[part] = Ddf[part][(Ddf[part]['focus']==0)]\n",
    "    Ddf_oo[part] = Ddf[part][(Ddf[part]['focus']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic dataframe\n",
    "for part in sorted_subj_data:\n",
    "    discrimination_RT = np.array(list(Sdf[part].discrimination_t_keydown))-np.array(list(Sdf[part].t_offset))\n",
    "    Sdf[part][\"discrimination_RT\"] = discrimination_RT \n",
    "    Snoise = np.array(list(Sdf[part]['noise']))/100\n",
    "    Sside_list = list(Sdf[part]['side_trial'])\n",
    "    \n",
    "    Sorientation_list = []\n",
    "    for elem in Sside_list:\n",
    "        # left trial\n",
    "        if elem == 0 or elem == 2:\n",
    "            Sorientation_list.append(0)\n",
    "        # right trial\n",
    "        else:\n",
    "            Sorientation_list.append(1)  \n",
    "    Sdf[part]['orientation'] = Sorientation_list\n",
    "    \n",
    "    Senergy = [1-elem for elem in Snoise]\n",
    "    signed_Senergy = []\n",
    "    ind_0 = -1\n",
    "    for elem in Senergy:\n",
    "        ind_0 += 1\n",
    "        if Sorientation_list[ind_0]==0:\n",
    "            signed_Senergy.append(-elem)\n",
    "        else:\n",
    "            signed_Senergy.append(elem)\n",
    "    Sdf[part]['signed_stim'] = signed_Senergy\n",
    "    \n",
    "    Scorrect_list = Sdf[part]['discrimination_is_correct']\n",
    "    Soptout_list = list(Sdf[part][\"optout\"])\n",
    "    Sbool_correct_list = [elem==1 for elem in Scorrect_list]\n",
    "    Sbool_orientation_list = [elem==1 for elem in Sorientation_list]\n",
    "    Sxor = np.logical_xor(Sbool_correct_list,np.logical_not(Sbool_orientation_list))   \n",
    "    Sresp = []\n",
    "    ind_1 = -1\n",
    "    for elem in Soptout_list:\n",
    "        ind_1 += 1\n",
    "        if elem==False and Sxor[ind_1]==True:\n",
    "            Sresp.append(1)\n",
    "        elif elem==False and Sxor[ind_1]==False:\n",
    "            Sresp.append(0)\n",
    "        elif elem==True: \n",
    "            Sresp.append(2)\n",
    "    Sdf[part]['resp_is_R'] = [elem==1 for elem in Sresp]\n",
    "    Sdf[part]['resp_is_R'] = Sdf[part]['resp_is_R'].astype(int)\n",
    "    Sdf[part]['answer'] = Sresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stoffset = []\n",
    "for part in sorted_subj_data:\n",
    "    Stoffset.append(Sdf[part]['t_offset'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Stoffset)\n",
    "ax.set_xticks(np.arange(1,len(sorted_subj_data)+1))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('stochastic time offset (stim display)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard t offset greater than 350 ms\n",
    "for name in sorted_subj_data: \n",
    "    Sdf[name] = Sdf[name][Sdf[name]['t_offset']<=350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic non-optout & optout df\n",
    "Sdf_no,Sdf_oo = {},{}\n",
    "for name in sorted_subj_data: \n",
    "    Sdf_no[name] = pd.DataFrame()\n",
    "    Sdf_oo[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    Sdf_no[part] = Sdf[part][(Sdf[part]['focus']==0)]\n",
    "    Sdf_oo[part] = Sdf[part][(Sdf[part]['focus']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-optout df for each participant\n",
    "df_no = {}\n",
    "for name in sorted_subj_data: \n",
    "    df_no[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    df_no[part] = pd.concat([Ddf_no[part],Sdf_no[part]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data together df for each participant\n",
    "df_all = {}\n",
    "for name in sorted_subj_data: \n",
    "    df_all[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    df_all[part] = pd.concat([Ddf[part],Sdf[part]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN AGAIN\n",
    "\n",
    "## toffset \n",
    "\n",
    "median_toffset,max_toffset = [],[]\n",
    "for part in sorted_subj_data:\n",
    "    toffset = df_all[part]['t_offset']\n",
    "    median_toffset.append(np.median(toffset))\n",
    "    max_toffset.append(np.max(toffset))\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"median_toffset\":median_toffset,\n",
    "    \"max_toffset\":max_toffset\n",
    "}\n",
    "# Serializing json  \n",
    "json_object = json.dumps(dict_) \n",
    "    \n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis between last staircase level and non-optout performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_n_s,subj_no_perf = [],[]\n",
    "for part in sorted_subj_data:\n",
    "    subj_n_s.append(Cdf[part].loc[59].at['noise'])\n",
    "    result_no = np.array(df_no[part].discrimination_is_correct)\n",
    "    num_trials_no = len(result_no)\n",
    "    subj_no_perf.append(100*np.sum(result_no)/num_trials_no)\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(subj_n_s,subj_no_perf)\n",
    "print(\"Correlation: \",r_value,\" and p value: \",p_value)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot()\n",
    "plt.plot(subj_n_s,intercept+np.array(subj_n_s)*slope,'k')\n",
    "plt.scatter(subj_n_s,subj_no_perf)\n",
    "plt.xlabel('last staircase level')\n",
    "plt.ylabel('non-optout performance')\n",
    "#plt.text(75,45,'p value:'+str(np.round(p_value,5)), ha='left', wrap=True,fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('last_staircase_perf_day'+str(fday)+'_session'+str(fsession)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis vs. difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs. difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "middle_perf_no = []\n",
    "subj_perf_diff_oo,Ssubj_perf_diff_oo,subj_perf_diff_no = [[] for _ in range(3)]\n",
    "subj_perf_oo,Ssubj_perf_oo,subj_perf_no = [[] for _ in range(3)]\n",
    "for part in sorted_subj_data:\n",
    "    perf_diff_oo,perf_diff_no,Sperf_diff_oo,se_perf_diff_oo,Sse_perf_diff_oo,\\\n",
    "    se_perf_diff_no,lnum_trials_oo,lSnum_trials_oo,lnum_trials_no=[[] for _ in range(9)]\n",
    "    for diff in range(3):\n",
    "        # correct deterministic\n",
    "        subset_oo = Ddf_oo[part][(Ddf_oo[part][\"difficulty\"]==diff) & (Ddf_oo[part][\"optout\"]==0)]  \n",
    "        result_oo = np.array(subset_oo.discrimination_is_correct)\n",
    "        num_trials_oo = len(result_oo)\n",
    "        lnum_trials_oo.append(num_trials_oo)\n",
    "        if num_trials_oo:\n",
    "            perf_diff_oo.append(100*np.sum(result_oo)/num_trials_oo)\n",
    "            se_perf_diff_oo.append(100*np.sqrt(perf_diff_oo[diff]/100 *(1-perf_diff_oo[diff]/100)/num_trials_oo))\n",
    "        else:\n",
    "            perf_diff_oo.append(np.nan)\n",
    "            se_perf_diff_oo.append(np.nan)\n",
    "        # correct stochastic\n",
    "        Ssubset_oo = Sdf_oo[part][(Sdf_oo[part][\"difficulty\"]==diff) & (Sdf_oo[part][\"optout\"]==0)]  \n",
    "        Sresult_oo = np.array(Ssubset_oo.discrimination_is_correct)\n",
    "        Snum_trials_oo = len(Sresult_oo)\n",
    "        lSnum_trials_oo.append(Snum_trials_oo)\n",
    "        if Snum_trials_oo:\n",
    "            Sperf_diff_oo.append(100*np.sum(Sresult_oo)/Snum_trials_oo)\n",
    "            Sse_perf_diff_oo.append(100*np.sqrt(Sperf_diff_oo[diff]/100 *(1-Sperf_diff_oo[diff]/100)/Snum_trials_oo))\n",
    "        else: \n",
    "            Sperf_diff_oo.append(np.nan)\n",
    "            Sse_perf_diff_oo.append(np.nan)\n",
    "        # non optout\n",
    "        subset_no = df_no[part][(df_no[part][\"difficulty\"]==diff)]\n",
    "        result_no = np.array(subset_no.discrimination_is_correct)\n",
    "        num_trials_no = len(result_no)\n",
    "        lnum_trials_no.append(num_trials_no)\n",
    "        perf_diff_no.append(100*np.sum(result_no)/num_trials_no)\n",
    "        se_perf_diff_no.append(100*np.sqrt(perf_diff_no[diff]/100 *(1-perf_diff_no[diff]/100)/num_trials_no))\n",
    "        if diff==1:\n",
    "            middle_perf_no.append(perf_diff_no[diff])\n",
    "            \n",
    "    subj_perf_diff_oo.append(perf_diff_oo)\n",
    "    Ssubj_perf_diff_oo.append(Sperf_diff_oo)\n",
    "    subj_perf_diff_no.append(perf_diff_no)\n",
    "    \n",
    "    subj_perf_oo.append(np.nanmean(perf_diff_oo))\n",
    "    Ssubj_perf_oo.append(np.nanmean(Sperf_diff_oo))\n",
    "    subj_perf_no.append(np.nanmean(perf_diff_no))\n",
    "        \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"Dperf_oo\":perf_diff_oo,\n",
    "        \"Dse_perf_oo\":se_perf_diff_oo,\n",
    "        \"Sperf_oo\":Sperf_diff_oo,\n",
    "        \"Sse_perf_oo\":Sse_perf_diff_oo,\n",
    "        \"perf_no\":perf_diff_no,\n",
    "        \"se_perf_no\":se_perf_diff_no,  \n",
    "        \"Dn_trials_oo\":lnum_trials_oo,\n",
    "        \"Sn_trials_oo\":lSnum_trials_oo,\n",
    "        \"NOn_trials\":lnum_trials_no\n",
    "    }\n",
    "    # Serializing json  \n",
    "    json_object = json.dumps(dict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(filename, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].set_ylim(-5,105)\n",
    "    ax[ind1,ind2].set_title('participante:'+str(part))\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),perf_diff_oo,yerr=se_perf_diff_oo,color='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),perf_diff_no,yerr=se_perf_diff_no,color='g',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),Sperf_diff_oo,yerr=Sse_perf_diff_oo,color='b',ls='-')\n",
    "    ax[ind1,0].set_ylabel('Performance')\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    ax[0,0].legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"participantID\":sorted_subj_data,\n",
    "    \"sessionID\":[reports['sessionID']]*(len(sorted_subj_data)),\n",
    "    \"Dsubj_perf_oo\":subj_perf_oo,\n",
    "    \"Ssubj_perf_oo\":Ssubj_perf_oo,\n",
    "    \"subj_perf_no\":subj_perf_no\n",
    "}\n",
    "# Serializing json  \n",
    "json_object = json.dumps(dict_) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_average, \"w\") as outfile: \n",
    "    outfile.write(json_object) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_perf_oo,Smean_subj_perf_oo,mean_subj_perf_no,se_subj_perf_oo,Sse_subj_perf_oo,se_subj_perf_no = [[] for _ in range(6)]\n",
    "for diff in range(3):\n",
    "    mean_subj_perf_oo.append(np.nanmean(np.array(subj_perf_diff_oo)[:,diff]))\n",
    "    Smean_subj_perf_oo.append(np.nanmean(np.array(Ssubj_perf_diff_oo)[:,diff]))\n",
    "    mean_subj_perf_no.append(np.nanmean(np.array(subj_perf_diff_no)[:,diff]))\n",
    "    se_subj_perf_oo.append(np.nanstd(np.array(subj_perf_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_perf_oo.append(np.nanstd(np.array(Ssubj_perf_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    se_subj_perf_no.append(np.nanstd(np.array(subj_perf_diff_no)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,4),mean_subj_perf_oo,se_subj_perf_oo,c='r')\n",
    "plt.errorbar(np.arange(1,4),mean_subj_perf_no,se_subj_perf_no,c='g')\n",
    "plt.errorbar(np.arange(1,4),Smean_subj_perf_oo,Sse_subj_perf_oo,c='b')\n",
    "plt.legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean perf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(subj_n_s,middle_perf_no)\n",
    "print(\"Correlation: \",r_value,\" and p value: \",p_value)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot()\n",
    "plt.plot(subj_n_s,intercept+np.array(subj_n_s)*slope,'k')\n",
    "plt.scatter(subj_n_s,middle_perf_no)\n",
    "plt.xlabel('last staircase level')\n",
    "plt.ylabel('middle diff performance')\n",
    "#plt.text(80,45,'p value:'+str(np.round(p_value,5)), ha='left', wrap=True,fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('last_staircase_middle_perf_day'+str(fday)+'_session'+str(fsession)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT vs. difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "subj_RT_oo,Ssubj_RT_oo,subj_RT_no = [[] for _ in range(3)]\n",
    "subj_RT_diff_oo,Ssubj_RT_diff_oo,subj_RT_diff_no,subj_medianRT = [[] for _ in range(4)]\n",
    "OKsubj_RT_oo,OKSsubj_RT_oo,OKsubj_RT_no = [[] for _ in range(3)]\n",
    "NOKsubj_RT_oo,NOKSsubj_RT_oo,NOKsubj_RT_no = [[] for _ in range(3)]\n",
    "for part in sorted_subj_data:\n",
    "    RT_list = list(df_no[part]['discrimination_t_keydown'])+list(Ddf_oo[part]['discrimination_t_keydown'])+list(Sdf_oo[part]['discrimination_t_keydown'])\n",
    "    medianRT = np.nanmedian(RT_list)\n",
    "    subj_medianRT.append(medianRT)\n",
    "    \n",
    "    ## non-optout trial\n",
    "    subj_RT_no.append(np.nanmedian(list(df_no[part]['discrimination_t_keydown']))/medianRT)\n",
    "    ## optout trials\n",
    "    subset_do = Ddf_oo[part][Ddf_oo[part][\"optout\"]==1]\n",
    "    subset_so = Sdf_oo[part][Sdf_oo[part][\"optout\"]==1]\n",
    "    # lists with the normalized median RT for optout trials\n",
    "    subj_RT_oo.append(np.nanmedian(list(subset_do['discrimination_t_keydown']))/medianRT)\n",
    "    Ssubj_RT_oo.append(np.nanmedian(list(subset_so['discrimination_t_keydown']))/medianRT)\n",
    "    # correct trials\n",
    "    OKsubset_no = df_no[part][(df_no[part][\"discrimination_is_correct\"]==1)]\n",
    "    OKsubset_do = Ddf_oo[part][(Ddf_oo[part][\"discrimination_is_correct\"]==1) & (Ddf_oo[part][\"optout\"]==0)]\n",
    "    OKsubset_so = Sdf_oo[part][(Sdf_oo[part][\"discrimination_is_correct\"]==1) & (Sdf_oo[part][\"optout\"]==0)]\n",
    "    # lists with the normalized median RT for correct trials\n",
    "    OKsubj_RT_no.append(np.nanmedian(list(OKsubset_no['discrimination_t_keydown']))/medianRT)\n",
    "    OKsubj_RT_oo.append(np.nanmedian(list(OKsubset_do['discrimination_t_keydown']))/medianRT)\n",
    "    OKSsubj_RT_oo.append(np.nanmedian(list(OKsubset_so['discrimination_t_keydown']))/medianRT)\n",
    "    # incorrect trials\n",
    "    NOKsubset_no = df_no[part][(df_no[part][\"discrimination_is_correct\"]==0)]\n",
    "    NOKsubset_do = Ddf_oo[part][(Ddf_oo[part][\"discrimination_is_correct\"]==0) & (Ddf_oo[part][\"optout\"]==0)]\n",
    "    NOKsubset_so = Sdf_oo[part][(Sdf_oo[part][\"discrimination_is_correct\"]==0) & (Sdf_oo[part][\"optout\"]==0)]\n",
    "    # lists with the normalized median RT for incorrect trials\n",
    "    NOKsubj_RT_no.append(np.nanmedian(list(NOKsubset_no['discrimination_t_keydown']))/medianRT)\n",
    "    NOKsubj_RT_oo.append(np.nanmedian(list(NOKsubset_do['discrimination_t_keydown']))/medianRT)\n",
    "    NOKSsubj_RT_oo.append(np.nanmedian(list(NOKsubset_so['discrimination_t_keydown']))/medianRT)\n",
    "    \n",
    "    RT_diff_oo,SRT_diff_oo,RT_diff_no,RT_diff_noNOK,sd_RT_diff_oo,Ssd_RT_diff_oo,sd_RT_diff_no,sd_RT_diff_noNOK, \\\n",
    "    RT_diff_OKoo,sd_RT_diff_OKoo,SRT_diff_OKoo,Ssd_RT_diff_OKoo = [[] for _ in range(12)]\n",
    "    for diff in range(3):\n",
    "        # optout deterministic\n",
    "        subset_oo = subset_do[(subset_do[\"difficulty\"]==diff)] \n",
    "        result_oo = list(subset_oo.discrimination_is_correct)\n",
    "        num_trials_oo = len(result_oo)\n",
    "        RT_oo = list(subset_oo.discrimination_t_keydown)\n",
    "        if num_trials_oo:\n",
    "            RT_diff_oo.append(np.median(RT_oo)/medianRT)\n",
    "            sd_RT_diff_oo.append(myf.std_median(RT_oo)/medianRT)\n",
    "        else:\n",
    "            RT_diff_oo.append(np.nan)\n",
    "            sd_RT_diff_oo.append(np.nan)\n",
    "        # optout stochastic\n",
    "        Ssubset_oo = subset_so[(subset_so[\"difficulty\"]==diff)]   \n",
    "        Sresult_oo = list(Ssubset_oo.discrimination_is_correct)\n",
    "        Snum_trials_oo = len(Sresult_oo)\n",
    "        SRT_oo = list(Ssubset_oo.discrimination_t_keydown)\n",
    "        if Snum_trials_oo:\n",
    "            SRT_diff_oo.append(np.median(SRT_oo)/medianRT)\n",
    "            Ssd_RT_diff_oo.append(myf.std_median(SRT_oo)/medianRT)\n",
    "        else: \n",
    "            SRT_diff_oo.append(np.nan)\n",
    "            Ssd_RT_diff_oo.append(np.nan)\n",
    "        # correct deterministic\n",
    "        subset_OKoo = OKsubset_do[(OKsubset_do[\"difficulty\"]==diff)] \n",
    "        result_OKoo = list(subset_OKoo.discrimination_is_correct)\n",
    "        num_trials_OKoo = len(result_OKoo)\n",
    "        RT_OKoo = list(subset_OKoo.discrimination_t_keydown)\n",
    "        if num_trials_OKoo:\n",
    "            RT_diff_OKoo.append(np.median(RT_OKoo)/medianRT)\n",
    "            sd_RT_diff_OKoo.append(myf.std_median(RT_OKoo)/medianRT)\n",
    "        else:\n",
    "            RT_diff_OKoo.append(np.nan)\n",
    "            sd_RT_diff_OKoo.append(np.nan)\n",
    "        # correct stochastic\n",
    "        Ssubset_OKoo = OKsubset_so[(OKsubset_so[\"difficulty\"]==diff)]   \n",
    "        Sresult_OKoo = list(Ssubset_OKoo.discrimination_is_correct)\n",
    "        Snum_trials_OKoo = len(Sresult_OKoo)\n",
    "        SRT_OKoo = list(Ssubset_OKoo.discrimination_t_keydown)\n",
    "        if Snum_trials_OKoo:\n",
    "            SRT_diff_OKoo.append(np.median(SRT_OKoo)/medianRT)\n",
    "            Ssd_RT_diff_OKoo.append(myf.std_median(SRT_OKoo)/medianRT)\n",
    "        else: \n",
    "            SRT_diff_OKoo.append(np.nan)\n",
    "            Ssd_RT_diff_OKoo.append(np.nan)\n",
    "        # non optout correct\n",
    "        subset_no = OKsubset_no[(OKsubset_no[\"difficulty\"]==diff)]\n",
    "        result_no = list(subset_no.discrimination_is_correct)\n",
    "        num_trials_no = len(result_no)\n",
    "        RT_no = list(subset_no.discrimination_t_keydown)\n",
    "        RT_diff_no.append(np.median(RT_no)/medianRT)\n",
    "        sd_RT_diff_no.append(myf.std_median(RT_no)/medianRT)\n",
    "        # non optout incorrect\n",
    "        subset_noNOK = NOKsubset_no[(NOKsubset_no[\"difficulty\"]==diff)]\n",
    "        #result_noNOK = list(subset_noNOK.discrimination_is_correct)\n",
    "        #num_trials_noNOK = len(result_noNOK)\n",
    "        RT_noNOK = list(subset_noNOK.discrimination_t_keydown)\n",
    "        RT_diff_noNOK.append(np.median(RT_noNOK)/medianRT)\n",
    "        sd_RT_diff_noNOK.append(myf.std_median(RT_noNOK)/medianRT)\n",
    "        \n",
    "    subj_RT_diff_oo.append(RT_diff_oo)\n",
    "    Ssubj_RT_diff_oo.append(SRT_diff_oo)\n",
    "    subj_RT_diff_no.append(RT_diff_no)\n",
    "      \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"DRT_oo\": RT_diff_oo,\n",
    "        \"DsdRT_oo\" : sd_RT_diff_oo,\n",
    "        \"SRT_oo\": SRT_diff_oo,\n",
    "        \"SsdRT_oo\" : Ssd_RT_diff_oo,\n",
    "        \"DRT_OKoo\": RT_diff_OKoo,\n",
    "        \"DsdRT_OKoo\" : sd_RT_diff_OKoo,\n",
    "        \"SRT_OKoo\": SRT_diff_OKoo,\n",
    "        \"SsdRT_OKoo\" : Ssd_RT_diff_OKoo,\n",
    "        \"RT_no\": RT_diff_no,\n",
    "        \"sdRT_no\" : sd_RT_diff_no, \n",
    "        \"RT_noNOK\": RT_diff_noNOK,\n",
    "        \"sdRT_noNOK\" : sd_RT_diff_noNOK \n",
    "    }\n",
    "    \n",
    "    # append to the dictionary in the existing file\n",
    "    with open(filename) as outfile:\n",
    "        old_data = json.load(outfile)\n",
    "    old_data.update(dict_)\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(old_data, outfile)\n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),RT_diff_oo,yerr=sd_RT_diff_oo,c='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),RT_diff_no,yerr=sd_RT_diff_no,c='g',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),SRT_diff_oo,yerr=Ssd_RT_diff_oo,c='b',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),RT_diff_noNOK,yerr=sd_RT_diff_noNOK,c='m',ls='-')\n",
    "    ax[ind1,0].set_ylabel('median RT (ms)')\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    ax[0,0].legend((\"DO optout\",\" correct non-optout\",\"SO optout\",\"incorrect non-optout\"),loc='best', shadow=True)\n",
    "    ax[ind1,ind2].set_ylim(0,2)\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"subj_RT_no\":subj_RT_no,\n",
    "    \"Dsubj_RT_oo\":subj_RT_oo,\n",
    "    \"Ssubj_RT_oo\":Ssubj_RT_oo,\n",
    "    \"OKubj_RT_no\":OKsubj_RT_no,\n",
    "    \"OKDsubj_RT_oo\":OKsubj_RT_oo,\n",
    "    \"OKSsubj_RT_oo\":OKSsubj_RT_oo,\n",
    "    \"NOKubj_RT_no\":NOKsubj_RT_no,\n",
    "    \"NOKDsubj_RT_oo\":NOKsubj_RT_oo,\n",
    "    \"NOKSsubj_RT_oo\":NOKSsubj_RT_oo,\n",
    "    \"medianRT\":subj_medianRT\n",
    "}\n",
    "\n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_RT_oo,Smean_subj_RT_oo,mean_subj_RT_no,se_subj_RT_oo,Sse_subj_RT_oo,se_subj_RT_no = [[] for _ in range(6)]\n",
    "for diff in range(3):\n",
    "    mean_subj_RT_oo.append(np.nanmean(np.array(subj_RT_diff_oo)[:,diff]))\n",
    "    Smean_subj_RT_oo.append(np.nanmean(np.array(Ssubj_RT_diff_oo)[:,diff]))\n",
    "    mean_subj_RT_no.append(np.nanmean(np.array(subj_RT_diff_no)[:,diff]))\n",
    "    se_subj_RT_oo.append(np.nanstd(np.array(subj_RT_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_RT_oo.append(np.nanstd(np.array(Ssubj_RT_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    se_subj_RT_no.append(np.nanstd(np.array(subj_RT_diff_no)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,4),mean_subj_RT_oo,se_subj_RT_oo,c='r')\n",
    "plt.errorbar(np.arange(1,4),mean_subj_RT_no,se_subj_RT_no,c='g')\n",
    "plt.errorbar(np.arange(1,4),Smean_subj_RT_oo,Sse_subj_RT_oo,c='b')\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean RT')\n",
    "plt.legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optout vs. difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "subj_optout_oo,Ssubj_optout_oo = [],[]\n",
    "subj_optout_diff_oo,Ssubj_optout_diff_oo = [],[]\n",
    "for part in sorted_subj_data:\n",
    "    optout_diff,Soptout_diff,se_optout_diff,Sse_optout_diff = [[] for _ in range(4)]\n",
    "    for diff in range(3):\n",
    "        # optout deterministic\n",
    "        subset_oob = Ddf_oo[part][(Ddf_oo[part][\"difficulty\"]==diff)]\n",
    "        oo_list = list(subset_oob.optout)\n",
    "        num_trials_oob = len(oo_list)\n",
    "        optout_diff.append(100*(np.sum(oo_list)/num_trials_oob))\n",
    "        se_optout_diff.append(100*np.sqrt(optout_diff[diff]/100 *(1-optout_diff[diff]/100)/num_trials_oob))\n",
    "        # optout stochastic\n",
    "        Ssubset_oob = Sdf_oo[part][(Sdf_oo[part][\"difficulty\"]==diff)]\n",
    "        Soo_list = list(Ssubset_oob.optout)\n",
    "        Snum_trials_oob = len(Soo_list)\n",
    "        Soptout_diff.append(100*(np.sum(Soo_list)/Snum_trials_oob))\n",
    "        Sse_optout_diff.append(100*np.sqrt(Soptout_diff[diff]/100 *(1-Soptout_diff[diff]/100)/Snum_trials_oob))\n",
    "\n",
    "    subj_optout_diff_oo.append(optout_diff)\n",
    "    Ssubj_optout_diff_oo.append(Soptout_diff)\n",
    "    \n",
    "    subj_optout_oo.append(np.nanmean(optout_diff))\n",
    "    Ssubj_optout_oo.append(np.nanmean(Soptout_diff))\n",
    "    \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"Doptout\" : optout_diff,\n",
    "        \"Dse_optout\" : se_optout_diff,\n",
    "        \"Soptout\" : Soptout_diff,\n",
    "        \"Sse_optout\" : Sse_optout_diff    \n",
    "    }\n",
    "    # append to the dictionary in the existing file\n",
    "    # append to the dictionary in the existing file\n",
    "    with open(filename) as outfile:\n",
    "        old_data = json.load(outfile)\n",
    "    old_data.update(dict_)\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(old_data, outfile)\n",
    "        \n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].set_ylim(-5,105)\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),optout_diff,yerr=se_optout_diff,color='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,4),Soptout_diff,yerr=Sse_optout_diff,color='b',ls='-')\n",
    "    ax[ind1,0].set_ylabel('Optout')\n",
    "    ax[5,ind2].set_xlabel('Difficulty')\n",
    "    ax[0,0].legend((\"DO optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,4))\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"Dsubj_optout_oo\" : subj_optout_oo,\n",
    "    \"Ssubj_optout_oo\" : Ssubj_optout_oo  \n",
    "}\n",
    "# append to the dictionary in the existing file\n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_optout_oo,Smean_subj_optout_oo,se_subj_optout_oo,Sse_subj_optout_oo = [[] for _ in range(4)]\n",
    "for diff in range(3):\n",
    "    mean_subj_optout_oo.append(np.nanmean(np.array(subj_optout_diff_oo)[:,diff]))\n",
    "    Smean_subj_optout_oo.append(np.nanmean(np.array(Ssubj_optout_diff_oo)[:,diff]))\n",
    "    se_subj_optout_oo.append(np.nanstd(np.array(subj_optout_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_optout_oo.append(np.nanstd(np.array(Ssubj_optout_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,4),mean_subj_optout_oo,se_subj_optout_oo,c='r')\n",
    "plt.errorbar(np.arange(1,4),Smean_subj_optout_oo,Sse_subj_optout_oo,c='b')\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean optout')\n",
    "plt.legend((\"DO optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psychometric curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON-optout psychometric curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "for part in sorted_subj_data:\n",
    "\n",
    "    # threshold value set up with the staircase procedure\n",
    "    n_s = Cdf[part].loc[59].at['noise']\n",
    "    # load list with the signed strenght stimuli\n",
    "    st_no = list(df_no[part]['signed_stim'])\n",
    "    # stim axis\n",
    "    unique_stim = df_no[part]['signed_stim'].unique()\n",
    "    signed_st = sorted(unique_stim)\n",
    "    # load data\n",
    "    diff_no = list(df_no[part]['difficulty'])\n",
    "    orientation_no = list(df_no[part]['orientation'])\n",
    "    correct_no = list(df_no[part]['discrimination_is_correct'])\n",
    "    is_right_no = np.array(list(df_no[part]['resp_is_R']))\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    m_right_No, se_right_No = np.zeros(len(signed_st)),np.zeros(len(signed_st))\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    y_no = is_right_no.astype(int)  \n",
    "    # mean performance (%) over all the stim for each task\n",
    "    mean_perf_no = np.nanmean(correct_no)*100\n",
    "\n",
    "    for st in range(len(signed_st)):\n",
    "        mask_st = (st_no==signed_st[st])\n",
    "        m_right_No[st] = np.nanmean(y_no[mask_st]==1)\n",
    "        n_No = np.sum(mask_st)\n",
    "        se_right_No[st]= np.sqrt(m_right_No[st]*(1-m_right_No[st])/n_No)   \n",
    "\n",
    "    # reshape of stimuli arrays for the logistic regression\n",
    "    st_no = np.array(st_no).reshape(-1,1)\n",
    "    # add a column of ones to the stimuli arrays for the logistic regression\n",
    "    x_no = [[1,elem[0]] for elem in st_no]\n",
    "    # lists with beta resulting values of the fit for each type of trials in this \n",
    "    # particular session and for this particular participant\n",
    "    betas_no = []\n",
    "    # fitted curves\n",
    "    x_lr = np.arange(-1,1.1,0.1)\n",
    "    \n",
    "    ### wih logistic regression...\n",
    "    # y_lr_no = []\n",
    "    #lr_no = LogisticRegression(C=1000000, fit_intercept=False)\n",
    "    #lr_no.fit(x_no, y_no)\n",
    "    #betas_no = lr_no.coef_[0]\n",
    "    #score_no = np.round(lr_no.score(x_no, y_no),3)\n",
    "    # sigma: standard deviation of the internal response (with non optout)\n",
    "    # Hno: decision boundary in the non optout trials\n",
    "    #Sigma = 1/betas_no[1]\n",
    "    #Hno = -betas_no[0]*Sigma\n",
    "    #y_lr_no=myf.sigmoid(betas_no[0]+x_lr*betas_no[1])\n",
    "    #yRfit = myf.sigmoid(betas_no[0]+np.array(signed_st)*betas_no[1])\n",
    "    \n",
    "    # with probit regression...\n",
    "    if not np.array_equal(m_right_No,np.array([0., 0., 0., 1., 1., 1.])):\n",
    "        pb_no = smf.glm(formula='resp_is_R ~ signed_stim', \n",
    "                    family=sm.families.Binomial(link = sm.genmod.families.links.probit),\n",
    "                    data=df_no[part]).fit()\n",
    "        params = pb_no.params\n",
    "        Hno = -params[0]/params[1]\n",
    "        Sigma = 1/params[1]\n",
    "        y_pr_no = [stats.norm.cdf((x-Hno)/Sigma) for x in x_lr]\n",
    "        yRfit = [stats.norm.cdf((x-Hno)/Sigma) for x in signed_st]\n",
    "        mse_no=myf.MSE_no(m_right_No,yRfit)\n",
    "        pearson_chi2=pb_no.pearson_chi2\n",
    "    else:\n",
    "        Hno = 0\n",
    "        Sigma = 0.00001\n",
    "        y_pr_no = [stats.norm.cdf((x-Hno)/Sigma) for x in x_lr]\n",
    "        yRfit = [stats.norm.cdf((x-Hno)/Sigma) for x in signed_st]\n",
    "        mse_no=myf.MSE_no(m_right_No,yRfit)\n",
    "        pearson_chi2='non-valid'       \n",
    "   \n",
    "    # write the result in file\n",
    "    filename=path_fit+'NO_fit_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    '''\n",
    "    if excluded_no!=0:\n",
    "        in_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        in_or_out = 'OK'\n",
    "    '''\n",
    "    dict_ = {\n",
    "        \"Hno\":Hno,\n",
    "        \"Sigma\":Sigma,\n",
    "        \"signed_st\":list(signed_st),\n",
    "        \"m_right_No\":list(m_right_No),\n",
    "        \"se_right_No\":list(se_right_No),\n",
    "        \"x_lr\":list(x_lr),\n",
    "        \"y_pr_no\":list(y_pr_no),\n",
    "        \"pearson_chi2\":pearson_chi2,\n",
    "        \"mean_perf_no\":mean_perf_no,\n",
    "        \"mse_no\":mse_no\n",
    "    }\n",
    "    # Serializing json  \n",
    "    json_object = json.dumps(dict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(filename, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "# npn-optout\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "# plot\n",
    "# NO PC fit\n",
    "NOfit_files = [f for f in os.listdir(path_fit) if f.startswith('NO_fit')]\n",
    "auxNO = [f.replace('NO_fit_Sub','') for f in NOfit_files]\n",
    "subj_NOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in auxNO]\n",
    "sorted_subj_NOfit = sorted(subj_NOfit)\n",
    "index_subj_NOfit = [subj_NOfit.index(elem) for elem in sorted_subj_NOfit]\n",
    "sorted_NOfit_files = [NOfit_files[i] for i in index_subj_NOfit]\n",
    "\n",
    "for part in sorted_subj_data:\n",
    "    # psychometric curve NON-optout\n",
    "    fNO = sorted_NOfit_files[ind]\n",
    "    filename=path_fit+fNO\n",
    "    with open(filename) as fNO:\n",
    "        dataNO = json.load(fNO)\n",
    "    for k, v in dataNO.items():\n",
    "        globals()[k]=v     \n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].set_title(\"Participant \"+str(part))\n",
    "    #ax[ind1,ind2].text(0.1, 0.2, 'pearson_chi2='+str(round(pearson_chi2,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(0.1, 0.3, 'sigma='+str(round(Sigma,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].errorbar(signed_st,m_right_No,se_right_No,c='g',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_lr,y_pr_no,c='g')\n",
    "    ax[0,0].legend((\"log-reg\",\"NG NO\"),loc='best', shadow=True)\n",
    "    ax[5,ind2].set_xlabel('signed differential energy')\n",
    "    ax[ind1,0].set_ylabel('proportion of right')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.51,0.51])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(Hno,color='g',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "    ax[ind1,ind2].text(0.1, 0.4,'mean perf:'+str(np.round(mean_perf_no)), ha='left', wrap=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic optout psychometric curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dlist2change = np.load(path_fit+'/DO_sub2changeFit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dlist2change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO not run again \n",
    "# this script change the fit from logistic to probit in DO trials where participants did not chose the optout\n",
    "x_fit=np.linspace(-0.2,0.2,200)\n",
    "\n",
    "for part in Dlist2change:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Dst_oo = np.array(list(Ddf_oo[part]['signed_stim']))\n",
    "    # stim axis\n",
    "    Dunique_stim = Ddf_oo[part]['signed_stim'].unique()\n",
    "    Dsigned_st = np.array(sorted(Dunique_stim))\n",
    "    # load data\n",
    "    Ddiff_oo = list(Ddf_oo[part]['difficulty'])\n",
    "    Dorientation_oo = list(Ddf_oo[part]['orientation'])\n",
    "    Dcorrect_oo = np.array(list(Ddf_oo[part]['discrimination_is_correct']))\n",
    "    Dis_right_oo = np.array(list(Ddf_oo[part]['resp_is_R']))\n",
    "    D_oo= list(Ddf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Dm_right_oo, Dse_right_oo = np.zeros(len(Dsigned_st)),np.zeros(len(Dsigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Dy_oo = np.array(list(Ddf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Dmask_ = (Dy_oo!=2)\n",
    "    Dmean_perf_oo = np.nanmean(Dcorrect_oo[Dmask_])*100\n",
    "    Dmean_oo = np.nanmean(D_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Dm_right_oob,Dse_right_oob,Dm_left_oob,Dse_left_oob,Dm_opt_oob,Dse_opt_oob = [np.zeros(len(Dsigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Dsigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Dmask_oob = (Dst_oo==Dsigned_st[st])\n",
    "        # rightward\n",
    "        Dm_right_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==1)\n",
    "        Dn_oob = np.sum(Dmask_oob)\n",
    "        Dse_right_oob[st]= np.sqrt(Dm_right_oob[st]*(1-Dm_right_oob[st])/Dn_oob)\n",
    "        # leftward\n",
    "        Dm_left_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==0)\n",
    "        Dse_left_oob[st]= np.sqrt(Dm_left_oob[st]*(1-Dm_left_oob[st])/Dn_oob)\n",
    "        # optout\n",
    "        Dm_opt_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==2)\n",
    "        Dse_opt_oob[st]= np.sqrt(Dm_opt_oob[st]*(1-Dm_opt_oob[st])/Dn_oob)\n",
    "    n=Dst_oo.size\n",
    "\n",
    "    ## Psychometric fit               \n",
    "    Dmask_oob2 = (Dy_oo!=2)\n",
    "    # lists instead of arrays because have variable length in optout trials \n",
    "    Dst_oo = Dst_oo[Dmask_oob2]\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    Dy_oo=Dy_oo[Dmask_oob2]\n",
    "\n",
    "    Dresult = myf.fit_oo_binomial('signed_stim','resp_is_R',Ddf_oo[part])\n",
    "    DHR_oo=Dresult[0][0]\n",
    "    DHL_oo=Dresult[0][1]\n",
    "    Dsigma_oo=Dresult[0][2]\n",
    "    Dexito=Dresult[1]\n",
    "\n",
    "    # with logistic regression...\n",
    "    '''\n",
    "    Dbeta0 = -DHR_oo/Dsigma_oo\n",
    "    Dbeta1 = 1/Dsigma_oo\n",
    "    DyR_fit=myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "    DyL_fit=1.0-myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "    DyR_fit_stim=myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "    DyL_fit_stim=1.0-myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "    '''\n",
    "\n",
    "    # with probit regression...\n",
    "    DyR_fit=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit]\n",
    "    DyL_fit=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit])\n",
    "    DyO_fit=np.zeros(len(x_fit))   \n",
    "    # fit result  over the stimuli values\n",
    "    DyR_fit_stim=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st]\n",
    "    DyL_fit_stim=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st])\n",
    "    DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "    \n",
    "    # mean squared error\n",
    "    Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "    DFit = 0\n",
    "    Dexcluded_oo=0    \n",
    "    \n",
    "    filename = 'DO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    with open(path_fit+filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data[\"DHR_oo\"]=DHR_oo\n",
    "        data[\"DHL_oo\"]=DHL_oo\n",
    "        data[\"Dsigma_oo\"]=Dsigma_oo\n",
    "        data[\"DyR_fit\"]=list(DyR_fit)\n",
    "        data[\"DyL_fit\"]=list(DyL_fit)\n",
    "        data[\"DyR_fit_stim\"]=list(DyR_fit_stim)\n",
    "        data[\"DyL_fit_stim\"]=list(DyL_fit_stim)\n",
    "        data[\"Dmse\"]=Dmse\n",
    "        data[\"Dexito\"]=Dexito\n",
    "     \n",
    "    with open(path_fit+filename,\"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN AGAIN\n",
    "\n",
    "# deterministic optout\n",
    "x_fit=np.linspace(-1,1,200)\n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Dst_oo = np.array(list(Ddf_oo[part]['signed_stim']))\n",
    "    # stim axis\n",
    "    Dunique_stim = Ddf_oo[part]['signed_stim'].unique()\n",
    "    Dsigned_st = np.array(sorted(Dunique_stim))\n",
    "    # load data\n",
    "    Ddiff_oo = list(Ddf_oo[part]['difficulty'])\n",
    "    Dorientation_oo = list(Ddf_oo[part]['orientation'])\n",
    "    Dcorrect_oo = np.array(list(Ddf_oo[part]['discrimination_is_correct']))\n",
    "    Dis_right_oo = np.array(list(Ddf_oo[part]['resp_is_R']))\n",
    "    D_oo= list(Ddf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Dm_right_oo, Dse_right_oo = np.zeros(len(Dsigned_st)),np.zeros(len(Dsigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Dy_oo = np.array(list(Ddf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Dmask_ = (Dy_oo!=2)\n",
    "    Dmean_perf_oo = np.nanmean(Dcorrect_oo[Dmask_])*100\n",
    "    Dmean_oo = np.nanmean(D_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Dm_right_oob,Dse_right_oob,Dm_left_oob,Dse_left_oob,Dm_opt_oob,Dse_opt_oob = [np.zeros(len(Dsigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Dsigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Dmask_oob = (Dst_oo==Dsigned_st[st])\n",
    "        # rightward\n",
    "        Dm_right_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==1)\n",
    "        Dn_oob = np.sum(Dmask_oob)\n",
    "        Dse_right_oob[st]= np.sqrt(Dm_right_oob[st]*(1-Dm_right_oob[st])/Dn_oob)\n",
    "        # leftward\n",
    "        Dm_left_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==0)\n",
    "        Dse_left_oob[st]= np.sqrt(Dm_left_oob[st]*(1-Dm_left_oob[st])/Dn_oob)\n",
    "        # optout\n",
    "        Dm_opt_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==2)\n",
    "        Dse_opt_oob[st]= np.sqrt(Dm_opt_oob[st]*(1-Dm_opt_oob[st])/Dn_oob)\n",
    "    n=np.sum(Dst_oo)\n",
    "\n",
    "    ## Psychometric fit\n",
    "    # Exclusion criterion: mean performance higher than 80% and \n",
    "    # mean optout election less than 80%\n",
    "    if Dmean_perf_oo>0 and Dmean_oo<100: \n",
    "        # Binomial fit: excluding the optout \n",
    "        if Dmean_oo<1:                   \n",
    "            Dmask_oob2 = (Dy_oo!=2)\n",
    "            # lists instead of arrays because have variable length in optout trials \n",
    "            Dst_oo = Dst_oo[Dmask_oob2]\n",
    "            # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "            Dy_oo=Dy_oo[Dmask_oob2]\n",
    "\n",
    "            Dresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Ddf_oo[part])\n",
    "            DHR_oo=Dresult[0][0]\n",
    "            DHL_oo=Dresult[0][1]\n",
    "            Dsigma_oo=Dresult[0][2]\n",
    "            Dexito=Dresult[1]\n",
    "\n",
    "            # with logistic regression...\n",
    "            '''\n",
    "            Dbeta0 = -DHR_oo/Dsigma_oo\n",
    "            Dbeta1 = 1/Dsigma_oo\n",
    "            DyR_fit=myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "            DyL_fit=1.0-myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "            DyR_fit_stim=myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "            DyL_fit_stim=1.0-myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "            '''\n",
    "\n",
    "            # with probit regression...\n",
    "            DyR_fit=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit]\n",
    "            DyL_fit=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit])\n",
    "            DyO_fit=np.zeros(len(x_fit))   \n",
    "            # fit result  over the stimuli values\n",
    "            DyR_fit_stim=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st]\n",
    "            DyL_fit_stim=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st])\n",
    "            DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "    \n",
    "            # mean squared error\n",
    "            Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "            DFit = 0\n",
    "            Dexcluded_oo=0\n",
    "        # Multinomial fit\n",
    "        else:\n",
    "            Dresult = myf.Wrandom_fit_oo_multinomial(Dsigned_st,Dm_right_oob,Dm_left_oob,Dm_opt_oob,n)\n",
    "            DHR_oo=Dresult[0][0]\n",
    "            DHL_oo=Dresult[0][1]\n",
    "            Dsigma_oo=Dresult[0][2]\n",
    "            Dexito=Dresult[1]\n",
    "            #print('[H_R  H_L  sigma]=',Dresult[0])\n",
    "            #print('success:',Dexito)\n",
    "            DyR_fit=myf.cumul_norm(x_fit,DHR_oo,Dsigma_oo)\n",
    "            DyL_fit=1.0-myf.cumul_norm(x_fit,DHL_oo,Dsigma_oo)\n",
    "            DyO_fit=1.0-DyR_fit-DyL_fit  \n",
    "            # fit result  over the stimuli values\n",
    "            DyR_fit_stim=myf.cumul_norm(Dsigned_st,DHR_oo,Dsigma_oo)\n",
    "            DyL_fit_stim=1.0-myf.cumul_norm(Dsigned_st,DHL_oo,Dsigma_oo)\n",
    "            DyO_fit_stim=1.0-DyR_fit_stim-DyL_fit_stim\n",
    "            # mean squared error\n",
    "            Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "            DFit = 1\n",
    "            Dexcluded_oo=0\n",
    "    elif Dmean_perf_oo<=0:\n",
    "        DyR_fit=np.zeros(len(x_fit))\n",
    "        DyL_fit=np.zeros(len(x_fit))\n",
    "        DyO_fit=np.zeros(len(x_fit))\n",
    "        # fit result  over the stimuli values\n",
    "        DyR_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyL_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        Dmse = m.nan\n",
    "        DHR_oo=1000000\n",
    "        DHL_oo=-1000000\n",
    "        Dsigma_oo=0\n",
    "        Dexito = False\n",
    "        Dexcluded_oo=1\n",
    "        DFit = 2\n",
    "    elif Dmean_oo>=100:\n",
    "        DyR_fit=np.zeros(len(x_fit))\n",
    "        DyL_fit=np.zeros(len(x_fit))\n",
    "        DyO_fit=np.ones(len(x_fit))\n",
    "        DHR_oo=1000000\n",
    "        DHL_oo=-1000000\n",
    "        Dsigma_oo=0\n",
    "        # fit result  over the stimuli values\n",
    "        DyR_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyL_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyO_fit_stim=np.ones(len(Dsigned_st))\n",
    "        Dexito = False\n",
    "        Dmse = m.nan\n",
    "        DFit = 3\n",
    "        Dexcluded_oo=1\n",
    "        \n",
    "    # write the result in file\n",
    "    Dfilename=path_fit+'DO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    if Dexcluded_oo!=0:\n",
    "        in_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        in_or_out = 'OK'\n",
    "    Ddict_ = {\n",
    "        \"in_or_out\":in_or_out,\n",
    "        \"DHR_oo\":DHR_oo,\n",
    "        \"DHL_oo\":DHL_oo,\n",
    "        \"Dsigma_oo\":Dsigma_oo,\n",
    "        \"Dsigned_st\":list(Dsigned_st),\n",
    "        \"Dm_right_oob\":list(Dm_right_oob),\n",
    "        \"Dm_left_oob\":list(Dm_left_oob),\n",
    "        \"Dm_opt_oob\":list(Dm_opt_oob),\n",
    "        \"Dse_right_oob\":list(Dse_right_oob),\n",
    "        \"Dse_left_oob\":list(Dse_left_oob),\n",
    "        \"Dse_opt_oob\":list(Dse_opt_oob),\n",
    "        \"x_fit\":list(x_fit),\n",
    "        \"DyR_fit\":list(DyR_fit),\n",
    "        \"DyL_fit\":list(DyL_fit),\n",
    "        \"DyO_fit\":list(DyO_fit),\n",
    "        \"DyR_fit_stim\":list(DyR_fit_stim),\n",
    "        \"DyL_fit_stim\":list(DyL_fit_stim),\n",
    "        \"DyO_fit_stim\":list(DyO_fit_stim),\n",
    "        \"n\":int(n),\n",
    "        \"Dmse\":Dmse,\n",
    "        \"Dexito\":Dexito,\n",
    "        \"Dmean_perf_oo\":Dmean_perf_oo,\n",
    "        \"Dmean_oo\":Dmean_oo,\n",
    "        \"DFit\":DFit\n",
    "    }\n",
    "    # Serializing json  \n",
    "    Djson_object = json.dumps(Ddict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(Dfilename, \"w\") as outfile: \n",
    "        outfile.write(Djson_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# Deterministic PC fit\n",
    "DOfit_files = [f for f in os.listdir(path_fit) if f.startswith('DO_fit')]\n",
    "aux = [f.replace('DO_fit_oo_Sub','') for f in DOfit_files]\n",
    "subj_DOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in aux]\n",
    "sorted_subj_DOfit = sorted(subj_DOfit)\n",
    "index_subj_DOfit = [subj_DOfit.index(elem) for elem in sorted_subj_DOfit]\n",
    "sorted_DOfit_files = [DOfit_files[i] for i in index_subj_DOfit]\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5)  \n",
    "for part in sorted_subj_data:\n",
    "    # deterministic PC fit\n",
    "    f = sorted_DOfit_files[ind]\n",
    "    filename=path_fit+f\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for k, v in data.items():\n",
    "        globals()[k]=v    \n",
    "    ind += 1\n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].text(-0.5, 1.0, 'mean optout ='+str(np.round(Dmean_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.9, 'mean perf ='+str(np.round(Dmean_perf_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.8, 'sigma ='+str(np.round(Dsigma_oo,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.7, 'mse ='+str(np.round(Dmse,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].set_title(\"participant \"+str(part))\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_right_oob,Dse_right_oob,c='r',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_left_oob,Dse_left_oob,c='m',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_opt_oob,Dse_opt_oob,c='g',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_fit,DyR_fit,c='r')   \n",
    "    ax[ind1,ind2].plot(x_fit,DyL_fit,c='m')\n",
    "    ax[ind1,ind2].plot(x_fit,DyO_fit,c='g')\n",
    "    ax[0,0].legend((\"DO right\",\"DO left\",\"DO opt-out\"),loc='best', shadow=True)\n",
    "    ax[5,ind2].set_xlabel('signed differential energy')\n",
    "    ax[ind1,0].set_ylabel('response proportion')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.51,0.51])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(DHR_oo,color='r',ls='--')\n",
    "    ax[ind1,ind2].axvline(DHL_oo,color='m',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic optout psychometric curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slist2change = np.load(path_fit+'SO_sub2changeFit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slist2change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit=np.linspace(-0.2,0.2,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO not run again \n",
    "# this script change the fit from logistic to probit in DO trials where participants did not chose the optout\n",
    "\n",
    "for part in Slist2change:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Sst_oo = np.array(list(Sdf_oo[part]['signed_stim']))\n",
    "    # stim axis\n",
    "    Sunique_stim = Sdf_oo[part]['signed_stim'].unique()\n",
    "    Ssigned_st = np.array(sorted(Sunique_stim))\n",
    "    # load data\n",
    "    Sdiff_oo = list(Sdf_oo[part]['difficulty'])\n",
    "    Sorientation_oo = list(Sdf_oo[part]['orientation'])\n",
    "    Scorrect_oo = np.array(list(Sdf_oo[part]['discrimination_is_correct']))\n",
    "    Sis_right_oo = np.array(list(Sdf_oo[part]['resp_is_R']))\n",
    "    S_oo= list(Sdf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Sm_right_oo, Sse_right_oo = np.zeros(len(Ssigned_st)),np.zeros(len(Ssigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Sy_oo = np.array(list(Sdf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Smask_ = (Sy_oo!=2)\n",
    "    Smean_perf_oo = np.nanmean(Scorrect_oo[Smask_])*100\n",
    "    Smean_oo = np.nanmean(S_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Sm_right_oob,Sse_right_oob,Sm_left_oob,Sse_left_oob,Sm_opt_oob,Sse_opt_oob = [np.zeros(len(Ssigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Ssigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Smask_oob = (Sst_oo==Ssigned_st[st])\n",
    "        # rightward\n",
    "        Sm_right_oob[st] = np.nanmean(Sy_oo[Smask_oob]==1)\n",
    "        Sn_oob = np.sum(Smask_oob)\n",
    "        Sse_right_oob[st]= np.sqrt(Sm_right_oob[st]*(1-Sm_right_oob[st])/Sn_oob)\n",
    "        # leftward\n",
    "        Sm_left_oob[st] = np.nanmean(Sy_oo[Smask_oob]==0)\n",
    "        Sse_left_oob[st]= np.sqrt(Sm_left_oob[st]*(1-Sm_left_oob[st])/Sn_oob)\n",
    "        # optout\n",
    "        Sm_opt_oob[st] = np.nanmean(Sy_oo[Smask_oob]==2)\n",
    "        Sse_opt_oob[st]= np.sqrt(Sm_opt_oob[st]*(1-Sm_opt_oob[st])/Sn_oob)\n",
    "    n=np.sum(Sst_oo)\n",
    "\n",
    "    ## Psychometric fit               \n",
    "    Smask_oob2 = (Sy_oo!=2)\n",
    "    # lists instead of arrays because have variable length in optout trials \n",
    "    Sst_oo = Sst_oo[Smask_oob2]\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    Sy_oo = Sy_oo[Smask_oob2]\n",
    "\n",
    "    Sresult = myf.fit_oo_binomial('signed_stim','resp_is_R',Sdf_oo[part])\n",
    "    \n",
    "    SHR_oo=Sresult[0][0]\n",
    "    SHL_oo=Sresult[0][1]\n",
    "    Ssigma_oo=Sresult[0][2]\n",
    "    Sexito=Sresult[1]\n",
    "\n",
    "    # with logistic regression...\n",
    "    '''\n",
    "    Sbeta0 = -SHR_oo/Ssigma_oo\n",
    "    Sbeta1 = 1/Ssigma_oo\n",
    "    SyR_fit=myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "    SyL_fit=1.0-myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "    SyO_fit=np.zeros(len(x_fit))\n",
    "    # fit result  over the stimuli values\n",
    "    SyR_fit_stim=myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "    SyL_fit_stim=1.0-myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "    SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "    '''\n",
    "\n",
    "    # with probit regression...\n",
    "    SyR_fit=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit]\n",
    "    SyL_fit=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit])\n",
    "    SyO_fit=np.zeros(len(x_fit))   \n",
    "    # fit result  over the stimuli values\n",
    "    SyR_fit_stim=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st]\n",
    "    SyL_fit_stim=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st])\n",
    "    SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "    \n",
    "    # mean squared error\n",
    "    Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)  \n",
    "    \n",
    "    filename = 'SO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    with open(path_fit+filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data[\"SHR_oo\"]=SHR_oo\n",
    "        data[\"SHL_oo\"]=SHL_oo\n",
    "        data[\"Ssigma_oo\"]=Ssigma_oo\n",
    "        data[\"SyR_fit\"]=list(SyR_fit)\n",
    "        data[\"SyL_fit\"]=list(SyL_fit)\n",
    "        data[\"SyR_fit_stim\"]=list(SyR_fit_stim)\n",
    "        data[\"SyL_fit_stim\"]=list(SyL_fit_stim)\n",
    "        data[\"Smse\"]=Smse\n",
    "        data[\"Sexito\"]=Sexito\n",
    "     \n",
    "    with open(path_fit+filename,\"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN!\n",
    "\n",
    "# stochastic optout \n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Sst_oo = np.array(list(Sdf_oo[part]['signed_stim']))\n",
    "    # stim axis\n",
    "    Sunique_stim = Sdf_oo[part]['signed_stim'].unique()\n",
    "    Ssigned_st = np.array(sorted(Sunique_stim))\n",
    "    # load data\n",
    "    Sdiff_oo = list(Sdf_oo[part]['difficulty'])\n",
    "    Sorientation_oo = list(Sdf_oo[part]['orientation'])\n",
    "    Scorrect_oo = np.array(list(Sdf_oo[part]['discrimination_is_correct']))\n",
    "    Sis_right_oo = np.array(list(Sdf_oo[part]['resp_is_R']))\n",
    "    S_oo= list(Sdf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Sm_right_oo, Sse_right_oo = np.zeros(len(Ssigned_st)),np.zeros(len(Ssigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Sy_oo = np.array(list(Sdf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Smask_ = (Sy_oo!=2)\n",
    "    Smean_perf_oo = np.nanmean(Scorrect_oo[Smask_])*100\n",
    "    Smean_oo = np.nanmean(S_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Sm_right_oob,Sse_right_oob,Sm_left_oob,Sse_left_oob,Sm_opt_oob,Sse_opt_oob = [np.zeros(len(Ssigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Ssigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Smask_oob = (Sst_oo==Ssigned_st[st])\n",
    "        # rightward\n",
    "        Sm_right_oob[st] = np.nanmean(Sy_oo[Smask_oob]==1)\n",
    "        Sn_oob = np.sum(Smask_oob)\n",
    "        Sse_right_oob[st]= np.sqrt(Sm_right_oob[st]*(1-Sm_right_oob[st])/Sn_oob)\n",
    "        # leftward\n",
    "        Sm_left_oob[st] = np.nanmean(Sy_oo[Smask_oob]==0)\n",
    "        Sse_left_oob[st]= np.sqrt(Sm_left_oob[st]*(1-Sm_left_oob[st])/Sn_oob)\n",
    "        # optout\n",
    "        Sm_opt_oob[st] = np.nanmean(Sy_oo[Smask_oob]==2)\n",
    "        Sse_opt_oob[st]= np.sqrt(Sm_opt_oob[st]*(1-Sm_opt_oob[st])/Sn_oob)\n",
    "    n=np.sum(Sst_oo)\n",
    "\n",
    "    ## Psychometric fit\n",
    "    # Exclusion criterion: mean performance higher than 80% and \n",
    "    # mean optout election less than 80%\n",
    "    if Smean_perf_oo>0 and Smean_oo<100: \n",
    "        # Binomial fit: excluding the optout \n",
    "        if Smean_oo<1:                   \n",
    "            Smask_oob2 = (Sy_oo!=2)\n",
    "            # lists instead of arrays because have variable length in optout trials \n",
    "            Sst_oo = Sst_oo[Smask_oob2]\n",
    "            # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "            Sy_oo = Sy_oo[Smask_oob2]\n",
    "\n",
    "            Sresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Sdf_oo[part])\n",
    "\n",
    "            SHR_oo=Sresult[0][0]\n",
    "            SHL_oo=Sresult[0][1]\n",
    "            Ssigma_oo=Sresult[0][2]\n",
    "            Sexito=Sresult[1]\n",
    "\n",
    "            # with logistic regression...\n",
    "            '''\n",
    "            Sbeta0 = -SHR_oo/Ssigma_oo\n",
    "            Sbeta1 = 1/Ssigma_oo\n",
    "            SyR_fit=myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "            SyL_fit=1.0-myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "            SyO_fit=np.zeros(len(x_fit))\n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "            SyL_fit_stim=1.0-myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "            SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "            '''\n",
    "\n",
    "            # with probit regression...\n",
    "            SyR_fit=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit]\n",
    "            SyL_fit=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit])\n",
    "            SyO_fit=np.zeros(len(x_fit))   \n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st]\n",
    "            SyL_fit_stim=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st])\n",
    "            SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "            \n",
    "            # mean squared error\n",
    "            Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)\n",
    "            SFit = 0\n",
    "            Sexcluded_oo=0\n",
    "        # Multinomial fit\n",
    "        else:\n",
    "            Sresult = myf.Wrandom_fit_oo_multinomial(Ssigned_st,Sm_right_oob,Sm_left_oob,Sm_opt_oob,n)\n",
    "            SHR_oo=Sresult[0][0]\n",
    "            SHL_oo=Sresult[0][1]\n",
    "            Ssigma_oo=Sresult[0][2]\n",
    "            Sexito=Sresult[1]\n",
    "            #print('[H_R  H_L  sigma]=',Sresult[0])\n",
    "            #print('success:',Sexito)\n",
    "            SyR_fit=cumul_norm(x_fit,SHR_oo,Ssigma_oo)\n",
    "            SyL_fit=1.0-cumul_norm(x_fit,SHL_oo,Ssigma_oo)\n",
    "            SyO_fit=1.0-SyR_fit-SyL_fit  \n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=cumul_norm(Ssigned_st,SHR_oo,Ssigma_oo)\n",
    "            SyL_fit_stim=1.0-cumul_norm(Ssigned_st,SHL_oo,Ssigma_oo)\n",
    "            SyO_fit_stim=1.0-SyR_fit_stim-SyL_fit_stim\n",
    "            # mean squared error\n",
    "            Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)\n",
    "            SFit = 1\n",
    "            Sexcluded_oo=0\n",
    "    elif Smean_perf_oo<=0:\n",
    "        SyR_fit=np.zeros(len(x_fit))\n",
    "        SyL_fit=np.zeros(len(x_fit))\n",
    "        SyO_fit=np.zeros(len(x_fit))\n",
    "        # fit result  over the stimuli values\n",
    "        SyR_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyL_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        Smse = m.nan\n",
    "        SHR_oo=1000000\n",
    "        SHL_oo=-1000000\n",
    "        Ssigma_oo=0\n",
    "        Sexito = False\n",
    "        Sexcluded_oo=1\n",
    "        SFit = 2\n",
    "    elif Smean_oo>=100:\n",
    "        SyR_fit=np.zeros(len(x_fit))\n",
    "        SyL_fit=np.zeros(len(x_fit))\n",
    "        SyO_fit=np.ones(len(x_fit))\n",
    "        SHR_oo=1000000\n",
    "        SHL_oo=-1000000\n",
    "        Sexito = False\n",
    "        Ssigma_oo=0\n",
    "        # fit result  over the stimuli values\n",
    "        SyR_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyL_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyO_fit_stim=np.ones(len(Ssigned_st))\n",
    "        Smse = m.nan\n",
    "        SFit = 3\n",
    "        Sexcluded_oo=1\n",
    "\n",
    "    # write the result in file\n",
    "    Sfilename=path_fit+'SO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    if Sexcluded_oo!=0:\n",
    "        Sin_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        Sin_or_out = 'OK'\n",
    "    Sdict_ = {\n",
    "        \"Sin_or_out\":Sin_or_out,\n",
    "        \"SHR_oo\":SHR_oo,\n",
    "        \"SHL_oo\":SHL_oo,\n",
    "        \"Ssigma_oo\":Ssigma_oo,\n",
    "        \"Ssigned_st\":list(Ssigned_st),\n",
    "        \"Sm_right_oob\":list(Sm_right_oob),\n",
    "        \"Sm_left_oob\":list(Sm_left_oob),\n",
    "        \"Sm_opt_oob\":list(Sm_opt_oob),\n",
    "        \"Sse_right_oob\":list(Sse_right_oob),\n",
    "        \"Sse_left_oob\":list(Sse_left_oob),\n",
    "        \"Sse_opt_oob\":list(Sse_opt_oob),\n",
    "        \"x_fit\":list(x_fit),\n",
    "        \"SyR_fit\":list(SyR_fit),\n",
    "        \"SyL_fit\":list(SyL_fit),\n",
    "        \"SyO_fit\":list(SyO_fit),\n",
    "        \"SyR_fit_stim\":list(SyR_fit_stim),\n",
    "        \"SyL_fit_stim\":list(SyL_fit_stim),\n",
    "        \"SyO_fit_stim\":list(SyO_fit_stim),\n",
    "        \"n\":int(n),\n",
    "        \"Smse\":Smse,\n",
    "        \"Sexito\":Sexito,\n",
    "        \"Smean_perf_oo\":Smean_perf_oo,\n",
    "        \"Smean_oo\":Smean_oo,\n",
    "        \"SFit\":SFit\n",
    "    }\n",
    "    # Serializing json  \n",
    "    Sjson_object = json.dumps(Sdict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(Sfilename, \"w\") as outfile: \n",
    "        outfile.write(Sjson_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# Stochastic PC fit\n",
    "SOfit_files = [f for f in os.listdir(path_fit) if f.startswith('SO_fit')]\n",
    "auxSO = [f.replace('SO_fit_oo_Sub','') for f in SOfit_files]\n",
    "subj_SOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in auxSO]\n",
    "sorted_subj_SOfit = sorted(subj_SOfit)\n",
    "index_subj_SOfit = [subj_SOfit.index(elem) for elem in sorted_subj_SOfit]\n",
    "sorted_SOfit_files = [SOfit_files[i] for i in index_subj_SOfit]\n",
    "\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(6,4,figsize=(18,22))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.5) \n",
    "for part in sorted_subj_data:\n",
    "    ind += 1\n",
    "    # stochastic PC fit\n",
    "    fSO = sorted_SOfit_files[ind]\n",
    "    filename=path_fit+fSO\n",
    "    with open(filename) as fSO:\n",
    "        dataSO = json.load(fSO)\n",
    "    for k, v in dataSO.items():\n",
    "        globals()[k]=v  \n",
    "    ind1 = ind%6\n",
    "    ind2 = int(round(ind/6,1))\n",
    "    ax[ind1,ind2].text(-0.5, 1.0, 'mean optout ='+str(np.round(Smean_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.9, 'mean perf ='+str(np.round(Smean_perf_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.8, 'sigma ='+str(np.round(Ssigma_oo,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.5, 0.7, 'mse ='+str(np.round(Smse,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].set_title(\"participant \"+str(part))\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_right_oob,Sse_right_oob,c='b',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_left_oob,Sse_left_oob,c='c',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_opt_oob,Sse_opt_oob,c='y',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_fit,SyR_fit,c='b')   \n",
    "    ax[ind1,ind2].plot(x_fit,SyL_fit,c='c')\n",
    "    ax[ind1,ind2].plot(x_fit,SyO_fit,c='y')\n",
    "    ax[0,0].legend((\"SO right\",\"SO left\",\"SO opt-out\"),loc='best', shadow=True)\n",
    "    ax[5,ind2].set_xlabel('signed differential energy')\n",
    "    ax[ind1,0].set_ylabel('response proportion')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.51,0.51])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(SHR_oo,color='b',ls='--')\n",
    "    ax[ind1,ind2].axvline(SHL_oo,color='c',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
