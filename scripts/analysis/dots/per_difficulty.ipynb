{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis per difficulty\n",
    "\n",
    "## Across subjects & sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2\n",
    "\n",
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]\n",
    "unique_signals = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/dots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, main_path+'/src')\n",
    "import my_functions as myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_csv(path_results+'preanalyzed.csv')  \n",
    "userids = adf['userID'].unique()\n",
    "\n",
    "key_PV = ['RT_no_0','RT_no_3','Doptout_0','Doptout_3','Soptout_0','Soptout_3']\n",
    "key_SR = ['mood','food', 'real_stress','sleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = {}\n",
    "ind = 0\n",
    "for part in userids:\n",
    "    ind += 1\n",
    "    RT, DO, SO = [],[],[]\n",
    "    for Day in fday:\n",
    "        for Ses in fsession:\n",
    "            sessionid = 2*Day-2+Ses\n",
    "            filename = path_results+'day'+str(Day)+'/session'+str(Ses)+'/diff_Sub'+str(part)+'_Day'+str(Day)+'_Sess'+str(Ses)+'.json'   \n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "            RT.append(data['RT_no'])\n",
    "            DO.append(data['Doptout'])\n",
    "            SO.append(data['Soptout'])\n",
    "    mas.update({part: {'RTas': np.nanmean(RT,axis=0),'DOas': np.nanmean(DO,axis=0),'SOas': np.nanmean(SO,axis=0)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['RT_no','Doptout','Dperf_oo','Sperf_oo','perf_no','DRT_oo','SRT_oo','DRT_OKoo','SRT_OKoo','RT_noNOK',\\\n",
    "             'Soptout']\n",
    "\n",
    "df = pd.DataFrame(columns=col_names+['RTeff','DOeff','SOeff','difficulty','sessionID','userID'])\n",
    "\n",
    "dfANOVA = pd.DataFrame(columns=['perf','type','difficulty','sessionID','userID'])\n",
    "\n",
    "df_LR = pd.DataFrame(columns=['slope_RT','slope_DO','slope_SO','intercept_RT','intercept_DO','intercept_SO',\\\n",
    "                              'sessionID','userID','user_sessionID'])\n",
    "ind = 0\n",
    "for part in userids:\n",
    "    ind += 1\n",
    "    dict_,dANOVA = {},{}\n",
    "    for Day in fday:\n",
    "        for Ses in fsession:\n",
    "            sessionid = 2*Day-2+Ses\n",
    "            user_sessionID = str(part)+'_'+str(sessionid)\n",
    "            \n",
    "            filename = path_results+'day'+str(Day)+'/session'+str(Ses)+'/diff_Sub'+str(part)+'_Day'+str(Day)+'_Sess'+str(Ses)+'.json'   \n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            diff_vals = np.array([1, 2, 3, 4])\n",
    "            diff_list = [1, 2, 3, 4]\n",
    "            num_diff = len(diff_list)\n",
    "            \n",
    "            for key in col_names:\n",
    "                dict_[key] = data[key]\n",
    "            dict_.update({'RTeff':np.array(data['RT_no'])-mas[part]['RTas'],\\\n",
    "                                   'DOeff':np.array(data['Doptout'])-mas[part]['DOas'],\\\n",
    "                                   'SOeff':np.array(data['Soptout'])-mas[part]['SOas'],\\\n",
    "                                   'difficulty':diff_list,'sessionID':[sessionid]*num_diff,'userID':[part]*num_diff})\n",
    "            dANOVA = {'perf':data['perf_no']+data['Dperf_oo']+data['Sperf_oo'],\\\n",
    "                      'type':['NO']*num_diff+['DO']*num_diff+['SO']*num_diff,\\\n",
    "                      'difficulty':diff_list*3,'sessionID':[sessionid]*num_diff*3,'userID':[part]*num_diff*3}\n",
    "            \n",
    "            df_new = pd.DataFrame(dict_)\n",
    "            dfANOVA_new = pd.DataFrame(dANOVA)\n",
    "            \n",
    "            RT = np.array(data['RT_no'])\n",
    "            DO = np.array(data['Doptout'])\n",
    "            SO = np.array(data['Soptout'])\n",
    "\n",
    "            slope_RT,intercept_RT,r_RT,p_RT,se_RT = stats.linregress(np.log(diff_vals[~np.isnan(RT)]), RT[~np.isnan(RT)])\n",
    "            slope_DO,intercept_DO,r_DO,p_DO,se_DO = stats.linregress(np.log(diff_vals[~np.isnan(DO)]), DO[~np.isnan(DO)])\n",
    "            slope_SO,intercept_SO,r_SO,p_SO,se_SO = stats.linregress(np.log(diff_vals[~np.isnan(SO)]), SO[~np.isnan(SO)])\n",
    "\n",
    "            df_LR_new = pd.DataFrame({'slope_RT':[slope_RT],'slope_DO':[slope_DO],'slope_SO':[slope_SO],\n",
    "                        'intercept_RT':[intercept_RT],'intercept_DO':[intercept_DO],'intercept_SO':[intercept_SO],\\\n",
    "                        'session':[sessionid],'subject':[part],'user_sessionID':[user_sessionID]})\n",
    "            \n",
    "            if user_sessionID!='3062_1' and user_sessionID!='3062_2' and user_sessionID!='3062_4':\n",
    "                df = (pd.concat([df, df_new], ignore_index=True).reindex(columns=df.columns))\n",
    "                dfANOVA = (pd.concat([dfANOVA, dfANOVA_new], ignore_index=True).reindex(columns=dfANOVA.columns))\n",
    "                df_LR = (pd.concat([df_LR, df_LR_new], ignore_index=True).reindex(columns=df_LR.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLR = df_LR[['slope_RT', 'slope_DO', 'slope_SO', 'intercept_RT', 'intercept_DO',\n",
    "       'intercept_SO', 'user_sessionID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfLR['user_sessionID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "dfLR.to_csv(path_results+'linearRegr_diff.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids = df['sessionID'].unique()\n",
    "userids = df['userID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMAS = df.groupby(['difficulty']).mean().reset_index()\n",
    "dfSEM = df.groupby(['difficulty']).sem().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
    "plt.subplots_adjust(wspace = 0.3)  \n",
    "ax[0].errorbar(unique_signals,dfMAS['perf_no'],dfSEM['perf_no'],c='g')\n",
    "ax[0].errorbar(unique_signals,dfMAS['Dperf_oo'],dfSEM['Dperf_oo'],c='r')\n",
    "ax[0].errorbar(unique_signals,dfMAS['Sperf_oo'],dfSEM['Sperf_oo'],c='b')\n",
    "ax[0].set_ylabel('performance')\n",
    "ax[0].set_xlabel('Difficulty')\n",
    "ax[0].legend((\"non-optout\",\"Doptout\",\"Soptout\"),loc='upper right', shadow=True)\n",
    "\n",
    "\n",
    "ax[1].errorbar(unique_signals,dfMAS['RT_no'],dfSEM['RT_no'],c='g')\n",
    "ax[1].errorbar(unique_signals,dfMAS['RT_noNOK'],dfSEM['RT_noNOK'],c='m')\n",
    "ax[1].errorbar(unique_signals,dfMAS['DRT_OKoo'],dfSEM['DRT_OKoo'],c='r')\n",
    "ax[1].errorbar(unique_signals,dfMAS['SRT_OKoo'],dfSEM['SRT_OKoo'],c='b')\n",
    "ax[1].errorbar(unique_signals,dfMAS['DRT_oo'],dfSEM['DRT_oo'],c='r',ls='--')\n",
    "ax[1].errorbar(unique_signals,dfMAS['SRT_oo'],dfSEM['SRT_oo'],c='b',ls='--')\n",
    "ax[1].set_ylabel('Reaction Time')\n",
    "ax[1].set_xlabel('Difficulty')\n",
    "ax[1].legend((\"correct non-optout\",\"incorrect non-optout\",\"correct Doptout\",\"correct Soptout\",\\\n",
    "             \"Doptout\",\"Soptout\"),loc='upper right', shadow=True)\n",
    "\n",
    "ax[2].errorbar(unique_signals,dfMAS['Doptout'],dfSEM['Doptout'],c='r')\n",
    "ax[2].errorbar(unique_signals,dfMAS['Soptout'],dfSEM['Soptout'],c='b')\n",
    "ax[2].set_ylabel('Optout')\n",
    "ax[2].set_xlabel('Difficulty')\n",
    "ax[2].legend((\"Doptout\",\"Soptout\"),loc='upper left', shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "df.to_csv(path_results+'per_difficulty.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "dfANOVA.to_csv(path_results+'forANOVA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdf = adf[['sessionID_x','userID','user_sessionID','mood','real_stress','food','sleep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LR = pd.merge(Rdf,df_LR,on='user_sessionID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LR_mor = df_LR[df_LR['sessionID_x']%2==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_PV_slope = ['slope_RT','slope_DO','slope_SO']\n",
    "key_PV_intercept = ['intercept_RT','intercept_DO','intercept_SO']\n",
    "key_SR = ['mood','real_stress','food','sleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_SR_PV_slope,pair_SR_PV_slope2plot = [],[]\n",
    "for pv in key_PV_slope:\n",
    "    aux = []\n",
    "    for sr in key_SR:\n",
    "        pair_SR_PV_slope.append((sr,pv))\n",
    "        aux.append((sr,pv))\n",
    "    pair_SR_PV_slope2plot.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_SR_PV_intercept,pair_SR_PV_intercept2plot = [],[]\n",
    "for pv in key_PV_intercept:\n",
    "    aux = []\n",
    "    for sr in key_SR:\n",
    "        pair_SR_PV_intercept.append((sr,pv))\n",
    "        aux.append((sr,pv))\n",
    "    pair_SR_PV_intercept2plot.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_SR_PV, p_SR_PV, SIG_SR_PV, NOS_SR_PV = {},{},{},{}\n",
    "for pair in pair_SR_PV_slope:\n",
    "    if 'sleep' in pair:  \n",
    "        LR = [myf.Linear_Regr(np.array(df_LR_mor[df_LR_mor['userID_x']==part][pair[0]]),\\\n",
    "                            np.array(df_LR_mor[df_LR_mor['userID_x']==part][pair[1]])) for part in userids]\n",
    "    else:\n",
    "        LR = [myf.Linear_Regr(np.array(df_LR[df_LR['userID_x']==part][pair[0]]),\\\n",
    "                            np.array(df_LR[df_LR['userID_x']==part][pair[1]])) for part in userids]\n",
    "    corr_SR_PV[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_SR_PV[pair] = stats.ttest_1samp(corr_SR_PV[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indSIG[0]]\n",
    "    NOS_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_p_PV = np.array([myf.roundP(p_SR_PV[(pair)]) for pair in pair_SR_PV_slope])\n",
    "round_p_PV = np.reshape(round_p_PV,(3,4))\n",
    "p_value = [['p_value']+key_SR]\n",
    "ind = -1\n",
    "for key in key_PV_slope:\n",
    "    ind += 1\n",
    "    p_value.append([key]+list(round_p_PV[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(p_value, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_SR_PV, p_SR_PV, SIG_SR_PV, NOS_SR_PV = {},{},{},{}\n",
    "for pair in pair_SR_PV_intercept:\n",
    "    if 'sleep' in pair:  \n",
    "        LR = [myf.Linear_Regr(np.array(df_LR_mor[df_LR_mor['userID_x']==part][pair[0]]),\\\n",
    "                            np.array(df_LR_mor[df_LR_mor['userID_x']==part][pair[1]])) for part in userids]\n",
    "    else:\n",
    "        LR = [myf.Linear_Regr(np.array(df_LR[df_LR['userID_x']==part][pair[0]]),\\\n",
    "                            np.array(df_LR[df_LR['userID_x']==part][pair[1]])) for part in userids]\n",
    "    corr_SR_PV[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_SR_PV[pair] = stats.ttest_1samp(corr_SR_PV[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indSIG[0]]\n",
    "    NOS_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_p_PV = np.array([myf.roundP(p_SR_PV[(pair)]) for pair in pair_SR_PV_intercept])\n",
    "round_p_PV = np.reshape(round_p_PV,(3,4))\n",
    "p_value = [['p_value']+key_SR]\n",
    "ind = -1\n",
    "for key in key_PV_intercept:\n",
    "    ind += 1\n",
    "    p_value.append([key]+list(round_p_PV[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(p_value, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfANOVA_SO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfANOVA_DO = dfANOVA[dfANOVA['type']!='SO']\n",
    "dfANOVA_SO = dfANOVA[dfANOVA['type']!='DO']\n",
    "dfANOVA_NO = dfANOVA[dfANOVA['type']!='NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#perform two-way ANOVA\n",
    "model = ols('perf ~ C(type) + C(difficulty)', data=dfANOVA_DO).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform two-way ANOVA\n",
    "model = ols('perf ~ C(type) + C(difficulty)', data=dfANOVA_SO).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform two-way ANOVA\n",
    "model = ols('perf ~ C(type) + C(difficulty)', data=dfANOVA_NO).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "interaction_groups = \"type\" + dfANOVA.type.astype(str) + \" & \" + \"difficulty\" + dfANOVA.difficulty.astype(str)\n",
    "\n",
    "comp = mc.MultiComparison(dfANOVA[\"perf\"], interaction_groups)\n",
    "post_hoc_res = comp.tukeyhsd()\n",
    "post_hoc_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
