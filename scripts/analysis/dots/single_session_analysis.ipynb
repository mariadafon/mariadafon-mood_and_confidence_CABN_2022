{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for each session\n",
    "\n",
    "Our experiment consists in testing a decision-making task and self-reports with volunteer participants in order to study how they influence each other. The experiment runs online through Jatos platform and last 20 sessions: 2 sessions per day: one in the morning and the other in the after, summing up to **10 consecutive days**. We provide to each participant a personal link that she is going to use once per session. Each session of the game starts with **3/4 questions about their mood, the quality of their sleep, the enjoyment of the food, and their stress**. They answer to the self-reports positioning a button in a continuous scale with sad and smile emoji faces at the ends. After the questionnaire, we present them noisy stimuli, and the participant has to answer deciding if the stimulus was towards the left or towards the right. If the participant chooses the correct answer, then she receives 3 points. A bad choice does not add points.\n",
    "\n",
    "The task is the **dots task** where the participant sees two circles with white dots in a black background, and she has to decide which of the circles has more dots as in Fig. 1. One of the circles always contains 50 and the other a greater amount of dots making impossible to count them to answer. The normalized difference between is computed as the **signal** present in the trial. We sort at random which circle will contain more dots in a way to present a balanced quantity of left and rightward stimuli per stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import HTML, display, Image\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2\n",
    "\n",
    "fday = 1\n",
    "fsession = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/dots/'\n",
    "path_plots = main_path+'/scripts/analysis/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, main_path+'/src')\n",
    "import my_functions as myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = main_path+'/data/jatos_dots_data/tanda1/day'+str(fday)+'/session'+str(fsession)+'/'\n",
    "filename_average= path_results+'across_sessions/average_Day'+str(fday)+'_Sess'+str(fsession)+'.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename= main_path+'/docs/example.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1**: Example stimulus that we display in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of participants \n",
    "participants = [3051+i for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [f for f in os.listdir(path) if f.endswith('_day'+str(fday)+'_session'+str(fsession))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files\n",
    "subj_data = [int(re.search('%s(.*)%s' % ('', '_day'), f).group(1)) for f in data_files]\n",
    "sorted_subj_data = sorted(subj_data)\n",
    "index_subj_data = [subj_data.index(elem) for elem in sorted_subj_data]\n",
    "sorted_data_files = [data_files[i] for i in index_subj_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reports, practice, deterministic and stochastic df for each participant\n",
    "\n",
    "Rdf,Pdf,Ddf,Sdf = {},{},{},{}\n",
    "for name in sorted_subj_data: \n",
    "    Rdf[name] = {}\n",
    "    Pdf[name] = pd.DataFrame()\n",
    "    Ddf[name] = pd.DataFrame()\n",
    "    Sdf[name] = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_list = []\n",
    "ind = -1\n",
    "for ses in sorted_data_files:\n",
    "    ind += 1\n",
    "    data = [] \n",
    "    for line in open(path+ses, 'r'):\n",
    "        if line.strip():\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    if fday==1 and fsession==1:\n",
    "        if len(data)==5:\n",
    "            demographics = data[0]\n",
    "            reports = data[1]\n",
    "            practice = data[2]\n",
    "            deterministic = data[3]\n",
    "            stochastic = data[4]\n",
    "        else:\n",
    "            reports = data[1]\n",
    "            practice = data[len(data)-3]\n",
    "            deterministic = data[len(data)-2]\n",
    "            stochastic = data[len(data)-1]\n",
    "            print('this participant ',part,' has repeated some stage')\n",
    "    else:\n",
    "        if len(data)==4:\n",
    "            reports = data[0]\n",
    "            practice = data[1]\n",
    "            deterministic = data[2]\n",
    "            stochastic = data[3]\n",
    "        elif len(data)>4:\n",
    "            reports = data[0]\n",
    "            practice = data[len(data)-3]\n",
    "            deterministic = data[len(data)-2]\n",
    "            stochastic = data[len(data)-1]\n",
    "            print('participant '+ str(sorted_subj_data[ind])+' has repeated practice '+str(len(data)-3))\n",
    "            pract = []\n",
    "            for j in range(len(data)):\n",
    "                if len(data[j])==10:\n",
    "                    pract.append(data[j])\n",
    "        else: \n",
    "            for dd in range(len(data)):\n",
    "                print(len(data[dd]))\n",
    "            reports = data[0]\n",
    "            practice = data[1]\n",
    "            deterministic = data[2]\n",
    "            print('participant '+ str(sorted_subj_data[ind])+' missed stochastic')        \n",
    "    part = reports['userID']\n",
    "    if reports['sessionID']%2==0:\n",
    "        session = 2\n",
    "    else:\n",
    "        session = 1\n",
    "    \n",
    "    if (part!=str(sorted_subj_data[ind])):\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('INCORRECT')\n",
    "        print('participant',part,'file participant',sorted_subj_data[ind])\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "    if (session!=fsession):\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('INCORRECT')\n",
    "        print(part, 'session',session,'file session',fsession)\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "    Rdf[sorted_subj_data[ind]] = reports\n",
    "    Pdf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(practice)\n",
    "    Ddf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(deterministic)\n",
    "    Sdf[sorted_subj_data[ind]] = pd.DataFrame.from_dict(stochastic)\n",
    "    rep_list.append(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports\n",
    "\n",
    "The first part of the experiment consists in answering 3 or 4 self-reports by changing a buttom in a continuos slider between a sad and a smile emoji faces.\n",
    "\n",
    "**Morning session questions**:\n",
    "\n",
    "- Mood report: ¿Cómo te has sentido esta tarde? (How did you feel this morning?) \n",
    "- Sleep report: ¿Cómo dormiste anoche? (How did you sleep the past night?)\n",
    "- Food report: ¿Cómo disfrutaste la última comida/snack? (How did you enjoy the last meal/snack?)\n",
    "- Stress report: ¿Cómo has sentido la carga de problemas personales y laborales esta mañana? (How did you feel the personal and working problems burden this morning?)\n",
    "\n",
    "**Afternoon session questions**:\n",
    "\n",
    "- Mood report: ¿Cómo te has sentido esta tarde? (How did you feel this afternoon?) \n",
    "- Food report: ¿Cómo disfrutaste la última comida/snack? (How did you enjoy the last meal/snack?)\n",
    "- Stress report: ¿Cómo has sentido la carga de problemas personales y laborales esta tarde? (How did you feel the personal and working problems burden this afternoon?)\n",
    "\n",
    "Since the stress report ranks high (low) when participants are less (more) stressed, we compute the *real_stress=1-stress*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in sorted_subj_data:\n",
    "    mood = Rdf[part]['mood']\n",
    "    stress = Rdf[part]['stress']\n",
    "    real_stress = 1-stress\n",
    "    food = Rdf[part]['food']\n",
    "    if fsession==1:\n",
    "        sleep = Rdf[part]['sleep']\n",
    "        if mood<0.15 and real_stress<0.15 and food<0.15 and sleep<0.15:\n",
    "            print('Here we printed the \"abnormal\" self-report answers to e-mail the participant in order to get \\\n",
    "            knowledge of the reason.')\n",
    "            print('-',part, 'has all reports below 0.15: ',Rdf[part])\n",
    "        elif mood>0.85 and real_stress>0.85 and food>0.85 and sleep>0.85:\n",
    "            print('Here we printed the \"abnormal\" self-report answers to e-mail the participant in order to get \\\n",
    "            knowledge of the reason.')\n",
    "            print('-',part, 'has all reports over 0.85: ',Rdf[part])\n",
    "    else: \n",
    "        if mood<0.15 and real_stress<0.15 and food<0.15:\n",
    "            print('Here we printed the \"abnormal\" self-report answers to e-mail the participant in order to get \\\n",
    "            knowledge of the reason.')\n",
    "            print('-',part, 'has all reports below 0.15: ',Rdf[part])\n",
    "        elif mood>0.85 and real_stress>0.85 and food>0.85:\n",
    "            print('Here we printed the \"abnormal\" self-report answers to e-mail the participant in order to get \\\n",
    "            knowledge of the reason.')\n",
    "            print('-',part, 'has all reports over 0.85: ',Rdf[part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reportsdf = pd.DataFrame(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reportsdf['real_stress'] = 1-Reportsdf['stress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reportsdf.head(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1**: Self-reports answered by each participant in the current session. Column names: \n",
    "- mood, sleep, food, stress: raw self-reports\n",
    "- sessionID: session number = 2*Day-2+Session, where Day takes values {1,2,...,10} and Session takes values {1,2}\n",
    "- userID: participant number ID\n",
    "- date: browser's time zone (Spain in all cases)\n",
    "- real_stress: 1-stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save results\n",
    "path_fit = path_results+'day'+str(fday)+'/session'+str(fsession)+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice stage\n",
    "\n",
    "After answering the self-report's questionnaire, it starts the dots task composed by three stages: practice, deterministic and stochastic. The practice stage is present in all sessions and consists of 10 trials with increasing (decreasing) difficulty if the participant answered correctly (incorrectly) in the previous trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "for part in sorted_subj_data:\n",
    "    Pdf[part]['signal'] = np.abs(Pdf[part]['dots_num_left']-Pdf[part]['dots_num_right'])\n",
    "    Presult = list(Pdf[part].discrimination_is_correct)\n",
    "    Psignal = list(Pdf[part].signal)\n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].plot(np.arange(1,11),np.array(Psignal)/100,'r')\n",
    "    ax[ind1,ind2].set_ylim(0.01,0.27)\n",
    "    ax[ind1,0].set_ylabel('Signal')\n",
    "    ax[6,ind2].set_xlabel('Practice trial number')\n",
    "    ax[6,3].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**: Practice signal vs trial number for each participant. It always starts with 0.2 signal (20 dots of difference between the two circles). Minumum possible signal: 0.02 (2 dots of difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic and stochastic stages\n",
    "\n",
    "In some trials, the participant has a third option to choose: **the opt-out option**. By choosing it, the subject skips the decision and passes to the next trial. Each session of the game has two stages, each of them with 120 trials. The difference between the two stages is the action of the opt-out option. In the first stage, the opt-out option returns a fix number of 2 points. We called this stage: **Deterministic Optout (DO) stage**. While, in the second stage, the 80% of the trials the opt-out option returns 3 points, while the other 20% does not return points. The name of this stage is: **Stochastic Optout (SO) stage** and we use it to study risk aversion.\n",
    "\n",
    "Before each stimulus of the DO stage, we display either a question mark or a cross, in order to inform to the participant if she will or will not have the opt-out option. For the SO stage, we change the question mark with the image of a dice, indicating the stochastic character of the trial.\n",
    "\n",
    "In order to study the psychometric variables, we slip the trials into **4 difficulties** (15 trials each) with signals: 0.02, 0.06, 0.1, 0.14. That is, 2, 6, 10 and 14 dots of difference between the circles. The trial difficulty presentation is also sorted randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic dataframe\n",
    "for part in sorted_subj_data:\n",
    "    # discrimination RT\n",
    "    discrimination_RT = np.array(list(Ddf[part].discrimination_t_keydown))-np.array(list(Ddf[part].t_offset))\n",
    "    Ddf[part][\"discrimination_RT\"] = discrimination_RT \n",
    "    Ddf[part]['signal'] = np.abs(Ddf[part]['dots_num_left']-Ddf[part]['dots_num_right'])\n",
    "    Dsignal = np.array(np.abs(Ddf[part]['dots_num_left']-Ddf[part]['dots_num_right']))/100\n",
    "    Dorientation = Ddf[part]['orientation']\n",
    "    signedDsignal = []\n",
    "    ind = -1\n",
    "    for elem in Dorientation:\n",
    "        ind += 1\n",
    "        if elem:\n",
    "            signedDsignal.append(Dsignal[ind])\n",
    "        else: \n",
    "            signedDsignal.append(-Dsignal[ind])  \n",
    "    # signed signal (neg signal to the left and pos signal tothe right)\n",
    "    Ddf[part]['signed_signal'] = signedDsignal\n",
    "    Dcorrect_list = list(Ddf[part]['discrimination_is_correct'])\n",
    "    Doptout_list = list(Ddf[part][\"optout\"])\n",
    "    Dbool_correct_list = [elem==1 for elem in Dcorrect_list]\n",
    "    Dbool_orientation_list = [elem==1 for elem in Dorientation]\n",
    "    Dxor = np.logical_xor(Dbool_correct_list,np.logical_not(Dbool_orientation_list))\n",
    "    Dresp = []\n",
    "    ind = -1\n",
    "    for elem in Doptout_list:\n",
    "        ind += 1\n",
    "        if elem==False and Dxor[ind]==True:\n",
    "            Dresp.append(1)\n",
    "        elif elem==False and Dxor[ind]==False:\n",
    "            Dresp.append(0)\n",
    "        elif elem==True: \n",
    "            Dresp.append(2)\n",
    "    # 1 for rightward answers, 0 for left\n",
    "    Ddf[part]['resp_is_R'] = [elem==1 for elem in Dresp]\n",
    "    Ddf[part]['resp_is_R'] = Ddf[part]['resp_is_R'].astype(int)\n",
    "    # 1 for rightward answers, 0 for left, and 2 for optout\n",
    "    Ddf[part]['answer'] = Dresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtoffset = []\n",
    "for part in sorted_subj_data:\n",
    "    Dtoffset.append(Ddf[part]['t_offset'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Dtoffset)\n",
    "ax.set_xticks(np.arange(1,28))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('deterministic time offset (stim display)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ddiscrimination_t_keydown = []\n",
    "for part in sorted_subj_data:\n",
    "    Ddiscrimination_t_keydown.append(Ddf[part]['discrimination_t_keydown'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Ddiscrimination_t_keydown)\n",
    "ax.set_xticks(np.arange(1,28))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('reaction time (discrimination_t_keydown)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_time = np.array(Ddf[3051].discrimination_t_onset)-np.array(Ddf[3051].t_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_time = np.array(Ddf[3051].t_offset)-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(delay_time,dead_time)\n",
    "plt.title('participant 3051')\n",
    "plt.xlabel('delay time (ms)')\n",
    "plt.ylabel('dead time (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard t offset greater than 350 ms\n",
    "for name in sorted_subj_data: \n",
    "    Ddf[name] = Ddf[name][Ddf[name]['t_offset']<=350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic non-optout & optout df\n",
    "Ddf_no,Ddf_oo = {},{}\n",
    "for name in sorted_subj_data: \n",
    "    Ddf_no[name] = pd.DataFrame()\n",
    "    Ddf_oo[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    Ddf_no[part] = Ddf[part][(Ddf[part]['focus']==0)]\n",
    "    Ddf_oo[part] = Ddf[part][(Ddf[part]['focus']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic dataframe\n",
    "for part in sorted_subj_data:\n",
    "    # discrimination RT\n",
    "    Sdiscrimination_RT = np.array(list(Sdf[part].discrimination_t_keydown))-np.array(list(Sdf[part].t_offset))\n",
    "    Sdf[part][\"discrimination_RT\"] = Sdiscrimination_RT \n",
    "    Sdf[part]['signal'] = np.abs(Sdf[part]['dots_num_left']-Sdf[part]['dots_num_right'])\n",
    "    Ssignal = np.array(np.abs(Sdf[part]['dots_num_left']-Sdf[part]['dots_num_right']))/100\n",
    "    Sorientation = Sdf[part]['orientation']\n",
    "    signedSsignal = []\n",
    "    ind = -1\n",
    "    for elem in Sorientation:\n",
    "        ind += 1\n",
    "        if elem:\n",
    "            signedSsignal.append(Ssignal[ind])\n",
    "        else: \n",
    "            signedSsignal.append(-Ssignal[ind])  \n",
    "    # signed signal (neg signal to the left and pos signal tothe right)\n",
    "    Sdf[part]['signed_signal'] = signedSsignal\n",
    "    Scorrect_list = list(Sdf[part]['discrimination_is_correct'])\n",
    "    Soptout_list = list(Sdf[part][\"optout\"])\n",
    "    Sbool_correct_list = [elem==1 for elem in Scorrect_list]\n",
    "    Sbool_orientation_list = [elem==1 for elem in Sorientation]\n",
    "    Sxor = np.logical_xor(Sbool_correct_list,np.logical_not(Sbool_orientation_list))\n",
    "    Sresp = []\n",
    "    ind = -1\n",
    "    for elem in Soptout_list:\n",
    "        ind += 1\n",
    "        if elem==False and Sxor[ind]==True:\n",
    "            Sresp.append(1)\n",
    "        elif elem==False and Sxor[ind]==False:\n",
    "            Sresp.append(0)\n",
    "        elif elem==True: \n",
    "            Sresp.append(2)\n",
    "    # 1 for rightward answers, 0 for left\n",
    "    Sdf[part]['resp_is_R'] = [elem==1 for elem in Sresp]\n",
    "    Sdf[part]['resp_is_R'] = Sdf[part]['resp_is_R'].astype(int)\n",
    "    # 1 for rightward answers, 0 for left, and 2 for optout\n",
    "    Sdf[part]['answer'] = Sresp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stoffset = []\n",
    "for part in sorted_subj_data:\n",
    "    Stoffset.append(Sdf[part]['t_offset'])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(Stoffset)\n",
    "ax.set_xticks(np.arange(1,28))\n",
    "ax.set_xlabel('participants')\n",
    "ax.set_ylabel('stochastic time offset (stim display)')\n",
    "ax.set_xticklabels(sorted_subj_data, rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard t offset greater than 350 ms\n",
    "for name in sorted_subj_data: \n",
    "    Sdf[name] = Sdf[name][Sdf[name]['t_offset']<=350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic non-optout & optout df\n",
    "Sdf_no,Sdf_oo = {},{}\n",
    "for name in sorted_subj_data: \n",
    "    Sdf_no[name] = pd.DataFrame()\n",
    "    Sdf_oo[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    Sdf_no[part] = Sdf[part][(Sdf[part]['focus']==0)]\n",
    "    Sdf_oo[part] = Sdf[part][(Sdf[part]['focus']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-optout df for each participant\n",
    "df_no = {}\n",
    "for name in sorted_subj_data: \n",
    "    df_no[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    df_no[part] = pd.concat([Ddf_no[part],Sdf_no[part]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data together df for each participant\n",
    "df_all = {}\n",
    "for name in sorted_subj_data: \n",
    "    df_all[name] = pd.DataFrame()\n",
    "for part in sorted_subj_data:\n",
    "    df_all[part] = pd.concat([Ddf[part],Sdf[part]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN AGAIN\n",
    "\n",
    "## toffset \n",
    "\n",
    "median_toffset,max_toffset = [],[]\n",
    "for part in sorted_subj_data:\n",
    "    toffset = df_all[part]['t_offset']\n",
    "    median_toffset.append(np.median(toffset))\n",
    "    max_toffset.append(np.max(toffset))\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"median_toffset\":median_toffset,\n",
    "    \"max_toffset\":max_toffset\n",
    "}\n",
    "# Serializing json  \n",
    "json_object = json.dumps(dict_) \n",
    "    \n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs. difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "middle_perf_no = []\n",
    "subj_perf_diff_oo,Ssubj_perf_diff_oo,subj_perf_diff_no = [[] for _ in range(3)]\n",
    "subj_perf_oo,Ssubj_perf_oo,subj_perf_no = [[] for _ in range(3)]\n",
    "for part in sorted_subj_data:\n",
    "    perf_diff_oo,perf_diff_no,Sperf_diff_oo,se_perf_diff_oo,Sse_perf_diff_oo,\\\n",
    "    se_perf_diff_no,lnum_trials_oo,lSnum_trials_oo,lnum_trials_no=[[] for _ in range(9)]\n",
    "    for diff in range(4):\n",
    "        # correct deterministic\n",
    "        subset_oo = Ddf_oo[part][(Ddf_oo[part][\"difficulty\"]==diff) & (Ddf_oo[part][\"optout\"]==0)]  \n",
    "        result_oo = np.array(subset_oo.discrimination_is_correct)\n",
    "        num_trials_oo = len(result_oo)\n",
    "        lnum_trials_oo.append(num_trials_oo)\n",
    "        if num_trials_oo:\n",
    "            perf_diff_oo.append(100*np.sum(result_oo)/num_trials_oo)\n",
    "            se_perf_diff_oo.append(100*np.sqrt(perf_diff_oo[diff]/100 *(1-perf_diff_oo[diff]/100)/num_trials_oo))\n",
    "        else:\n",
    "            perf_diff_oo.append(np.nan)\n",
    "            se_perf_diff_oo.append(np.nan)\n",
    "        # correct stochastic\n",
    "        Ssubset_oo = Sdf_oo[part][(Sdf_oo[part][\"difficulty\"]==diff) & (Sdf_oo[part][\"optout\"]==0)]  \n",
    "        Sresult_oo = np.array(Ssubset_oo.discrimination_is_correct)\n",
    "        Snum_trials_oo = len(Sresult_oo)\n",
    "        lSnum_trials_oo.append(Snum_trials_oo)\n",
    "        if Snum_trials_oo:\n",
    "            Sperf_diff_oo.append(100*np.sum(Sresult_oo)/Snum_trials_oo)\n",
    "            Sse_perf_diff_oo.append(100*np.sqrt(Sperf_diff_oo[diff]/100 *(1-Sperf_diff_oo[diff]/100)/Snum_trials_oo))\n",
    "        else: \n",
    "            Sperf_diff_oo.append(np.nan)\n",
    "            Sse_perf_diff_oo.append(np.nan)\n",
    "        # non optout\n",
    "        subset_no = df_no[part][(df_no[part][\"difficulty\"]==diff)]\n",
    "        result_no = np.array(subset_no.discrimination_is_correct)\n",
    "        num_trials_no = len(result_no)\n",
    "        lnum_trials_no.append(num_trials_no)\n",
    "        perf_diff_no.append(100*np.sum(result_no)/num_trials_no)\n",
    "        se_perf_diff_no.append(100*np.sqrt(perf_diff_no[diff]/100 *(1-perf_diff_no[diff]/100)/num_trials_no))\n",
    "        if diff==1:\n",
    "            middle_perf_no.append(perf_diff_no[diff])\n",
    "            \n",
    "    subj_perf_diff_oo.append(perf_diff_oo)\n",
    "    Ssubj_perf_diff_oo.append(Sperf_diff_oo)\n",
    "    subj_perf_diff_no.append(perf_diff_no)\n",
    "    \n",
    "    subj_perf_oo.append(np.nanmean(perf_diff_oo))\n",
    "    Ssubj_perf_oo.append(np.nanmean(Sperf_diff_oo))\n",
    "    subj_perf_no.append(np.nanmean(perf_diff_no))\n",
    "        \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"Dperf_oo\":perf_diff_oo,\n",
    "        \"Dse_perf_oo\":se_perf_diff_oo,\n",
    "        \"Sperf_oo\":Sperf_diff_oo,\n",
    "        \"Sse_perf_oo\":Sse_perf_diff_oo,\n",
    "        \"perf_no\":perf_diff_no,\n",
    "        \"se_perf_no\":se_perf_diff_no,  \n",
    "        \"Dn_trials_oo\":lnum_trials_oo,\n",
    "        \"Sn_trials_oo\":lSnum_trials_oo,\n",
    "        \"NOn_trials\":lnum_trials_no\n",
    "    }\n",
    "    # Serializing json  \n",
    "    json_object = json.dumps(dict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(filename, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].set_ylim(0,105)\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),perf_diff_oo,yerr=se_perf_diff_oo,color='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),perf_diff_no,yerr=se_perf_diff_no,color='g',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),Sperf_diff_oo,yerr=Sse_perf_diff_oo,color='b',ls='-')\n",
    "    ax[ind1,0].set_ylabel('Performance')\n",
    "    ax[6,ind2].set_xlabel('Difficulty')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,5))\n",
    "    ax[0,0].legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "    ax[6,3].axis('off')\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"participantID\":sorted_subj_data,\n",
    "    \"sessionID\":[reports['sessionID']]*(len(sorted_subj_data)),\n",
    "    \"Dsubj_perf_oo\":subj_perf_oo,\n",
    "    \"Ssubj_perf_oo\":Ssubj_perf_oo,\n",
    "    \"subj_perf_no\":subj_perf_no\n",
    "}\n",
    "# Serializing json  \n",
    "json_object = json.dumps(dict_) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_average, \"w\") as outfile: \n",
    "    outfile.write(json_object) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3**: Mean and standard deviation performance vs difficulty for each participant. Green: non-optout trials. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_perf_oo,Smean_subj_perf_oo,mean_subj_perf_no,se_subj_perf_oo,Sse_subj_perf_oo,se_subj_perf_no = [[] for _ in range(6)]\n",
    "for diff in range(4):\n",
    "    mean_subj_perf_oo.append(np.nanmean(np.array(subj_perf_diff_oo)[:,diff]))\n",
    "    Smean_subj_perf_oo.append(np.nanmean(np.array(Ssubj_perf_diff_oo)[:,diff]))\n",
    "    mean_subj_perf_no.append(np.nanmean(np.array(subj_perf_diff_no)[:,diff]))\n",
    "    se_subj_perf_oo.append(np.nanstd(np.array(subj_perf_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_perf_oo.append(np.nanstd(np.array(Ssubj_perf_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    se_subj_perf_no.append(np.nanstd(np.array(subj_perf_diff_no)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,5),mean_subj_perf_oo,se_subj_perf_oo,c='r')\n",
    "plt.errorbar(np.arange(1,5),mean_subj_perf_no,se_subj_perf_no,c='g')\n",
    "plt.errorbar(np.arange(1,5),Smean_subj_perf_oo,Sse_subj_perf_oo,c='b')\n",
    "plt.legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean perf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4**: Mean and standard error performance vs difficulty across participants. Green: non-optout trials. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time (RT) vs. difficulty\n",
    "\n",
    "As a cue of self-confidence, we study the median reaction time in correct trials for each of the three type of trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "subj_RT_oo,Ssubj_RT_oo,subj_RT_no = [[] for _ in range(3)]\n",
    "OKsubj_RT_oo,OKSsubj_RT_oo,OKsubj_RT_no = [[] for _ in range(3)]\n",
    "NOKsubj_RT_oo,NOKSsubj_RT_oo,NOKsubj_RT_no = [[] for _ in range(3)]\n",
    "subj_RT_diff_oo,Ssubj_RT_diff_oo,subj_RT_diff_no,subj_medianRT = [[] for _ in range(4)]\n",
    "for part in sorted_subj_data:\n",
    "    # list with RT in every trials for this participant\n",
    "    RT_list = list(df_no[part]['discrimination_t_keydown'])+list(Ddf_oo[part]['discrimination_t_keydown'])+\\\n",
    "    list(Sdf_oo[part]['discrimination_t_keydown'])\n",
    "    # global median RT for this participant\n",
    "    medianRT = np.nanmedian(RT_list)\n",
    "    # list with the global median RT for every participant\n",
    "    subj_medianRT.append(medianRT)\n",
    "    \n",
    "    ## non-optout trial\n",
    "    subj_RT_no.append(np.nanmedian(list(df_no[part]['discrimination_t_keydown']))/medianRT)\n",
    "    ## optout trials\n",
    "    subset_do = Ddf_oo[part][Ddf_oo[part][\"optout\"]==1]\n",
    "    subset_so = Sdf_oo[part][Sdf_oo[part][\"optout\"]==1]\n",
    "    # lists with the normalized median RT for optout trials\n",
    "    subj_RT_oo.append(np.nanmedian(list(subset_do['discrimination_t_keydown']))/medianRT)\n",
    "    Ssubj_RT_oo.append(np.nanmedian(list(subset_so['discrimination_t_keydown']))/medianRT)\n",
    "    ## correct trials\n",
    "    OKsubset_no = df_no[part][(df_no[part][\"discrimination_is_correct\"]==1)]\n",
    "    OKsubset_do = Ddf_oo[part][(Ddf_oo[part][\"discrimination_is_correct\"]==1) & (Ddf_oo[part][\"optout\"]==0)]\n",
    "    OKsubset_so = Sdf_oo[part][(Sdf_oo[part][\"discrimination_is_correct\"]==1) & (Sdf_oo[part][\"optout\"]==0)]\n",
    "    # lists with the normalized median RT for correct trials\n",
    "    OKsubj_RT_no.append(np.nanmedian(list(OKsubset_no['discrimination_t_keydown']))/medianRT)\n",
    "    OKsubj_RT_oo.append(np.nanmedian(list(OKsubset_do['discrimination_t_keydown']))/medianRT)\n",
    "    OKSsubj_RT_oo.append(np.nanmedian(list(OKsubset_so['discrimination_t_keydown']))/medianRT)\n",
    "    ## incorrect trials\n",
    "    NOKsubset_no = df_no[part][(df_no[part][\"discrimination_is_correct\"]==0)]\n",
    "    NOKsubset_do = Ddf_oo[part][(Ddf_oo[part][\"discrimination_is_correct\"]==0) & (Ddf_oo[part][\"optout\"]==0)]\n",
    "    NOKsubset_so = Sdf_oo[part][(Sdf_oo[part][\"discrimination_is_correct\"]==0) & (Sdf_oo[part][\"optout\"]==0)]\n",
    "    # lists with the normalized median RT for incorrect trials\n",
    "    NOKsubj_RT_no.append(np.nanmedian(list(NOKsubset_no['discrimination_t_keydown']))/medianRT)\n",
    "    NOKsubj_RT_oo.append(np.nanmedian(list(NOKsubset_do['discrimination_t_keydown']))/medianRT)\n",
    "    NOKSsubj_RT_oo.append(np.nanmedian(list(NOKsubset_so['discrimination_t_keydown']))/medianRT)\n",
    "    \n",
    "    RT_diff_oo,SRT_diff_oo,RT_diff_no,RT_diff_noNOK,sd_RT_diff_oo,Ssd_RT_diff_oo,sd_RT_diff_no,sd_RT_diff_noNOK, \\\n",
    "    RT_diff_OKoo,sd_RT_diff_OKoo,SRT_diff_OKoo,Ssd_RT_diff_OKoo = [[] for _ in range(12)]\n",
    "    for diff in range(4):\n",
    "        # optout deterministic\n",
    "        subset_oo = subset_do[(subset_do[\"difficulty\"]==diff)] \n",
    "        result_oo = list(subset_oo.discrimination_is_correct)\n",
    "        num_trials_oo = len(result_oo)\n",
    "        RT_oo = list(subset_oo.discrimination_t_keydown)\n",
    "        if num_trials_oo:\n",
    "            RT_diff_oo.append(np.median(RT_oo)/medianRT)\n",
    "            sd_RT_diff_oo.append(myf.std_median(RT_oo)/medianRT)\n",
    "        else:\n",
    "            RT_diff_oo.append(np.nan)\n",
    "            sd_RT_diff_oo.append(np.nan)\n",
    "        # optout stochastic\n",
    "        Ssubset_oo = subset_so[(subset_so[\"difficulty\"]==diff)]   \n",
    "        Sresult_oo = list(Ssubset_oo.discrimination_is_correct)\n",
    "        Snum_trials_oo = len(Sresult_oo)\n",
    "        SRT_oo = list(Ssubset_oo.discrimination_t_keydown)\n",
    "        if Snum_trials_oo:\n",
    "            SRT_diff_oo.append(np.median(SRT_oo)/medianRT)\n",
    "            Ssd_RT_diff_oo.append(myf.std_median(SRT_oo)/medianRT)\n",
    "        else: \n",
    "            SRT_diff_oo.append(np.nan)\n",
    "            Ssd_RT_diff_oo.append(np.nan)\n",
    "        # correct deterministic\n",
    "        subset_OKoo = OKsubset_do[(OKsubset_do[\"difficulty\"]==diff)] \n",
    "        result_OKoo = list(subset_OKoo.discrimination_is_correct)\n",
    "        num_trials_OKoo = len(result_OKoo)\n",
    "        RT_OKoo = list(subset_OKoo.discrimination_t_keydown)\n",
    "        if num_trials_OKoo:\n",
    "            RT_diff_OKoo.append(np.median(RT_OKoo)/medianRT)\n",
    "            sd_RT_diff_OKoo.append(myf.std_median(RT_OKoo)/medianRT)\n",
    "        else:\n",
    "            RT_diff_OKoo.append(np.nan)\n",
    "            sd_RT_diff_OKoo.append(np.nan)\n",
    "        # correct stochastic\n",
    "        Ssubset_OKoo = OKsubset_so[(OKsubset_so[\"difficulty\"]==diff)]   \n",
    "        Sresult_OKoo = list(Ssubset_OKoo.discrimination_is_correct)\n",
    "        Snum_trials_OKoo = len(Sresult_OKoo)\n",
    "        SRT_OKoo = list(Ssubset_OKoo.discrimination_t_keydown)\n",
    "        if Snum_trials_OKoo:\n",
    "            SRT_diff_OKoo.append(np.median(SRT_OKoo)/medianRT)\n",
    "            Ssd_RT_diff_OKoo.append(myf.std_median(SRT_OKoo)/medianRT)\n",
    "        else: \n",
    "            SRT_diff_OKoo.append(np.nan)\n",
    "            Ssd_RT_diff_OKoo.append(np.nan)\n",
    "        # non optout correct\n",
    "        subset_no = OKsubset_no[(OKsubset_no[\"difficulty\"]==diff)]\n",
    "        result_no = list(subset_no.discrimination_is_correct)\n",
    "        num_trials_no = len(result_no)\n",
    "        RT_no = list(subset_no.discrimination_t_keydown)\n",
    "        RT_diff_no.append(np.median(RT_no)/medianRT)\n",
    "        sd_RT_diff_no.append(myf.std_median(RT_no)/medianRT)\n",
    "        # non optout incorrect\n",
    "        subset_noNOK = NOKsubset_no[(NOKsubset_no[\"difficulty\"]==diff)]\n",
    "        #result_noNOK = list(subset_noNOK.discrimination_is_correct)\n",
    "        #num_trials_noNOK = len(result_noNOK)\n",
    "        RT_noNOK = list(subset_noNOK.discrimination_t_keydown)\n",
    "        RT_diff_noNOK.append(np.median(RT_noNOK)/medianRT)\n",
    "        sd_RT_diff_noNOK.append(myf.std_median(RT_noNOK)/medianRT)\n",
    "        \n",
    "    subj_RT_diff_oo.append(RT_diff_OKoo)\n",
    "    Ssubj_RT_diff_oo.append(SRT_diff_OKoo)\n",
    "    subj_RT_diff_no.append(RT_diff_no)\n",
    "      \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"DRT_oo\": RT_diff_oo,\n",
    "        \"DsdRT_oo\" : sd_RT_diff_oo,\n",
    "        \"SRT_oo\": SRT_diff_oo,\n",
    "        \"SsdRT_oo\" : Ssd_RT_diff_oo,\n",
    "        \"DRT_OKoo\": RT_diff_OKoo,\n",
    "        \"DsdRT_OKoo\" : sd_RT_diff_OKoo,\n",
    "        \"SRT_OKoo\": SRT_diff_OKoo,\n",
    "        \"SsdRT_OKoo\" : Ssd_RT_diff_OKoo,\n",
    "        \"RT_no\": RT_diff_no,\n",
    "        \"sdRT_no\" : sd_RT_diff_no, \n",
    "        \"RT_noNOK\": RT_diff_noNOK,\n",
    "        \"sdRT_noNOK\" : sd_RT_diff_noNOK \n",
    "    }\n",
    "    \n",
    "    # append to the dictionary in the existing file\n",
    "    with open(filename) as outfile:\n",
    "        old_data = json.load(outfile)\n",
    "    old_data.update(dict_)\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(old_data, outfile)\n",
    "\n",
    "    ind += 1\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),RT_diff_OKoo,yerr=sd_RT_diff_OKoo,c='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),RT_diff_no,yerr=sd_RT_diff_no,c='g',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),RT_diff_noNOK,yerr=sd_RT_diff_noNOK,c='m',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),SRT_diff_OKoo,yerr=Ssd_RT_diff_OKoo,c='b',ls='-')\n",
    "    ax[ind1,0].set_ylabel('median RT')\n",
    "    ax[6,ind2].set_xlabel('Difficulty')\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,5))\n",
    "    ax[0,0].legend((\"DO optout\",\"correct non-optout\",\"incorrect non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "    ax[ind1,ind2].set_ylim(0,2)\n",
    "    ax[6,3].axis('off')\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"subj_RT_no\":subj_RT_no,\n",
    "    \"Dsubj_RT_oo\":subj_RT_oo,\n",
    "    \"Ssubj_RT_oo\":Ssubj_RT_oo,\n",
    "    \"OKubj_RT_no\":OKsubj_RT_no,\n",
    "    \"OKDsubj_RT_oo\":OKsubj_RT_oo,\n",
    "    \"OKSsubj_RT_oo\":OKSsubj_RT_oo,\n",
    "    \"NOKubj_RT_no\":NOKsubj_RT_no,\n",
    "    \"NOKDsubj_RT_oo\":NOKsubj_RT_oo,\n",
    "    \"NOKSsubj_RT_oo\":NOKSsubj_RT_oo,\n",
    "    \"medianRT\":subj_medianRT\n",
    "}\n",
    "\n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5**: Median and standard deviation normalized reaction time vs difficulty for each participant in correct trials where she answer correctly. Green: non-optout correct trials. Magenta: non-optout incorrect trials. Red: DO optout correct trials. Blue: SO optout correct trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_RT_oo,Smean_subj_RT_oo,mean_subj_RT_no,se_subj_RT_oo,Sse_subj_RT_oo,se_subj_RT_no = [[] for _ in range(6)]\n",
    "for diff in range(4):\n",
    "    mean_subj_RT_oo.append(np.nanmean(np.array(subj_RT_diff_oo)[:,diff]))\n",
    "    Smean_subj_RT_oo.append(np.nanmean(np.array(Ssubj_RT_diff_oo)[:,diff]))\n",
    "    mean_subj_RT_no.append(np.nanmean(np.array(subj_RT_diff_no)[:,diff]))\n",
    "    se_subj_RT_oo.append(np.nanstd(np.array(subj_RT_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_RT_oo.append(np.nanstd(np.array(Ssubj_RT_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    se_subj_RT_no.append(np.nanstd(np.array(subj_RT_diff_no)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,5),mean_subj_RT_oo,se_subj_RT_oo,c='r')\n",
    "plt.errorbar(np.arange(1,5),mean_subj_RT_no,se_subj_RT_no,c='g')\n",
    "plt.errorbar(np.arange(1,5),Smean_subj_RT_oo,Sse_subj_RT_oo,c='b')\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean RT')\n",
    "plt.legend((\"DO optout\",\"non-optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 6**: Mean and standard error normalized reaction time of correct answers vs difficulty across participants. Green: non-optout correct trials. Red: DO optout correct trials. Blue: SO optout correct trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optout vs. difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "subj_optout_oo,Ssubj_optout_oo = [],[]\n",
    "subj_optout_diff_oo,Ssubj_optout_diff_oo = [],[]\n",
    "for part in sorted_subj_data:\n",
    "    optout_diff,Soptout_diff,se_optout_diff,Sse_optout_diff = [[] for _ in range(4)]\n",
    "    for diff in range(4):\n",
    "        # optout deterministic\n",
    "        subset_oob = Ddf_oo[part][(Ddf_oo[part][\"difficulty\"]==diff)]\n",
    "        oo_list = list(subset_oob.optout)\n",
    "        num_trials_oob = len(oo_list)\n",
    "        optout_diff.append(100*(np.sum(oo_list)/num_trials_oob))\n",
    "        se_optout_diff.append(100*np.sqrt(optout_diff[diff]/100 *(1-optout_diff[diff]/100)/num_trials_oob))\n",
    "        # optout stochastic\n",
    "        Ssubset_oob = Sdf_oo[part][(Sdf_oo[part][\"difficulty\"]==diff)]\n",
    "        Soo_list = list(Ssubset_oob.optout)\n",
    "        Snum_trials_oob = len(Soo_list)\n",
    "        Soptout_diff.append(100*(np.sum(Soo_list)/Snum_trials_oob))\n",
    "        Sse_optout_diff.append(100*np.sqrt(Soptout_diff[diff]/100 *(1-Soptout_diff[diff]/100)/Snum_trials_oob))\n",
    "\n",
    "    subj_optout_diff_oo.append(optout_diff)\n",
    "    Ssubj_optout_diff_oo.append(Soptout_diff)\n",
    "    \n",
    "    subj_optout_oo.append(np.nanmean(optout_diff))\n",
    "    Ssubj_optout_oo.append(np.nanmean(Soptout_diff))\n",
    "    \n",
    "    # write the result in file\n",
    "    filename=path_fit+'diff_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    dict_ = {\n",
    "        \"Doptout\" : optout_diff,\n",
    "        \"Dse_optout\" : se_optout_diff,\n",
    "        \"Soptout\" : Soptout_diff,\n",
    "        \"Sse_optout\" : Sse_optout_diff    \n",
    "    }\n",
    "    # append to the dictionary in the existing file\n",
    "    # append to the dictionary in the existing file\n",
    "    with open(filename) as outfile:\n",
    "        old_data = json.load(outfile)\n",
    "    old_data.update(dict_)\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(old_data, outfile)\n",
    "        \n",
    "    ind += 1\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].set_title('participant:'+str(part))\n",
    "    ax[ind1,ind2].set_ylim(-5,105)\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),optout_diff,yerr=se_optout_diff,color='r',ls='-')\n",
    "    ax[ind1,ind2].errorbar(np.arange(1,5),Soptout_diff,yerr=Sse_optout_diff,color='b',ls='-')\n",
    "    ax[ind1,0].set_ylabel('Optout')\n",
    "    ax[6,ind2].set_xlabel('Difficulty')\n",
    "    ax[0,0].legend((\"DO optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "    ax[ind1,ind2].set_xticks(np.arange(1,5))\n",
    "    ax[6,3].axis('off')\n",
    "    \n",
    "# write the result in file\n",
    "dict_ = {\n",
    "    \"Dsubj_optout_oo\" : subj_optout_oo,\n",
    "    \"Ssubj_optout_oo\" : Ssubj_optout_oo  \n",
    "}\n",
    "# append to the dictionary in the existing file\n",
    "# append to the dictionary in the existing file\n",
    "with open(filename_average) as outfile:\n",
    "    old_data = json.load(outfile)\n",
    "old_data.update(dict_)\n",
    "with open(filename_average, 'w') as outfile:\n",
    "    json.dump(old_data, outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 7**: Mean and standard deviation optout choice vs difficulty for each participant. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subj_optout_oo,Smean_subj_optout_oo,se_subj_optout_oo,Sse_subj_optout_oo = [[] for _ in range(4)]\n",
    "for diff in range(4):\n",
    "    mean_subj_optout_oo.append(np.nanmean(np.array(subj_optout_diff_oo)[:,diff]))\n",
    "    Smean_subj_optout_oo.append(np.nanmean(np.array(Ssubj_optout_diff_oo)[:,diff]))\n",
    "    se_subj_optout_oo.append(np.nanstd(np.array(subj_optout_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "    Sse_subj_optout_oo.append(np.nanstd(np.array(Ssubj_optout_diff_oo)[:,diff])/np.sqrt(len(sorted_subj_data)))\n",
    "plt.errorbar(np.arange(1,5),mean_subj_optout_oo,se_subj_optout_oo,c='r')\n",
    "plt.errorbar(np.arange(1,5),Smean_subj_optout_oo,Sse_subj_optout_oo,c='b')\n",
    "plt.xlabel('Difficulty')\n",
    "plt.ylabel('Population mean optout')\n",
    "plt.legend((\"DO optout\",\"SO optout\"),loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 8**: Mean and standard error optout choice vs difficulty across participants. Red: DO optout trials. Blue: SO optout trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psychometric curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON-optout psychometric curves\n",
    "\n",
    "Proportion of right answers vs. signed stimuli. \n",
    "\n",
    "$y = \\frac{1}{1+\\exp{-(\\beta_0+\\beta_1 x)}}$\n",
    "\n",
    "Sigmoid function as $sigmoid(z)$. \n",
    "\n",
    "- Bias: $\\beta_0$\n",
    "\n",
    "- Sensitivity: $ \\beta_1 $\n",
    "\n",
    "If $\\beta_0=0$ (no bias), then $y(x=0)=1/2$. If $\\beta_0>0$, then then $y(x=0)>1/2$ exposing a bias to rightward answers. Otherwise, there is a bias toward the left option. \n",
    "\n",
    "We can estimate the noise in the internal response $\\sigma^2$ and the decision boundary $H$ with the non-optout trials. If $x$ is the stimulus strength (i.e. signed signal), the participant observes $\\hat{x} = x + \\eta$, where $\\eta ~ N(0,\\sigma^2)$, and the participant answers to the right if $\\hat{x}>H$.\n",
    "\n",
    "Thus, we have $p(rightward|x) = \\int _{[H,+ \\infty ]} (x+ \\eta) d \\eta = \\int _{[H-x,+\\infty]} \\eta d \\eta = \\Phi(\\frac{x-H}{\\sigma})$ with $\\Phi$ as the standard normal cumulative.\n",
    "\n",
    "By fitting the psychometric curve we could estimate the noise $\\sigma$ and the decision boundary $H$. \n",
    "\n",
    "$p(rightward|x) = \\Phi(\\beta_0 + \\beta_1 x)$, with $\\beta_1=1/\\sigma$ and $\\beta_0=-H/\\sigma$\n",
    "\n",
    "We fitted the psychometric curve with the logistic regression:\n",
    "\n",
    "$p(rightward|x) = \\frac{1}{1+e^{-(\\beta_0+\\beta_1 x)}}$, \n",
    "\n",
    "with $\\sigma=1/\\beta_1$ and $H=-\\beta_0\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    st_no = list(df_no[part]['signed_signal'])\n",
    "    # stim axis\n",
    "    unique_stim = df_no[part]['signed_signal'].unique()\n",
    "    signed_st = sorted(unique_stim)\n",
    "    # load data\n",
    "    diff_no = list(df_no[part]['difficulty'])\n",
    "    orientation_no = list(df_no[part]['orientation'])\n",
    "    correct_no = list(df_no[part]['discrimination_is_correct'])\n",
    "    is_right_no = np.array(list(df_no[part]['resp_is_R']))\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    m_right_No, se_right_No = np.zeros(len(signed_st)),np.zeros(len(signed_st))\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    y_no = is_right_no.astype(int)  \n",
    "    # mean performance (%) over all the stim for each task\n",
    "    mean_perf_no = np.nanmean(correct_no)*100\n",
    "\n",
    "    for st in range(len(signed_st)):\n",
    "        mask_st = (st_no==signed_st[st])\n",
    "        m_right_No[st] = np.nanmean(y_no[mask_st]==1)\n",
    "        n_No = np.sum(mask_st)\n",
    "        se_right_No[st]= np.sqrt(m_right_No[st]*(1-m_right_No[st])/n_No)   \n",
    "\n",
    "    # reshape of stimuli arrays for the logistic regression\n",
    "    st_no = np.array(st_no).reshape(-1,1)\n",
    "    # add a column of ones to the stimuli arrays for the logistic regression\n",
    "    x_no = [[1,elem[0]] for elem in st_no]\n",
    "    # lists with beta resulting values of the fit for each type of trials in this \n",
    "    # particular session and for this particular participant\n",
    "    betas_no = []\n",
    "    # fitted curves\n",
    "    x_lr = np.arange(-0.2,0.2,0.01)\n",
    "    \n",
    "    ### wih logistic regression...\n",
    "    # y_lr_no = []\n",
    "    #lr_no = LogisticRegression(C=1000000, fit_intercept=False)\n",
    "    #lr_no.fit(x_no, y_no)\n",
    "    #betas_no = lr_no.coef_[0]\n",
    "    #score_no = np.round(lr_no.score(x_no, y_no),3)\n",
    "    # sigma: standard deviation of the internal response (with non optout)\n",
    "    # Hno: decision boundary in the non optout trials\n",
    "    #Sigma = 1/betas_no[1]\n",
    "    #Hno = -betas_no[0]*Sigma\n",
    "    #y_lr_no=myf.sigmoid(betas_no[0]+x_lr*betas_no[1])\n",
    "    #yRfit = myf.sigmoid(betas_no[0]+np.array(signed_st)*betas_no[1])\n",
    "    \n",
    "    # with probit regression...\n",
    "    pb_no = smf.glm(formula='resp_is_R ~ signed_signal', \n",
    "                family=sm.families.Binomial(link = sm.genmod.families.links.probit),\n",
    "                data=df_no[part]).fit()\n",
    "    params = pb_no.params\n",
    "    Hno = -params[0]/params[1]\n",
    "    Sigma = 1/params[1]\n",
    "    y_pr_no = [stats.norm.cdf((x-Hno)/Sigma) for x in x_lr]\n",
    "    yRfit = [stats.norm.cdf((x-Hno)/Sigma) for x in signed_st]\n",
    "    mse_no=myf.MSE_no(m_right_No,yRfit)\n",
    "    pearson_chi2=pb_no.pearson_chi2\n",
    "    \n",
    "    # write the result in file\n",
    "    filename=path_fit+'NO_fit_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    '''\n",
    "    if excluded_no!=0:\n",
    "        in_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        in_or_out = 'OK'\n",
    "    '''\n",
    "    dict_ = {\n",
    "        \"Hno\":Hno,\n",
    "        \"Sigma\":Sigma,\n",
    "        \"signed_st\":list(signed_st),\n",
    "        \"m_right_No\":list(m_right_No),\n",
    "        \"se_right_No\":list(se_right_No),\n",
    "        \"x_lr\":list(x_lr),\n",
    "        \"y_pr_no\":list(y_pr_no),\n",
    "        \"pearson_chi2\":pearson_chi2,\n",
    "        \"mean_perf_no\":mean_perf_no,\n",
    "        \"mse_no\":mse_no\n",
    "    }\n",
    "    # Serializing json  \n",
    "    json_object = json.dumps(dict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(filename, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results2 = path_results+'day'+str(fday)+'/session'+str(fsession)+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "# NO PC fit\n",
    "NOfit_files = [f for f in os.listdir(path_results2) if f.startswith('NO_fit')]\n",
    "auxNO = [f.replace('NO_fit_Sub','') for f in NOfit_files]\n",
    "subj_NOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in auxNO]\n",
    "sorted_subj_NOfit = sorted(subj_NOfit)\n",
    "index_subj_NOfit = [subj_NOfit.index(elem) for elem in sorted_subj_NOfit]\n",
    "sorted_NOfit_files = [NOfit_files[i] for i in index_subj_NOfit]\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "for part in sorted_subj_data:\n",
    "    # psychometric curve NON-optout\n",
    "    fNO = sorted_NOfit_files[ind]\n",
    "    filename=path_results2+fNO\n",
    "    with open(filename) as fNO:\n",
    "        dataNO = json.load(fNO)\n",
    "    for k, v in dataNO.items():\n",
    "        globals()[k]=v     \n",
    "    ind += 1\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].set_title(\"Participant \"+str(part))\n",
    "    ax[ind1,ind2].text(0.05, 0.2, 'pearson_chi2='+str(round(pearson_chi2,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(0.05, 0.3, 'bias='+str(round(Hno,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].errorbar(signed_st,m_right_No,se_right_No,c='g',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_lr,y_pr_no,c='g')\n",
    "    ax[0,0].legend((\"log-reg\",\"NG NO\"),loc='best', shadow=True)\n",
    "    ax[6,ind2].set_xlabel('signed signal')\n",
    "    ax[ind1,0].set_ylabel('proportion of right')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.17,0.17])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(Hno,color='g',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "    ax[ind1,ind2].text(0.05, 0.4,'mean perf:'+str(np.round(mean_perf_no)), ha='left', wrap=True) \n",
    "    ax[6,3].axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9**: Psychometric curves in non-optout trials for each participant. Dots: mean and sd proportion of rightward choice. Solid line: sigmoid function with logistic regression results. Dashed line: fit resulting decision boundary. Legend meaning of \"mean perf\": mean performance in non-optout trials, \"sigma\": fit resulting noise of the internal response, \"score\": goodness of fit (maximum: 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic optout psychometric curves\n",
    "\n",
    "In these trials, the participant has 3 options: L (leftward), R (rightward) and O (opt-out), where the proportion of rightward (leftward) answers vs. the signed stimuli is plotted as psychometric curves. The noise model is assumed to be multinomial, that is:\n",
    "\n",
    "$p(y_R,y_L,y_O,p_R,p_L,p_O) = \\frac{n!}{(y_Ln)!(y_Rn)!(y_On)!}p_L^{y_Ln}p_R^{y_Rn}p_O^{y_On}$, with $y_L+y_R+y_O=1$ and $y_k=\\frac{n_k}{n}$ are the fraction of trials where the participant chose each type of response.\n",
    "\n",
    "Assuming that $p_L \\sim 1-\\Phi(\\frac{x-H_L}{\\sigma})$, $p_R \\sim \\Phi(\\frac{x-H_R}{\\sigma})$ and $p_O = 1-p_L-p_R$. The stimulus was re-escaled to be bounded within the range $[-1,1]$.\n",
    "\n",
    "We are going to estimate $H_L,H_R$ and $\\sigma$ with maximum likelihood.\n",
    "\n",
    "### Logistic regression when the participant did not choose the optout\n",
    "\n",
    "Finally, if the participant did not choose the optout option, then $p_O \\sim 0$ and the multinomial probability distribution tend to be binomial. Thus, if the mean optout elections over all the stim is zero, we fit the psychometric curves with the logistic regression over the points where the participant did not choose the optout option.\n",
    "\n",
    "The x-axis: The 6 presented stimuli ordered as *[l1,l2,l3,r3,r2,r1]*, where 'l' means left, 'r' means right, and the numbers are the corresponding values for difficulty. Right stimuli are positive, while left stimuli are negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN AGAIN\n",
    "# deterministic optout\n",
    "  \n",
    "x_fit=np.linspace(-0.2,0.2,50)\n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Dst_oo = np.array(list(Ddf_oo[part]['signed_signal']))\n",
    "    # stim axis\n",
    "    Dunique_stim = Ddf_oo[part]['signed_signal'].unique()\n",
    "    Dsigned_st = np.array(sorted(Dunique_stim))\n",
    "    # load data\n",
    "    Ddiff_oo = list(Ddf_oo[part]['difficulty'])\n",
    "    Dorientation_oo = list(Ddf_oo[part]['orientation'])\n",
    "    Dcorrect_oo = np.array(list(Ddf_oo[part]['discrimination_is_correct']))\n",
    "    Dis_right_oo = np.array(list(Ddf_oo[part]['resp_is_R']))\n",
    "    D_oo= list(Ddf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Dm_right_oo, Dse_right_oo = np.zeros(len(Dsigned_st)),np.zeros(len(Dsigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Dy_oo = np.array(list(Ddf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Dmask_ = (Dy_oo!=2)\n",
    "    Dmean_perf_oo = np.nanmean(Dcorrect_oo[Dmask_])*100\n",
    "    Dmean_oo = np.nanmean(D_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Dm_right_oob,Dse_right_oob,Dm_left_oob,Dse_left_oob,Dm_opt_oob,Dse_opt_oob = [np.zeros(len(Dsigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Dsigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Dmask_oob = (Dst_oo==Dsigned_st[st])\n",
    "        # rightward\n",
    "        Dm_right_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==1)\n",
    "        Dn_oob = np.sum(Dmask_oob)\n",
    "        Dse_right_oob[st]= np.sqrt(Dm_right_oob[st]*(1-Dm_right_oob[st])/Dn_oob)\n",
    "        # leftward\n",
    "        Dm_left_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==0)\n",
    "        Dse_left_oob[st]= np.sqrt(Dm_left_oob[st]*(1-Dm_left_oob[st])/Dn_oob)\n",
    "        # optout\n",
    "        Dm_opt_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==2)\n",
    "        Dse_opt_oob[st]= np.sqrt(Dm_opt_oob[st]*(1-Dm_opt_oob[st])/Dn_oob)\n",
    "    n=Dst_oo.size\n",
    "\n",
    "    ## Psychometric fit\n",
    "    # Exclusion criterion: mean performance higher than 80% and \n",
    "    # mean optout election less than 80%\n",
    "    if Dmean_perf_oo>0 and Dmean_oo<100: \n",
    "        # Binomial fit: excluding the optout \n",
    "        if Dmean_oo<1:                   \n",
    "            Dmask_oob2 = (Dy_oo!=2)\n",
    "            # lists instead of arrays because have variable length in optout trials \n",
    "            Dst_oo = Dst_oo[Dmask_oob2]\n",
    "            # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "            Dy_oo=Dy_oo[Dmask_oob2]\n",
    "\n",
    "            Dresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Ddf_oo[part])\n",
    "            DHR_oo=Dresult[0][0]\n",
    "            DHL_oo=Dresult[0][1]\n",
    "            Dsigma_oo=Dresult[0][2]\n",
    "            Dexito=Dresult[1]\n",
    "\n",
    "            # with logistic regression...\n",
    "            '''\n",
    "            Dbeta0 = -DHR_oo/Dsigma_oo\n",
    "            Dbeta1 = 1/Dsigma_oo\n",
    "            DyR_fit=myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "            DyL_fit=1.0-myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "            DyR_fit_stim=myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "            DyL_fit_stim=1.0-myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "            '''\n",
    "\n",
    "            # with probit regression...\n",
    "            DyR_fit=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit]\n",
    "            DyL_fit=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit])\n",
    "            DyO_fit=np.zeros(len(x_fit))   \n",
    "            # fit result  over the stimuli values\n",
    "            DyR_fit_stim=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st]\n",
    "            DyL_fit_stim=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st])\n",
    "            DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "    \n",
    "            # mean squared error\n",
    "            Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "            DFit = 0\n",
    "            Dexcluded_oo=0\n",
    "        # Multinomial fit\n",
    "        else:\n",
    "            Dresult = myf.Wrandom_fit_oo_multinomial(Dsigned_st,Dm_right_oob,Dm_left_oob,Dm_opt_oob,n)\n",
    "            DHR_oo=Dresult[0][0]\n",
    "            DHL_oo=Dresult[0][1]\n",
    "            Dsigma_oo=Dresult[0][2]\n",
    "            Dexito=Dresult[1]\n",
    "            #print('[H_R  H_L  sigma]=',Dresult[0])\n",
    "            #print('success:',Dexito)\n",
    "            DyR_fit=myf.cumul_norm(x_fit,DHR_oo,Dsigma_oo)\n",
    "            DyL_fit=1.0-myf.cumul_norm(x_fit,DHL_oo,Dsigma_oo)\n",
    "            DyO_fit=1.0-DyR_fit-DyL_fit  \n",
    "            # fit result  over the stimuli values\n",
    "            DyR_fit_stim=myf.cumul_norm(Dsigned_st,DHR_oo,Dsigma_oo)\n",
    "            DyL_fit_stim=1.0-myf.cumul_norm(Dsigned_st,DHL_oo,Dsigma_oo)\n",
    "            DyO_fit_stim=1.0-DyR_fit_stim-DyL_fit_stim\n",
    "            # mean squared error\n",
    "            Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "            DFit = 1\n",
    "            Dexcluded_oo=0\n",
    "    elif Dmean_perf_oo<=0:\n",
    "        DyR_fit=np.zeros(len(x_fit))\n",
    "        DyL_fit=np.zeros(len(x_fit))\n",
    "        DyO_fit=np.zeros(len(x_fit))\n",
    "        # fit result  over the stimuli values\n",
    "        DyR_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyL_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        Dmse = m.nan\n",
    "        DHR_oo=1000000\n",
    "        DHL_oo=-1000000\n",
    "        Dsigma_oo=0\n",
    "        Dexito = False\n",
    "        Dexcluded_oo=1\n",
    "        DFit = 2\n",
    "    elif Dmean_oo>=100:\n",
    "        DyR_fit=np.zeros(len(x_fit))\n",
    "        DyL_fit=np.zeros(len(x_fit))\n",
    "        DyO_fit=np.ones(len(x_fit))\n",
    "        DHR_oo=1000000\n",
    "        DHL_oo=-1000000\n",
    "        Dsigma_oo=0\n",
    "        # fit result  over the stimuli values\n",
    "        DyR_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyL_fit_stim=np.zeros(len(Dsigned_st))\n",
    "        DyO_fit_stim=np.ones(len(Dsigned_st))\n",
    "        Dexito = False\n",
    "        Dmse = m.nan\n",
    "        DFit = 3\n",
    "        Dexcluded_oo=1\n",
    "        \n",
    "    # write the result in file\n",
    "    Dfilename=path_fit+'DO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    if Dexcluded_oo!=0:\n",
    "        in_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        in_or_out = 'OK'\n",
    "    Ddict_ = {\n",
    "        \"in_or_out\":in_or_out,\n",
    "        \"DHR_oo\":DHR_oo,\n",
    "        \"DHL_oo\":DHL_oo,\n",
    "        \"Dsigma_oo\":Dsigma_oo,\n",
    "        \"Dsigned_st\":list(Dsigned_st),\n",
    "        \"Dm_right_oob\":list(Dm_right_oob),\n",
    "        \"Dm_left_oob\":list(Dm_left_oob),\n",
    "        \"Dm_opt_oob\":list(Dm_opt_oob),\n",
    "        \"Dse_right_oob\":list(Dse_right_oob),\n",
    "        \"Dse_left_oob\":list(Dse_left_oob),\n",
    "        \"Dse_opt_oob\":list(Dse_opt_oob),\n",
    "        \"x_fit\":list(x_fit),\n",
    "        \"DyR_fit\":list(DyR_fit),\n",
    "        \"DyL_fit\":list(DyL_fit),\n",
    "        \"DyO_fit\":list(DyO_fit),\n",
    "        \"DyR_fit_stim\":list(DyR_fit_stim),\n",
    "        \"DyL_fit_stim\":list(DyL_fit_stim),\n",
    "        \"DyO_fit_stim\":list(DyO_fit_stim),\n",
    "        \"n\":int(n),\n",
    "        \"Dmse\":Dmse,\n",
    "        \"Dexito\":Dexito,\n",
    "        \"Dmean_perf_oo\":Dmean_perf_oo,\n",
    "        \"Dmean_oo\":Dmean_oo,\n",
    "        \"DFit\":DFit\n",
    "    }\n",
    "    # Serializing json  \n",
    "    Djson_object = json.dumps(Ddict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(Dfilename, \"w\") as outfile: \n",
    "        outfile.write(Djson_object) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dlist2change = np.load(path_results+'day'+str(fday)+'/session'+str(fsession)+'/DO_sub2changeFit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dlist2change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO not run again \n",
    "# this script change the fit from logistic to probit in DO trials where participants did not chose the optout\n",
    "x_fit=np.linspace(-0.2,0.2,200)\n",
    "\n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Dst_oo = np.array(list(Ddf_oo[part]['signed_signal']))\n",
    "    # stim axis\n",
    "    Dunique_stim = Ddf_oo[part]['signed_signal'].unique()\n",
    "    Dsigned_st = np.array(sorted(Dunique_stim))\n",
    "    # load data\n",
    "    Ddiff_oo = list(Ddf_oo[part]['difficulty'])\n",
    "    Dorientation_oo = list(Ddf_oo[part]['orientation'])\n",
    "    Dcorrect_oo = np.array(list(Ddf_oo[part]['discrimination_is_correct']))\n",
    "    Dis_right_oo = np.array(list(Ddf_oo[part]['resp_is_R']))\n",
    "    D_oo= list(Ddf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Dm_right_oo, Dse_right_oo = np.zeros(len(Dsigned_st)),np.zeros(len(Dsigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Dy_oo = np.array(list(Ddf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Dmask_ = (Dy_oo!=2)\n",
    "    Dmean_perf_oo = np.nanmean(Dcorrect_oo[Dmask_])*100\n",
    "    Dmean_oo = np.nanmean(D_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Dm_right_oob,Dse_right_oob,Dm_left_oob,Dse_left_oob,Dm_opt_oob,Dse_opt_oob = [np.zeros(len(Dsigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Dsigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Dmask_oob = (Dst_oo==Dsigned_st[st])\n",
    "        # rightward\n",
    "        Dm_right_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==1)\n",
    "        Dn_oob = np.sum(Dmask_oob)\n",
    "        Dse_right_oob[st]= np.sqrt(Dm_right_oob[st]*(1-Dm_right_oob[st])/Dn_oob)\n",
    "        # leftward\n",
    "        Dm_left_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==0)\n",
    "        Dse_left_oob[st]= np.sqrt(Dm_left_oob[st]*(1-Dm_left_oob[st])/Dn_oob)\n",
    "        # optout\n",
    "        Dm_opt_oob[st] = np.nanmean(Dy_oo[Dmask_oob]==2)\n",
    "        Dse_opt_oob[st]= np.sqrt(Dm_opt_oob[st]*(1-Dm_opt_oob[st])/Dn_oob)\n",
    "    n=Dst_oo.size\n",
    "\n",
    "    ## Psychometric fit               \n",
    "    Dmask_oob2 = (Dy_oo!=2)\n",
    "    # lists instead of arrays because have variable length in optout trials \n",
    "    Dst_oo = Dst_oo[Dmask_oob2]\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    Dy_oo=Dy_oo[Dmask_oob2]\n",
    "\n",
    "    Dresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Ddf_oo[part])\n",
    "    DHR_oo=Dresult[0][0]\n",
    "    DHL_oo=Dresult[0][1]\n",
    "    Dsigma_oo=Dresult[0][2]\n",
    "    Dexito=Dresult[1]\n",
    "\n",
    "    # with logistic regression...\n",
    "    '''\n",
    "    Dbeta0 = -DHR_oo/Dsigma_oo\n",
    "    Dbeta1 = 1/Dsigma_oo\n",
    "    DyR_fit=myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "    DyL_fit=1.0-myf.sigmoid(Dbeta0+x_fit*Dbeta1)\n",
    "    DyR_fit_stim=myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "    DyL_fit_stim=1.0-myf.sigmoid(Dbeta0+Dsigned_st*Dbeta1)\n",
    "    '''\n",
    "\n",
    "    # with probit regression...\n",
    "    DyR_fit=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit]\n",
    "    DyL_fit=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in x_fit])\n",
    "    DyO_fit=np.zeros(len(x_fit))   \n",
    "    # fit result  over the stimuli values\n",
    "    DyR_fit_stim=[stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st]\n",
    "    DyL_fit_stim=1.0-np.array([stats.norm.cdf((x-DHR_oo)/Dsigma_oo) for x in Dsigned_st])\n",
    "    DyO_fit_stim=np.zeros(len(Dsigned_st))\n",
    "    \n",
    "    # mean squared error\n",
    "    Dmse = myf.MSE_oo(Dm_right_oob,Dm_left_oob,Dm_opt_oob,DyR_fit_stim,DyL_fit_stim,DyO_fit_stim)\n",
    "    DFit = 0\n",
    "    Dexcluded_oo=0    \n",
    "    \n",
    "    filename = 'DO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    with open(path_results+'day'+str(fday)+'/session'+str(fsession)+'/'+filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data[\"DHR_oo\"]=DHR_oo\n",
    "        data[\"DHL_oo\"]=DHL_oo\n",
    "        data[\"Dsigma_oo\"]=Dsigma_oo\n",
    "        data[\"DyR_fit\"]=list(DyR_fit)\n",
    "        data[\"DyL_fit\"]=list(DyL_fit)\n",
    "        data[\"DyR_fit_stim\"]=list(DyR_fit_stim)\n",
    "        data[\"DyL_fit_stim\"]=list(DyL_fit_stim)\n",
    "        data[\"Dmse\"]=Dmse\n",
    "        data[\"Dexito\"]=Dexito\n",
    "     \n",
    "    with open(path_results+'day'+str(fday)+'/session'+str(fsession)+'/'+filename,\"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# Deterministic PC fit\n",
    "DOfit_files = [f for f in os.listdir(path_results2) if f.startswith('DO_fit')]\n",
    "aux = [f.replace('DO_fit_oo_Sub','') for f in DOfit_files]\n",
    "subj_DOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in aux]\n",
    "sorted_subj_DOfit = sorted(subj_DOfit)\n",
    "index_subj_DOfit = [subj_DOfit.index(elem) for elem in sorted_subj_DOfit]\n",
    "sorted_DOfit_files = [DOfit_files[i] for i in index_subj_DOfit]\n",
    "\n",
    "ind = -1\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "for part in sorted_subj_data:\n",
    "    ind += 1\n",
    "    # deterministic PC fit\n",
    "    f = sorted_DOfit_files[ind]\n",
    "    filename=path_results2+f\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for k, v in data.items():\n",
    "        globals()[k]=v        \n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].text(-0.14, 1.0, 'mean optout ='+str(np.round(Dmean_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.9, 'mean perf ='+str(np.round(Dmean_perf_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.8, 'sigma ='+str(np.round(Dsigma_oo,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.7, 'mse ='+str(np.round(Dmse,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].set_title(\"participant \"+str(part))\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_right_oob,Dse_right_oob,c='r',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_left_oob,Dse_left_oob,c='m',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Dsigned_st,Dm_opt_oob,Dse_opt_oob,c='g',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_fit,DyR_fit,c='r')   \n",
    "    ax[ind1,ind2].plot(x_fit,DyL_fit,c='m')\n",
    "    ax[ind1,ind2].plot(x_fit,DyO_fit,c='g')\n",
    "    ax[0,0].legend((\"DO right\",\"DO left\",\"DO opt-out\"),loc='best', shadow=True)\n",
    "    ax[6,ind2].set_xlabel('signed signal')\n",
    "    ax[ind1,0].set_ylabel('response proportion')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.17,0.17])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(DHR_oo,color='r',ls='--')\n",
    "    ax[ind1,ind2].axvline(DHL_oo,color='m',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "    ax[6,3].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10**: Psychometric curves in DO optout trials for each participant. Red (magenta, green) dots: mean and sd proportion of rightward (leftward, optout) choice. Red (magenta, green) solid line: sigmoid function with maximum likelihood (if mean optout choice > 0) or logistic regression (if mean optout = 0) results for rightward (leftward, optout) choice. Red (magenta, green) dashed line: resulting decision boundary for rightward (leftward, optout) choice. Legend meaning of \"mean optout\": mean optout election, \"mean perf\": mean performance in non-optout trials, \"sigma\": fit resulting noise of the internal response, \"mse\": mean square error as goodness of fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic optout psychometric curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slist2change = np.load(path_results+'day'+str(fday)+'/session'+str(fsession)+'/SO_sub2changeFit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slist2change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit=np.linspace(-0.2,0.2,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO not run again \n",
    "# this script change the fit from logistic to probit in DO trials where participants did not chose the optout\n",
    "\n",
    "for part in Slist2change:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Sst_oo = np.array(list(Sdf_oo[part]['signed_signal']))\n",
    "    # stim axis\n",
    "    Sunique_stim = Sdf_oo[part]['signed_signal'].unique()\n",
    "    Ssigned_st = np.array(sorted(Sunique_stim))\n",
    "    # load data\n",
    "    Sdiff_oo = list(Sdf_oo[part]['difficulty'])\n",
    "    Sorientation_oo = list(Sdf_oo[part]['orientation'])\n",
    "    Scorrect_oo = np.array(list(Sdf_oo[part]['discrimination_is_correct']))\n",
    "    Sis_right_oo = np.array(list(Sdf_oo[part]['resp_is_R']))\n",
    "    S_oo= list(Sdf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Sm_right_oo, Sse_right_oo = np.zeros(len(Ssigned_st)),np.zeros(len(Ssigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Sy_oo = np.array(list(Sdf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Smask_ = (Sy_oo!=2)\n",
    "    Smean_perf_oo = np.nanmean(Scorrect_oo[Smask_])*100\n",
    "    Smean_oo = np.nanmean(S_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Sm_right_oob,Sse_right_oob,Sm_left_oob,Sse_left_oob,Sm_opt_oob,Sse_opt_oob = [np.zeros(len(Ssigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Ssigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Smask_oob = (Sst_oo==Ssigned_st[st])\n",
    "        # rightward\n",
    "        Sm_right_oob[st] = np.nanmean(Sy_oo[Smask_oob]==1)\n",
    "        Sn_oob = np.sum(Smask_oob)\n",
    "        Sse_right_oob[st]= np.sqrt(Sm_right_oob[st]*(1-Sm_right_oob[st])/Sn_oob)\n",
    "        # leftward\n",
    "        Sm_left_oob[st] = np.nanmean(Sy_oo[Smask_oob]==0)\n",
    "        Sse_left_oob[st]= np.sqrt(Sm_left_oob[st]*(1-Sm_left_oob[st])/Sn_oob)\n",
    "        # optout\n",
    "        Sm_opt_oob[st] = np.nanmean(Sy_oo[Smask_oob]==2)\n",
    "        Sse_opt_oob[st]= np.sqrt(Sm_opt_oob[st]*(1-Sm_opt_oob[st])/Sn_oob)\n",
    "    n=np.sum(Sst_oo)\n",
    "\n",
    "    ## Psychometric fit               \n",
    "    Smask_oob2 = (Sy_oo!=2)\n",
    "    # lists instead of arrays because have variable length in optout trials \n",
    "    Sst_oo = Sst_oo[Smask_oob2]\n",
    "    # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "    Sy_oo = Sy_oo[Smask_oob2]\n",
    "\n",
    "    Sresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Sdf_oo[part])\n",
    "    \n",
    "    SHR_oo=Sresult[0][0]\n",
    "    SHL_oo=Sresult[0][1]\n",
    "    Ssigma_oo=Sresult[0][2]\n",
    "    Sexito=Sresult[1]\n",
    "\n",
    "    # with logistic regression...\n",
    "    '''\n",
    "    Sbeta0 = -SHR_oo/Ssigma_oo\n",
    "    Sbeta1 = 1/Ssigma_oo\n",
    "    SyR_fit=myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "    SyL_fit=1.0-myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "    SyO_fit=np.zeros(len(x_fit))\n",
    "    # fit result  over the stimuli values\n",
    "    SyR_fit_stim=myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "    SyL_fit_stim=1.0-myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "    SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "    '''\n",
    "\n",
    "    # with probit regression...\n",
    "    SyR_fit=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit]\n",
    "    SyL_fit=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit])\n",
    "    SyO_fit=np.zeros(len(x_fit))   \n",
    "    # fit result  over the stimuli values\n",
    "    SyR_fit_stim=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st]\n",
    "    SyL_fit_stim=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st])\n",
    "    SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "    \n",
    "    # mean squared error\n",
    "    Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)  \n",
    "    \n",
    "    filename = 'SO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    with open(path_results+'day'+str(fday)+'/session'+str(fsession)+'/'+filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data[\"SHR_oo\"]=SHR_oo\n",
    "        data[\"SHL_oo\"]=SHL_oo\n",
    "        data[\"Ssigma_oo\"]=Ssigma_oo\n",
    "        data[\"SyR_fit\"]=list(SyR_fit)\n",
    "        data[\"SyL_fit\"]=list(SyL_fit)\n",
    "        data[\"SyR_fit_stim\"]=list(SyR_fit_stim)\n",
    "        data[\"SyL_fit_stim\"]=list(SyL_fit_stim)\n",
    "        data[\"Smse\"]=Smse\n",
    "        data[\"Sexito\"]=Sexito\n",
    "     \n",
    "    with open(path_results+'day'+str(fday)+'/session'+str(fsession)+'/'+filename,\"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN!\n",
    "\n",
    "# stochastic optout\n",
    "ind = -1 \n",
    "for part in sorted_subj_data:\n",
    "    # load list with the signed strenght stimuli\n",
    "    Sst_oo = np.array(list(Sdf_oo[part]['signed_signal']))\n",
    "    # stim axis\n",
    "    Sunique_stim = Sdf_oo[part]['signed_signal'].unique()\n",
    "    Ssigned_st = np.array(sorted(Sunique_stim))\n",
    "    # load data\n",
    "    Sdiff_oo = list(Sdf_oo[part]['difficulty'])\n",
    "    Sorientation_oo = list(Sdf_oo[part]['orientation'])\n",
    "    Scorrect_oo = np.array(list(Sdf_oo[part]['discrimination_is_correct']))\n",
    "    Sis_right_oo = np.array(list(Sdf_oo[part]['resp_is_R']))\n",
    "    S_oo= list(Sdf_oo[part]['optout'])\n",
    "    # mean and se of righrward answers in non optout trials    \n",
    "    Sm_right_oo, Sse_right_oo = np.zeros(len(Ssigned_st)),np.zeros(len(Ssigned_st))\n",
    "    # arrays with answers in optout trials: 1 rightwars and 0 leftward and 2 for optout\n",
    "    Sy_oo = np.array(list(Sdf_oo[part]['answer']))\n",
    "    # mean performance (%) over all the stim for each task\n",
    "    Smask_ = (Sy_oo!=2)\n",
    "    Smean_perf_oo = np.nanmean(Scorrect_oo[Smask_])*100\n",
    "    Smean_oo = np.nanmean(S_oo)*100\n",
    "    # mean and se of answers in optout trials    \n",
    "    Sm_right_oob,Sse_right_oob,Sm_left_oob,Sse_left_oob,Sm_opt_oob,Sse_opt_oob = [np.zeros(len(Ssigned_st)) for _ in range(6)]\n",
    "    for st in range(len(Ssigned_st)):\n",
    "        # this selection sum up 1 with the 3 options: left, right, optout\n",
    "        Smask_oob = (Sst_oo==Ssigned_st[st])\n",
    "        # rightward\n",
    "        Sm_right_oob[st] = np.nanmean(Sy_oo[Smask_oob]==1)\n",
    "        Sn_oob = np.sum(Smask_oob)\n",
    "        Sse_right_oob[st]= np.sqrt(Sm_right_oob[st]*(1-Sm_right_oob[st])/Sn_oob)\n",
    "        # leftward\n",
    "        Sm_left_oob[st] = np.nanmean(Sy_oo[Smask_oob]==0)\n",
    "        Sse_left_oob[st]= np.sqrt(Sm_left_oob[st]*(1-Sm_left_oob[st])/Sn_oob)\n",
    "        # optout\n",
    "        Sm_opt_oob[st] = np.nanmean(Sy_oo[Smask_oob]==2)\n",
    "        Sse_opt_oob[st]= np.sqrt(Sm_opt_oob[st]*(1-Sm_opt_oob[st])/Sn_oob)\n",
    "    n=np.sum(Sst_oo)\n",
    "\n",
    "    ## Psychometric fit\n",
    "    # Exclusion criterion: mean performance higher than 80% and \n",
    "    # mean optout election less than 80%\n",
    "    if Smean_perf_oo>0 and Smean_oo<100: \n",
    "        # Binomial fit: excluding the optout \n",
    "        if Smean_oo<1:                   \n",
    "            Smask_oob2 = (Sy_oo!=2)\n",
    "            # lists instead of arrays because have variable length in optout trials \n",
    "            Sst_oo = Sst_oo[Smask_oob2]\n",
    "            # arrays with answers in non optout trials: 1 rightwars and 0 leftward\n",
    "            Sy_oo = Sy_oo[Smask_oob2]\n",
    "\n",
    "            Sresult = myf.fit_oo_binomial('signed_signal','resp_is_R',Sdf_oo[part])\n",
    "\n",
    "            SHR_oo=Sresult[0][0]\n",
    "            SHL_oo=Sresult[0][1]\n",
    "            Ssigma_oo=Sresult[0][2]\n",
    "            Sexito=Sresult[1]\n",
    "\n",
    "            # with logistic regression...\n",
    "            '''\n",
    "            Sbeta0 = -SHR_oo/Ssigma_oo\n",
    "            Sbeta1 = 1/Ssigma_oo\n",
    "            SyR_fit=myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "            SyL_fit=1.0-myf.sigmoid(Sbeta0+x_fit*Sbeta1)\n",
    "            SyO_fit=np.zeros(len(x_fit))\n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "            SyL_fit_stim=1.0-myf.sigmoid(Sbeta0+Ssigned_st*Sbeta1)\n",
    "            SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "            '''\n",
    "\n",
    "            # with probit regression...\n",
    "            SyR_fit=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit]\n",
    "            SyL_fit=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in x_fit])\n",
    "            SyO_fit=np.zeros(len(x_fit))   \n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=[stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st]\n",
    "            SyL_fit_stim=1.0-np.array([stats.norm.cdf((x-SHR_oo)/Ssigma_oo) for x in Ssigned_st])\n",
    "            SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "    \n",
    "            # mean squared error\n",
    "            Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)\n",
    "            SFit = 0\n",
    "            Sexcluded_oo=0\n",
    "        # Multinomial fit\n",
    "        else:\n",
    "            Sresult = myf.Wrandom_fit_oo_multinomial(Ssigned_st,Sm_right_oob,Sm_left_oob,Sm_opt_oob,n)\n",
    "            SHR_oo=Sresult[0][0]\n",
    "            SHL_oo=Sresult[0][1]\n",
    "            Ssigma_oo=Sresult[0][2]\n",
    "            Sexito=Sresult[1]\n",
    "            #print('[H_R  H_L  sigma]=',Sresult[0])\n",
    "            #print('success:',Sexito)\n",
    "            SyR_fit=myf.cumul_norm(x_fit,SHR_oo,Ssigma_oo)\n",
    "            SyL_fit=1.0-myf.cumul_norm(x_fit,SHL_oo,Ssigma_oo)\n",
    "            SyO_fit=1.0-SyR_fit-SyL_fit  \n",
    "            # fit result  over the stimuli values\n",
    "            SyR_fit_stim=myf.cumul_norm(Ssigned_st,SHR_oo,Ssigma_oo)\n",
    "            SyL_fit_stim=1.0-myf.cumul_norm(Ssigned_st,SHL_oo,Ssigma_oo)\n",
    "            SyO_fit_stim=1.0-SyR_fit_stim-SyL_fit_stim\n",
    "            # mean squared error\n",
    "            Smse = myf.MSE_oo(Sm_right_oob,Sm_left_oob,Sm_opt_oob,SyR_fit_stim,SyL_fit_stim,SyO_fit_stim)\n",
    "            SFit = 1\n",
    "            Sexcluded_oo=0\n",
    "    elif Smean_perf_oo<=0:\n",
    "        SyR_fit=np.zeros(len(x_fit))\n",
    "        SyL_fit=np.zeros(len(x_fit))\n",
    "        SyO_fit=np.zeros(len(x_fit))\n",
    "        # fit result  over the stimuli values\n",
    "        SyR_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyL_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyO_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        Smse = m.nan\n",
    "        SHR_oo=1000000\n",
    "        SHL_oo=-1000000\n",
    "        Ssigma_oo=0\n",
    "        Sexito = False\n",
    "        Sexcluded_oo=1\n",
    "        SFit = 2\n",
    "    elif Smean_oo>=100:\n",
    "        SyR_fit=np.zeros(len(x_fit))\n",
    "        SyL_fit=np.zeros(len(x_fit))\n",
    "        SyO_fit=np.ones(len(x_fit))\n",
    "        SHR_oo=1000000\n",
    "        SHL_oo=-1000000\n",
    "        Sexito = False\n",
    "        Ssigma_oo=0\n",
    "        # fit result  over the stimuli values\n",
    "        SyR_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyL_fit_stim=np.zeros(len(Ssigned_st))\n",
    "        SyO_fit_stim=np.ones(len(Ssigned_st))\n",
    "        Smse = m.nan\n",
    "        SFit = 3\n",
    "        Sexcluded_oo=1\n",
    "\n",
    "    # write the result in file\n",
    "    Sfilename=path_fit+'SO_fit_oo_Sub'+str(part)+'_Day'+str(fday)+'_Sess'+str(fsession)+'.json'\n",
    "    if Sexcluded_oo!=0:\n",
    "        Sin_or_out = 'EXCLUIDO'\n",
    "    else:\n",
    "        Sin_or_out = 'OK'\n",
    "    Sdict_ = {\n",
    "        \"Sin_or_out\":Sin_or_out,\n",
    "        \"SHR_oo\":SHR_oo,\n",
    "        \"SHL_oo\":SHL_oo,\n",
    "        \"Ssigma_oo\":Ssigma_oo,\n",
    "        \"Ssigned_st\":list(Ssigned_st),\n",
    "        \"Sm_right_oob\":list(Sm_right_oob),\n",
    "        \"Sm_left_oob\":list(Sm_left_oob),\n",
    "        \"Sm_opt_oob\":list(Sm_opt_oob),\n",
    "        \"Sse_right_oob\":list(Sse_right_oob),\n",
    "        \"Sse_left_oob\":list(Sse_left_oob),\n",
    "        \"Sse_opt_oob\":list(Sse_opt_oob),\n",
    "        \"x_fit\":list(x_fit),\n",
    "        \"SyR_fit\":list(SyR_fit),\n",
    "        \"SyL_fit\":list(SyL_fit),\n",
    "        \"SyO_fit\":list(SyO_fit),\n",
    "        \"SyR_fit_stim\":list(SyR_fit_stim),\n",
    "        \"SyL_fit_stim\":list(SyL_fit_stim),\n",
    "        \"SyO_fit_stim\":list(SyO_fit_stim),\n",
    "        \"n\":int(n),\n",
    "        \"Smse\":Smse,\n",
    "        \"Sexito\":Sexito,\n",
    "        \"Smean_perf_oo\":Smean_perf_oo,\n",
    "        \"Smean_oo\":Smean_oo,\n",
    "        \"SFit\":SFit\n",
    "    }\n",
    "    # Serializing json  \n",
    "    Sjson_object = json.dumps(Sdict_) \n",
    "\n",
    "    # Writing to sample.json \n",
    "    with open(Sfilename, \"w\") as outfile: \n",
    "        outfile.write(Sjson_object) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "# Stochastic PC fit\n",
    "SOfit_files = [f for f in os.listdir(path_results2) if f.startswith('SO_fit')]\n",
    "auxSO = [f.replace('SO_fit_oo_Sub','') for f in SOfit_files]\n",
    "subj_SOfit = [int(f.replace('_Day'+str(fday)+'_Sess'+str(fsession)+'.json','')) for f in auxSO]\n",
    "sorted_subj_SOfit = sorted(subj_SOfit)\n",
    "index_subj_SOfit = [subj_SOfit.index(elem) for elem in sorted_subj_SOfit]\n",
    "sorted_SOfit_files = [SOfit_files[i] for i in index_subj_SOfit]\n",
    "\n",
    "fig, ax = plt.subplots(7,4,figsize=(18,25))\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "ind = -1 \n",
    "for part in sorted_subj_data:\n",
    "    ind += 1 \n",
    "    # stochastic PC fit\n",
    "    fSO = sorted_SOfit_files[ind]\n",
    "    filename=path_results2+fSO\n",
    "    with open(filename) as fSO:\n",
    "        dataSO = json.load(fSO)\n",
    "    for k, v in dataSO.items():\n",
    "        globals()[k]=v  \n",
    "    if part==3076:\n",
    "        print(len(x_fit))\n",
    "    ind1 = ind%7\n",
    "    ind2 = int(round(ind/7,1))\n",
    "    ax[ind1,ind2].text(-0.14, 1.0, 'mean optout ='+str(np.round(Smean_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.9, 'mean perf ='+str(np.round(Smean_perf_oo,2)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.8, 'sigma ='+str(np.round(Ssigma_oo,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].text(-0.14, 0.7, 'mse ='+str(np.round(Smse,3)), ha='left', wrap=True)\n",
    "    ax[ind1,ind2].set_title(\"participant \"+str(part))\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_right_oob,Sse_right_oob,c='b',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_left_oob,Sse_left_oob,c='c',marker='o',ls='')\n",
    "    ax[ind1,ind2].errorbar(Ssigned_st,Sm_opt_oob,Sse_opt_oob,c='y',marker='o',ls='')\n",
    "    ax[ind1,ind2].plot(x_fit,SyR_fit,c='b')   \n",
    "    ax[ind1,ind2].plot(x_fit,SyL_fit,c='c')\n",
    "    ax[ind1,ind2].plot(x_fit,SyO_fit,c='y')\n",
    "    ax[0,0].legend((\"SO right\",\"SO left\",\"SO opt-out\"),loc='best', shadow=True)\n",
    "    ax[6,ind2].set_xlabel('signed signal')\n",
    "    ax[ind1,0].set_ylabel('response proportion')\n",
    "    ax[ind1,ind2].set_ylim([-0.1,1.1])\n",
    "    ax[ind1,ind2].set_xlim([-0.17,0.17])\n",
    "    ax[ind1,ind2].axvline(0,color='k')\n",
    "    ax[ind1,ind2].axvline(SHR_oo,color='b',ls='--')\n",
    "    ax[ind1,ind2].axvline(SHL_oo,color='c',ls='--')\n",
    "    ax[ind1,ind2].axhline(0.5,color='k')\n",
    "    ax[6,3].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 11**: Psychometric curves in SO optout trials for each participant. Blue (cyan, yellow) dots: mean and sd proportion of rightward (leftward, optout) choice. Blue (cyan, yellow) solid line: sigmoid function with maximum likelihood (if mean optout choice > 0) or logistic regression (if mean optout = 0) results for rightward (leftward, optout) choice. Blue (cyan, yellow) dashed line: resulting decision boundary for rightward (leftward, optout) choice. Legend meaning of \"mean optout\": mean optout election, \"mean perf\": mean performance in non-optout trials, \"sigma\": fit resulting noise of the internal response, \"mse\": mean square error as goodness of fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winners\n",
    "\n",
    "Since the first and second winner of each session receive extra payment, we compute the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = []\n",
    "print('part','score')\n",
    "for part in sorted_subj_data:\n",
    "    total_score.append(np.sum(Ddf[part]['score'])+np.sum(Sdf[part]['score']))\n",
    "    print(part,np.sum(Ddf[part]['score'])+np.sum(Sdf[part]['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 2**: Score table. Column 'part' with participant number ID. Column 'score' with the total amount of points for each participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = np.zeros(4)\n",
    "winners[0] = fday\n",
    "winners[1] = fsession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_total_score = sorted(total_score, reverse=True)\n",
    "if len(np.where(total_score==sorted_total_score[0])[0])==2:\n",
    "    winners[2] = sorted_subj_data[np.where(total_score==sorted_total_score[0])[0][0]]\n",
    "    winners[3] = sorted_subj_data[np.where(total_score==sorted_total_score[0])[0][1]]\n",
    "elif len(np.where(total_score==sorted_total_score[0])[0])>2:\n",
    "    print('más de dos ganadores!!!')\n",
    "else:\n",
    "    winners[2] = sorted_subj_data[total_score.index(sorted_total_score[0])]\n",
    "    winners[3] = sorted_subj_data[total_score.index(sorted_total_score[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('winners of the current session:',int(winners[2]),int(winners[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
