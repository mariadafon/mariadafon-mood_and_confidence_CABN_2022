{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final step: starting from preanalysis.csv and per_difficulty files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats,signal\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/dots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, main_path+'/src')\n",
    "import my_functions as myf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 1\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 1\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 1\n",
    "mpl.rcParams['ytick.major.width'] = 1\n",
    "mpl.rcParams['ytick.minor.width'] = 1\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]\n",
    "unique_signals = [1,2,3,4]\n",
    "\n",
    "adf = pd.read_csv(path_results+'preanalyzed.csv')  \n",
    "df_diff = pd.read_csv(path_results+'per_difficulty.csv')  \n",
    "dfANOVA = pd.read_csv(path_results+'forANOVA.csv') \n",
    "dfLR = pd.read_csv(path_results+'linearRegr_diff.csv') \n",
    "\n",
    "adf = pd.merge(dfLR,adf,on='user_sessionID',how='outer') \n",
    "# sort df by userID and sessionID in second place\n",
    "adf = adf.sort_values(by = ['userID', 'sessionID_y'])\n",
    "\n",
    "userids = adf['userID'].unique()\n",
    "userids = sorted(userids)\n",
    "nsub = len(userids)\n",
    "sessionids = adf['sessionID_x'].unique()\n",
    "sessionids = sorted(sessionids)\n",
    "\n",
    "# morning df\n",
    "mdf = adf[adf['sessionID_x']%2==1]\n",
    "# evening df\n",
    "edf = adf[adf['sessionID_x']%2==0]\n",
    "edf_sin_nan = edf.copy()\n",
    "edf_sin_nan['sleep']=list(mdf['sleep'])\n",
    "\n",
    "key_SR = ['mood','food','sleep', 'real_stress']\n",
    "key_PV = ['Dsubj_optout_oo','Ssubj_optout_oo','subj_perf_no','OKubj_RT_no','DoverConf','SoverConf','risk_av']\n",
    "key_LR = ['slope_RT', 'slope_DO', 'slope_SO', 'intercept_RT', 'intercept_DO','intercept_SO']\n",
    "key_name = key_SR+key_PV\n",
    "\n",
    "key_SR2plot = [key_SR[:int(len(key_SR)/2)],key_SR[int(len(key_SR)/2):]]\n",
    "pair_keys_SR = list(itertools.combinations(key_SR, 2))\n",
    "\n",
    "# pair of PV \n",
    "pair_keys_PV = list(itertools.combinations(key_PV[:-3], 2))\n",
    "pair_keys_PV2plot = [pair_keys_PV[:int(len(pair_keys_PV)/2)],pair_keys_PV[int(len(pair_keys_PV)/2):]]\n",
    "key_name_PV = {'Dsubj_optout_oo':'DO','Ssubj_optout_oo':'SO','subj_perf_no':'acc NO','OKubj_RT_no':'RT NO'}\n",
    "pair_key_name_PV2plot = [[[key_name_PV[k] for k in tupl] for tupl in lista] for lista in pair_keys_PV2plot]\n",
    "\n",
    "SR_color = {'mood': 'b','food': 'r','sleep': 'y', 'real_stress':'g'}\n",
    "\n",
    "key_diff = ['Dperf_oo', 'Sperf_oo', 'perf_no', 'Dn_trials_oo', 'Sn_trials_oo', 'NOn_trials', 'DRT_oo', 'SRT_oo', \\\n",
    "            'DRT_OKoo', 'SRT_OKoo', 'RT_no', 'RT_noNOK', 'Doptout', 'Soptout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfANOVA_MAS = dfANOVA.groupby(['userID','difficulty','type']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    print(i,stats.ttest_rel(dfANOVA_MAS[(dfANOVA_MAS['type']=='DO') & (dfANOVA_MAS['difficulty']==i)].perf,\\\n",
    "                          dfANOVA_MAS[(dfANOVA_MAS['type']=='NO') & (dfANOVA_MAS['difficulty']==i)].perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    print(i,stats.ttest_rel(dfANOVA_MAS[(dfANOVA_MAS['type']=='SO') & (dfANOVA_MAS['difficulty']==i)].perf,\\\n",
    "                          dfANOVA_MAS[(dfANOVA_MAS['type']=='NO') & (dfANOVA_MAS['difficulty']==i)].perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_MAS = dfANOVA.groupby(['userID','type']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adf_MAS[adf_MAS['type']=='DO'].perf,alpha=0.5,color='r')\n",
    "plt.hist(adf_MAS[adf_MAS['type']=='NO'].perf,alpha=0.5,color='k')\n",
    "plt.hist(adf_MAS[adf_MAS['type']=='SO'].perf,alpha=0.5,color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(adf_MAS[adf_MAS['type']=='NO'].perf,adf_MAS[adf_MAS['type']=='DO'].perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3896527982696632e-05*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(adf_MAS[adf_MAS['type']=='NO'].perf,adf_MAS[adf_MAS['type']=='SO'].perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0935066696143903e-09*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, se = {},{}\n",
    "for (var, op) in [(ap, np.nanmean), (se, myf.sem)]:\n",
    "    for key in key_name:\n",
    "        if key != 'sleep':\n",
    "            var[key] = [op(np.array(adf[adf['sessionID_x']==sesid][key])) for sesid in sessionids]\n",
    "        else:\n",
    "            var[key] = [op(np.array(mdf[mdf['sessionID_x']==sesid][key])) for sesid in sessionids[0::2]]\n",
    "session_labels = ['Th','Fr','Sa','Su','Mo','Tu','We','Th','Fr','Sa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN AGAIN !!!\n",
    "\n",
    "# write the result in file\n",
    "filename_ap=path_results+'mean_across_participants.json'\n",
    "filename_se=path_results+'se_across_participants.json'\n",
    "# Serializing json  \n",
    "json_object_ap = json.dumps(ap) \n",
    "json_object_se = json.dumps(se)\n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_ap, \"w\") as outfile: \n",
    "    outfile.write(json_object_ap) \n",
    "with open(filename_se, \"w\") as outfile: \n",
    "    outfile.write(json_object_se) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-reports (figure 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(18,8))\n",
    "plt.subplots_adjust(hspace = 0.3)  \n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        lower_limit = np.min(ap[key_SR2plot[j][i]])-np.max(se[key_SR2plot[j][i]])\n",
    "        upper_limit = np.max(ap[key_SR2plot[j][i]])+np.max(se[key_SR2plot[j][i]])\n",
    "        ax[i,j].fill_between([4,8],lower_limit,upper_limit,color=[0.9,0.9,0.9])\n",
    "        ax[i,j].fill_between([18,20],lower_limit,upper_limit,color=[0.9,0.9,0.9])\n",
    "        ax[i,j].set_xticks(np.arange(1,21)[::2])\n",
    "        ax[i,j].set_xticklabels(session_labels,rotation=45)\n",
    "        if key_SR2plot[j][i]=='real_stress':\n",
    "            label = 'stress'\n",
    "        else:\n",
    "            label = key_SR2plot[j][i]\n",
    "        ax[i,j].set_ylabel(label)\n",
    "        if key_SR2plot[j][i]!='sleep':\n",
    "            ax[i,j].plot(np.arange(1,len(ap[key_SR2plot[j][i]])+1), ap[key_SR2plot[j][i]],color = SR_color[key_SR2plot[j][i]])\n",
    "            ax[i,j].fill_between(np.arange(1,len(ap[key_SR2plot[j][i]])+1),np.array(ap[key_SR2plot[j][i]])-se[key_SR2plot[j][i]], \\\n",
    "                       np.array(ap[key_SR2plot[j][i]])+se[key_SR2plot[j][i]], alpha=0.2,color = SR_color[key_SR2plot[j][i]])   \n",
    "        else:\n",
    "            ax[i,j].plot(np.arange(1,21)[::2],ap[key_SR2plot[j][i]],color = SR_color[key_SR2plot[j][i]])\n",
    "            ax[i,j].fill_between(np.arange(1,21)[::2],\\\n",
    "                       np.array(ap[key_SR2plot[j][i]])-se[key_SR2plot[j][i]], \\\n",
    "                       np.array(ap[key_SR2plot[j][i]])+se[key_SR2plot[j][i]], alpha=0.2,color = SR_color[key_SR2plot[j][i]])  \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not substract the mean across participants for self-reports\n",
    "\n",
    "ACC_SR,mean_sem_p_ACC = {},{}\n",
    "for key in key_SR:\n",
    "    if key != 'sleep':\n",
    "        ACC_SR[key] = [myf.finalACC(np.array(adf[adf['userID']==part][key]),np.zeros(20)) for part in userids]\n",
    "    else:\n",
    "        ACC_SR[key] = [myf.finalACC(np.array(mdf[mdf['userID']==part][key]),np.zeros(10)) for part in userids]\n",
    "    ACC_SR[key] = np.array(ACC_SR[key])\n",
    "    mean_sem_p_ACC[key] = myf.mean_sem_p_ACC(ACC_SR[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sem_p_SR_ACC = {}\n",
    "for k,v in mean_sem_p_ACC.items():\n",
    "    mean_sem_p_SR_ACC[k] = {'mean':list(mean_sem_p_ACC[k].mean),'se':list(mean_sem_p_ACC[k].se),\\\n",
    "                           'p_value':list(mean_sem_p_ACC[k].p_value),'pgranger':list(mean_sem_p_ACC[k].pgranger)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN AGAIN !!!\n",
    "\n",
    "# write the result in file\n",
    "filename_SR_ACC=path_results+'ACC_SR.json'\n",
    "# Serializing json  \n",
    "json_object_SR_ACC = json.dumps(mean_sem_p_SR_ACC) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_SR_ACC, \"w\") as outfile: \n",
    "    outfile.write(json_object_SR_ACC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(12,7))\n",
    "plt.subplots_adjust(hspace = 0.6)  \n",
    "\n",
    "for i in range(2):\n",
    "    for k in range(2):\n",
    "        for j in range(1,len(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'])+1):\n",
    "            if mean_sem_p_SR_ACC[key_SR2plot[k][i]]['pgranger'][j-1]<0.05:\n",
    "                ax[i,k].scatter(j,mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'][j-1],marker='*',s=300,c='#ffffff',edgecolors = SR_color[key_SR2plot[k][i]], zorder=3)\n",
    "        ax[i,k].plot(np.arange(1,len(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'])+1),mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'], color = SR_color[key_SR2plot[k][i]], zorder=2)\n",
    "        ax[i,k].fill_between(np.arange(1,len(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'])+1),\\\n",
    "                             np.array(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'])-np.array(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['se']), \\\n",
    "                           np.array(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['mean'])+np.array(mean_sem_p_SR_ACC[key_SR2plot[k][i]]['se']), color = SR_color[key_SR2plot[k][i]], alpha=0.2)\n",
    "        if key_SR2plot[k][i]=='real_stress':\n",
    "            label_ = 'stress'\n",
    "        else:\n",
    "            label_ = key_SR2plot[k][i]\n",
    "        ax[i,k].set_title(label_)\n",
    "        \n",
    "\n",
    "ax[0,0].set_ylabel('autocorrelation')\n",
    "ax[1,0].set_ylabel('autocorrelation')\n",
    "ax[1,0].set_xlabel('lag (sessions)')\n",
    "ax[1,1].set_xlabel('lag (sessions)')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].set_ylim(-0.35,0.35)\n",
    "        ax[i,j].axhline(0.0,c='k',lw=1)\n",
    "        ax[i,j].set_xticks(np.arange(1,10,2))\n",
    "        ax[i,j].set_xlabel('lag (sessions)')\n",
    "ax[0,1].set_xlim(0.8,4.2)        \n",
    "ax[0,1].set_xticks(np.arange(1,5,1))\n",
    "ax[0,1].set_xlabel('lag (days)')       \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood3053 = np.array(adf[adf['userID']==3053].mood)\n",
    "stress3053 = np.array(adf[adf['userID']==3053].real_stress)\n",
    "mask = ~np.isnan(mood3053) & ~np.isnan(stress3053)\n",
    "slope, intercept, r_value, p_value, stderr = stats.linregress(stress3053[mask],mood3053[mask])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(stress3053,mood3053,color='darkcyan')\n",
    "plt.ylabel('mood')\n",
    "plt.xlabel('stress') \n",
    "plt.plot(np.arange(-0.1,1.1,0.1),intercept+slope*np.arange(-0.1,1.1,0.1),color='darkcyan')\n",
    "plt.fill_between(np.arange(-0.1,1.1,0.1),intercept+slope*np.arange(-0.1,1.1,0.1)-stderr, \\\n",
    "                   intercept+slope*np.arange(-0.1,1.1,0.1)+stderr, color='darkcyan', alpha=0.2)\n",
    "plt.yticks([0.0,0.5,1.0])\n",
    "plt.xticks([0.0,0.5,1.0])\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3053 = {'mood3053':list(mood3053),'stress3053':list(stress3053),'slope':slope,'intercept':intercept,'r_value':r_value,\\\n",
    "          'p_value':p_value,'stderr':stderr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_ex3053=path_results+'ex3053.json'\n",
    "# Serializing json  \n",
    "json_object_ex3053 = json.dumps(ex3053) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_ex3053, \"w\") as outfile: \n",
    "    outfile.write(json_object_ex3053) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_SR, p_SR, SIG_SR, NOS_SR = {},{},{},{}\n",
    "for pair in pair_keys_SR:\n",
    "    if 'sleep' in pair: \n",
    "        LR = [myf.Linear_Regr(np.array(mdf[mdf['userID']==part][pair[0]]),\\\n",
    "                            np.array(mdf[mdf['userID']==part][pair[1]])) for part in userids]\n",
    "    else:\n",
    "        LR = [myf.Linear_Regr(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "\n",
    "    corr_SR[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_SR[pair] = stats.ttest_1samp(corr_SR[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_SR[pair] = [corr_SR[pair][j] for j in indSIG[0]]\n",
    "    NOS_SR[pair] = [corr_SR[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_p_SR = [myf.roundP(p_SR[(pair)]) for pair in pair_keys_SR]\n",
    "\n",
    "Mround_p_SR = myf.symmetrize(round_p_SR)\n",
    "\n",
    "p_value = [['p_value']+key_SR]\n",
    "ind = -1\n",
    "for key in key_SR:\n",
    "    ind += 1\n",
    "    p_value.append([key]+list(Mround_p_SR[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(p_value, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_SR = [myf.roundP(np.mean(corr_SR[(pair)])) for pair in pair_keys_SR]\n",
    "\n",
    "Mround_R_SR = myf.symmetrize(R_SR)+np.identity(len(key_SR))\n",
    "\n",
    "mean_r = [['mean R']+key_SR]\n",
    "ind = -1\n",
    "for key in key_SR:\n",
    "    ind += 1\n",
    "    mean_r.append([key]+list(Mround_R_SR[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(mean_r, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_keys_SR2plot = [pair_keys_SR[:2],pair_keys_SR[2:4],pair_keys_SR[4:]]\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(12,8))\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "\n",
    "for ii in range(3):\n",
    "    for jj in range(2):\n",
    "        ax[ii,jj].hist([SIG_SR[pair_keys_SR2plot[ii][jj]],NOS_SR[pair_keys_SR2plot[ii][jj]]],bins=np.arange(-1,1,0.1),\\\n",
    "                        alpha=0.7,histtype='bar', stacked=True, \\\n",
    "                        color=['gray','w'], edgecolor='gray', linewidth=2) \n",
    "        ax[ii,jj].text(-0.95,3.5,'ttest p: '+str(myf.roundP(p_SR[pair_keys_SR2plot[ii][jj]])), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].text(-0.95,4.5,'mean r: '+str(myf.roundP(np.nanmean(corr_SR[pair_keys_SR2plot[ii][jj]]))), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].set_title(pair_keys_SR2plot[ii][jj])\n",
    "        ax[ii,jj].set_xlim(-1.1,1.1)\n",
    "        ax[ii,jj].set_ylim(0,9)\n",
    "        ax[ii,jj].axvline(0,color='k')\n",
    "        \n",
    "        if ii==2:\n",
    "            ax[ii,jj].set_xlabel('Pearson corr coeff')\n",
    "    ax[ii,0].set_ylabel('counts')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert key tuples into strings for saving the results as json dictionary\n",
    "\n",
    "for pair in pair_keys_SR:\n",
    "    new_key = pair[0]+'-'+pair[1]\n",
    "    corr_SR[new_key] = corr_SR.pop(pair)\n",
    "    p_SR[new_key] = p_SR.pop(pair)\n",
    "    SIG_SR[new_key] = SIG_SR.pop(pair)\n",
    "    NOS_SR[new_key] = NOS_SR.pop(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrSR2save = {'corr_SR':corr_SR, 'p_SR':p_SR, 'SIG_SR':SIG_SR, 'NOS_SR':NOS_SR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_corrSR=path_results+'corrSR.json'\n",
    "# Serializing json  \n",
    "json_object_corrSR = json.dumps(corrSR2save) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_corrSR, \"w\") as outfile: \n",
    "    outfile.write(json_object_corrSR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From morning to afternoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def que_array(part,key):\n",
    "    return np.array(adf[adf['userID']==part][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mor2aftSR, p_mor2aftSR, SIG_mor2aftSR, NOS_mor2aftSR = {},{},{},{}\n",
    "for key in key_SR:\n",
    "    if key != 'sleep': \n",
    "        LR = [myf.Linear_Regr(que_array(part,key)[::2],que_array(part,key)[1::2]) for part in userids]\n",
    "\n",
    "    corr_mor2aftSR[key] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_mor2aftSR[key] = stats.ttest_1samp(corr_mor2aftSR[key],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_mor2aftSR[key] = [corr_mor2aftSR[key][j] for j in indSIG[0]]\n",
    "    NOS_mor2aftSR[key] = [corr_mor2aftSR[key][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_key_SR = [x for x in key_SR if x!= 'sleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(22,5))\n",
    "for i in range(3):\n",
    "    ax[i].hist(corr_mor2aftSR[ma_key_SR[i]],color=[0.5,0.5,0.5])\n",
    "    ax[i].text(-0.95,3.5,'ttest p: '+str(myf.roundP(p_mor2aftSR[ma_key_SR[i]])), ha='left', wrap=True,fontsize=18)\n",
    "    ax[i].text(-0.95,4.5,'mean r: '+str(myf.roundP(np.nanmean(corr_mor2aftSR[ma_key_SR[i]]))), ha='left', wrap=True,fontsize=18)\n",
    "    ax[i].set_title(ma_key_SR[i])\n",
    "    ax[i].set_xlim(-1.1,1.1)\n",
    "    ax[i].set_ylim(0,9)\n",
    "    ax[i].axvline(0,color='k')\n",
    "    ax[i].set_xlabel('Pearson corr coeff')\n",
    "ax[0].set_ylabel('from morning to afternoon counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From afternoon to morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_aft2morSR, p_aft2morSR, SIG_aft2morSR, NOS_aft2morSR = {},{},{},{}\n",
    "for key in key_SR:\n",
    "    if key != 'sleep': \n",
    "        LR = [myf.Linear_Regr(que_array(part,key)[::2][1:],que_array(part,key)[1::2][:-1]) for part in userids]\n",
    "\n",
    "    corr_aft2morSR[key] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_aft2morSR[key] = stats.ttest_1samp(corr_aft2morSR[key],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_aft2morSR[key] = [corr_aft2morSR[key][j] for j in indSIG[0]]\n",
    "    NOS_aft2morSR[key] = [corr_aft2morSR[key][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(22,5))\n",
    "for i in range(3):\n",
    "    ax[i].hist(corr_aft2morSR[ma_key_SR[i]],color=[0.5,0.5,0.5])\n",
    "    ax[i].text(-0.95,3.5,'ttest p: '+str(myf.roundP(p_aft2morSR[ma_key_SR[i]])), ha='left', wrap=True,fontsize=18)\n",
    "    ax[i].text(-0.95,4.5,'mean r: '+str(myf.roundP(np.nanmean(corr_aft2morSR[ma_key_SR[i]]))), ha='left', wrap=True,fontsize=18)\n",
    "    ax[i].set_title(ma_key_SR[i])\n",
    "    ax[i].set_xlim(-1.1,1.1)\n",
    "    ax[i].set_ylim(0,9)\n",
    "    ax[i].axvline(0,color='k')\n",
    "    ax[i].set_xlabel('Pearson corr coeff')\n",
    "ax[0].set_ylabel('from afternoon to morning counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relM2A_A2M = {}\n",
    "for key in key_SR:\n",
    "    if key != 'sleep': \n",
    "        relM2A_A2M[key] = stats.ttest_rel(corr_mor2aftSR[key],corr_aft2morSR[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relM2A_A2M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psychometric variables (figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMAS = df_diff.groupby(['difficulty']).mean().reset_index()\n",
    "dfSEM = df_diff.groupby(['difficulty']).sem().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_keys = [elem for elem in key_diff if 'perf' in elem]\n",
    "oo_keys = [elem for elem in key_diff if 'optout' in elem]\n",
    "RT_keys = [elem for elem in key_diff if 'RT' in elem]\n",
    "\n",
    "perf_color = {'perf_no':'g','Dperf_oo':'r','Sperf_oo':'b'}\n",
    "perf_legend = {'perf_no':'non-optout','Dperf_oo':'deterministic','Sperf_oo':'stochastic'}\n",
    "\n",
    "oo_color = {'Doptout':'r', 'Soptout':'b'}\n",
    "oo_legend = {'Doptout':'deterministic', 'Soptout':'stochastic'}\n",
    "\n",
    "RT_color = {'DRT_oo':'r', 'SRT_oo':'b', 'DRT_OKoo':'r', 'SRT_OKoo':'b', 'RT_no':'g', 'RT_noNOK':'m'}\n",
    "RT_ls = {'DRT_oo':'--', 'SRT_oo':'--', 'DRT_OKoo':'-', 'SRT_OKoo':'-', 'RT_no':'-', 'RT_noNOK':'-'}\n",
    "RT_legend = {'DRT_oo':'d', 'SRT_oo':'s', 'DRT_OKoo':'ok d',\\\n",
    "             'SRT_OKoo':'ok s', 'RT_no':'ok n-o', 'RT_noNOK':'x n-o'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
    "plt.subplots_adjust(wspace = 0.3)  \n",
    "for k in perf_keys:\n",
    "    ax[0].plot(unique_signals,dfMAS[k],c=perf_color[k],label=perf_legend[k])\n",
    "    ax[0].fill_between(unique_signals,np.array(dfMAS[k])-np.array(dfSEM[k]), \\\n",
    "                   np.array(dfMAS[k])+np.array(dfSEM[k]), color=perf_color[k], alpha=0.2)\n",
    "ax[0].set_ylabel('performance',fontsize=25)\n",
    "ax[0].set_xlabel('difficulty',fontsize=25)\n",
    "ax[0].legend(loc='lower left', shadow=True,fontsize=15)\n",
    "\n",
    "for k in oo_keys:\n",
    "    ax[1].plot(unique_signals,dfMAS[k],c=oo_color[k],label=oo_legend[k])\n",
    "    ax[1].fill_between(unique_signals,np.array(dfMAS[k])-np.array(dfSEM[k]), \\\n",
    "                       np.array(dfMAS[k])+np.array(dfSEM[k]), color=oo_color[k], alpha=0.2)\n",
    "\n",
    "ax[1].legend(loc='upper left', shadow=True,fontsize=15)\n",
    "ax[1].set_ylabel('optout (%)',fontsize=25)\n",
    "ax[1].set_xlabel('difficulty',fontsize=25)\n",
    "\n",
    "for k in RT_keys:\n",
    "    ax[2].plot(unique_signals,dfMAS[k],c=RT_color[k],ls=RT_ls[k],label=RT_legend[k])\n",
    "    ax[2].fill_between(unique_signals,np.array(dfMAS[k])-np.array(dfSEM[k]), \\\n",
    "                       np.array(dfMAS[k])+np.array(dfSEM[k]), color=RT_color[k], alpha=0.2)\n",
    "ax[2].set_ylabel('reaction time (norm.)',fontsize=25)\n",
    "ax[2].set_xlabel('difficulty',fontsize=25)\n",
    "ax[2].legend(loc='best', shadow=True,fontsize=15, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_diff_dots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_diff = dfMAS.to_dict('list')\n",
    "se_diff = dfSEM.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_ap_diff=path_results+'ap_diff.json'\n",
    "filename_se_diff=path_results+'se_diff.json'\n",
    "# Serializing json  \n",
    "json_object_ap_diff = json.dumps(ap_diff) \n",
    "json_object_se_diff = json.dumps(se_diff) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_ap_diff, \"w\") as outfile: \n",
    "    outfile.write(json_object_ap_diff) \n",
    "with open(filename_se_diff, \"w\") as outfile: \n",
    "    outfile.write(json_object_se_diff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfANOVA_MAS[dfANOVA_MAS['userID']==3051].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#perform two-way ANOVA\n",
    "model = ols('perf ~ C(type) + C(difficulty)', data=dfANOVA_MAS).fit()\n",
    "sm.stats.anova_lm(model, typ=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#perform two-way ANOVA\n",
    "model = ols('perf ~ C(type) + C(difficulty) + C(type)*C(difficulty)', data=dfANOVA_MAS).fit()\n",
    "sm.stats.anova_lm(model, typ=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_dropna = df_diff.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "interaction_groups = \"type_\" + dfANOVA_MAS.type.astype(str) + \" & \" + \"type_\" + dfANOVA_MAS.type.astype(str)\n",
    "\n",
    "comp = mc.MultiComparison(dfANOVA_MAS[\"perf\"], interaction_groups)\n",
    "post_hoc_res = comp.tukeyhsd()\n",
    "post_hoc_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLMM_DO, pLMM_DO,sigLMM_DO, nosLMM_DO = [],[],[],[]\n",
    "for part in userids:\n",
    "    subset = df_diff[df_diff['userID']==part]\n",
    "    RTeff = subset['RTeff']\n",
    "    DOeff = subset['DOeff']\n",
    "\n",
    "    mm_RT_DO = smf.mixedlm(\"RTeff ~ DOeff\", subset, re_formula='1', groups=subset[\"sessionID\"])\n",
    "    mdf_RT_DO = mm_RT_DO.fit()\n",
    "    sLMM_DO.append(mdf_RT_DO.params.DOeff)\n",
    "    pLMM_DO.append(mdf_RT_DO.pvalues.DOeff)\n",
    "    indSIG_DO = np.where(np.array(pLMM_DO)<0.05)\n",
    "    indNOS_DO = np.where(np.array(pLMM_DO)>=0.05)\n",
    "    sigLMM_DO = [sLMM_DO[j] for j in indSIG_DO[0]]\n",
    "    nosLMM_DO = [sLMM_DO[j] for j in indNOS_DO[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax1 = plt.subplots()\n",
    "\n",
    "ax1.hist([sigLMM_DO,nosLMM_DO],alpha=0.7,histtype='bar', stacked=True, \\\n",
    "         color=['m',[0.95,0.7,0.95]], edgecolor='m', linewidth=1)\n",
    "ax1.text(-0.0095,1,\"RTeff ~ DOeff\", ha='left', wrap=True,fontsize=18,color='m')\n",
    "ax1.set_ylabel('counts')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xticks([-0.01,0,0.01])\n",
    "ax1.set_yticks([0,5,10])\n",
    "ax1.set_xlabel('LMM coeff.')\n",
    "ax1.axvline(0,color='k',lw=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('RTeff&DOeff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sLMM_DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sLMM_DO,0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTeffDOeff = {'sigLMM_DO':sigLMM_DO,'nosLMM_DO':nosLMM_DO,'pLMM_DO':pLMM_DO,'sLMM_DO':sLMM_DO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_RTeffDOeff=path_results+'RTeffDOeff.json'\n",
    "# Serializing json  \n",
    "json_object_RTeffDOeff = json.dumps(RTeffDOeff) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_RTeffDOeff, \"w\") as outfile: \n",
    "    outfile.write(json_object_RTeffDOeff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLMM_SO, pLMM_SO,sigLMM_SO, nosLMM_SO = [],[],[],[]\n",
    "for part in userids:\n",
    "    subset = df_diff[df_diff['userID']==part]\n",
    "    RTeff = subset['RTeff']\n",
    "    SOeff = subset['SOeff']\n",
    "\n",
    "    mm_RT_SO = smf.mixedlm(\"RTeff ~ SOeff\", subset, re_formula='1', groups=subset[\"sessionID\"])\n",
    "    mdf_RT_SO = mm_RT_SO.fit()\n",
    "    sLMM_SO.append(mdf_RT_SO.params.SOeff)\n",
    "    pLMM_SO.append(mdf_RT_SO.pvalues.SOeff)\n",
    "    indSIG_SO = np.where(np.array(pLMM_SO)<0.05)\n",
    "    indNOS_SO = np.where(np.array(pLMM_SO)>=0.05)\n",
    "    sigLMM_SO = [sLMM_SO[j] for j in indSIG_SO[0]]\n",
    "    nosLMM_SO = [sLMM_SO[j] for j in indNOS_SO[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax1 = plt.subplots()\n",
    "\n",
    "ax1.hist([sigLMM_SO,nosLMM_SO],alpha=0.7,histtype='bar', stacked=True, \\\n",
    "         color=['m',[0.95,0.7,0.95]], edgecolor='m', linewidth=1)\n",
    "ax1.text(-0.0095,1,\"RTeff ~ SOeff\", ha='left', wrap=True,fontsize=18,color='m')\n",
    "ax1.set_ylabel('counts')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xticks([-0.01,0,0.01])\n",
    "ax1.set_xlabel('LMM coeff.')\n",
    "ax1.axvline(0,color='k',lw=1)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('RTeff&SOeff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sLMM_SO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sLMM_SO,0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTeffSOeff = {'sigLMM_SO':sigLMM_SO,'nosLMM_SO':nosLMM_SO,'pLMM_SO':pLMM_SO,'sLMM_SO':sLMM_SO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_RTeffSOeff=path_results+'RTeffSOeff.json'\n",
    "# Serializing json  \n",
    "json_object_RTeffSOeff = json.dumps(RTeffSOeff) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_RTeffSOeff, \"w\") as outfile: \n",
    "    outfile.write(json_object_RTeffSOeff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,figsize=(7,8))\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "\n",
    "ax[0].fill_between([4,8], 72,83,color=[0.9,0.9,0.9])\n",
    "ax[0].fill_between([18,20], 72,83,color=[0.9,0.9,0.9])\n",
    "ax[0].plot(np.arange(1,len(ap[key_PV[2]])+1),ap[key_PV[2]],c='g', zorder=2)\n",
    "ax[0].fill_between(np.arange(1,len(ap[key_PV[2]])+1),np.array(ap[key_PV[2]])-np.array(se[key_PV[2]]),\\\n",
    "                   np.array(ap[key_PV[2]])+np.array(se[key_PV[2]]), color='g', alpha=0.2)\n",
    "\n",
    "ax[1].fill_between([4,8], 15, 48,color=[0.9,0.9,0.9])\n",
    "ax[1].fill_between([18,20], 15, 48,color=[0.9,0.9,0.9])\n",
    "ax[1].plot(np.arange(1,len(ap[key_PV[0]])+1),ap[key_PV[0]],c='r', zorder=2)\n",
    "ax[1].fill_between(np.arange(1,len(ap[key_PV[0]])+1),np.array(ap[key_PV[0]])-np.array(se[key_PV[0]]),\\\n",
    "                   np.array(ap[key_PV[0]])+np.array(se[key_PV[0]]), color='r', alpha=0.2)\n",
    "ax[1].plot(np.arange(1,len(ap[key_PV[1]])+1),ap[key_PV[1]],c='b', zorder=2)\n",
    "ax[1].fill_between(np.arange(1,len(ap[key_PV[1]])+1),np.array(ap[key_PV[1]])-np.array(se[key_PV[1]]),\\\n",
    "                   np.array(ap[key_PV[1]])+np.array(se[key_PV[1]]), color='b', alpha=0.2)\n",
    "\n",
    "ax[2].fill_between([4,8], 0.95, 1.03,color=[0.9,0.9,0.9])\n",
    "ax[2].fill_between([18,20], 0.95, 1.03,color=[0.9,0.9,0.9])\n",
    "ax[2].plot(np.arange(1,len(ap[key_PV[3]])+1),ap[key_PV[3]],c='g', zorder=2)\n",
    "ax[2].fill_between(np.arange(1,len(ap[key_PV[3]])+1),np.array(ap[key_PV[3]])-np.array(se[key_PV[3]]),\\\n",
    "                   np.array(ap[key_PV[3]])+np.array(se[key_PV[3]]), color='g', alpha=0.2)\n",
    "\n",
    "ax[0].set_ylabel('NO acc. (%)')\n",
    "ax[1].set_ylabel('optout (%)')\n",
    "ax[2].set_ylabel('NO RT (norm.)')\n",
    "ax[2].set_xlabel('lag (sessions)')\n",
    "  \n",
    "ax[1].legend((\"Deterministic\",\"Stochastic\"),loc='upper right', shadow=True)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xticks(np.arange(1,(len(ap[key_PV[0]])+1))[::2])\n",
    "    ax[i].set_xticklabels(session_labels)\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_PV,mean_sem_p_PV_ACC = {},{}\n",
    "for key in key_PV:\n",
    "    ACC_PV[key] = [myf.finalACC(np.array(adf[adf['userID']==part][key]),ap[key]) for part in userids]\n",
    "    ACC_PV[key] = np.array(ACC_PV[key])\n",
    "    mean_sem_p_PV_ACC[key] = myf.mean_sem_p_ACC(ACC_PV[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,figsize=(5,8))\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].axhline(0.0,c='k',lw=1)\n",
    "    ax[i].set_xticks([1,3,5,7,9]) \n",
    "    \n",
    "for j in range(1,len(mean_sem_p_PV_ACC[key_PV[0]].mean)+1):\n",
    "    if mean_sem_p_PV_ACC[key_PV[0]].pgranger[j-1]<0.05:\n",
    "        ax[1].scatter(j,mean_sem_p_PV_ACC[key_PV[0]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='r', zorder=3)\n",
    "ax[1].plot(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[0]].mean)+1),mean_sem_p_PV_ACC[key_PV[0]].mean,c='r', zorder=2)\n",
    "ax[1].fill_between(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[0]].mean)+1),np.array(mean_sem_p_PV_ACC[key_PV[0]].mean)\\\n",
    "                    -np.array(mean_sem_p_PV_ACC[key_PV[0]].se),np.array(mean_sem_p_PV_ACC[key_PV[0]].mean)\n",
    "                    +np.array(mean_sem_p_PV_ACC[key_PV[0]].se), color='r', alpha=0.2)\n",
    "\n",
    "for j in range(1,len(mean_sem_p_PV_ACC[key_PV[3]].mean)+1):\n",
    "    if mean_sem_p_PV_ACC[key_PV[3]].pgranger[j-1]<0.05:\n",
    "        ax[2].scatter(j,mean_sem_p_PV_ACC[key_PV[3]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='g', zorder=3)\n",
    "ax[2].plot(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[3]].mean)+1),mean_sem_p_PV_ACC[key_PV[3]].mean,c='g', zorder=2)\n",
    "ax[2].fill_between(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[3]].mean)+1),np.array(mean_sem_p_PV_ACC[key_PV[3]].mean)\\\n",
    "                    -np.array(mean_sem_p_PV_ACC[key_PV[3]].se),np.array(mean_sem_p_PV_ACC[key_PV[3]].mean)\\\n",
    "                    +np.array(mean_sem_p_PV_ACC[key_PV[3]].se), color='g', alpha=0.2)\n",
    "\n",
    "for j in range(1,len(mean_sem_p_PV_ACC[key_PV[2]].mean)+1):\n",
    "    if mean_sem_p_PV_ACC[key_PV[2]].pgranger[j-1]<0.05:\n",
    "        ax[0].scatter(j,mean_sem_p_PV_ACC[key_PV[2]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='g', zorder=3)\n",
    "ax[0].plot(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[2]].mean)+1),mean_sem_p_PV_ACC[key_PV[2]].mean,c='g', zorder=2)\n",
    "ax[0].fill_between(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[2]].mean)+1),np.array(mean_sem_p_PV_ACC[key_PV[2]].mean)\\\n",
    "                    -np.array(mean_sem_p_PV_ACC[key_PV[2]].se),np.array(mean_sem_p_PV_ACC[key_PV[2]].mean)\\\n",
    "                    +np.array(mean_sem_p_PV_ACC[key_PV[2]].se), color='g', alpha=0.2)\n",
    "\n",
    "for j in range(1,len(mean_sem_p_PV_ACC[key_PV[1]].mean)+1):\n",
    "    if mean_sem_p_PV_ACC[key_PV[1]].pgranger[j-1]<0.05:\n",
    "        ax[1].scatter(j,mean_sem_p_PV_ACC[key_PV[1]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='b', zorder=3)\n",
    "ax[1].plot(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[1]].mean)+1),mean_sem_p_PV_ACC[key_PV[1]].mean,c='b', zorder=2)\n",
    "ax[1].fill_between(np.arange(1,len(mean_sem_p_PV_ACC[key_PV[1]].mean)+1),np.array(mean_sem_p_PV_ACC[key_PV[1]].mean)\\\n",
    "                    -np.array(mean_sem_p_PV_ACC[key_PV[1]].se),np.array(mean_sem_p_PV_ACC[key_PV[1]].mean)\\\n",
    "                    +np.array(mean_sem_p_PV_ACC[key_PV[1]].se), color='b', alpha=0.2)\n",
    "\n",
    "ax[1].set_ylabel('AC optout')\n",
    "ax[0].set_ylabel('AC NO acc.')\n",
    "ax[2].set_ylabel('AC NO RT')\n",
    "ax[2].set_xlabel('lag (sessions)')\n",
    "  \n",
    "ax[1].legend((\"Deterministic\",\"Stochastic\"),loc='upper right', shadow=True)\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sem_p_PV_ACC_ = {}\n",
    "for k,v in mean_sem_p_PV_ACC.items():\n",
    "    mean_sem_p_PV_ACC_[k] = {'mean':list(mean_sem_p_PV_ACC[k].mean),'se':list(mean_sem_p_PV_ACC[k].se),\\\n",
    "                           'p_value':list(mean_sem_p_PV_ACC[k].p_value),'pgranger':list(mean_sem_p_PV_ACC[k].pgranger)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN AGAIN !!!\n",
    "\n",
    "# write the result in file\n",
    "filename_PV_ACC=path_results+'ACC_PV.json'\n",
    "# Serializing json  \n",
    "json_object_PV_ACC = json.dumps(mean_sem_p_PV_ACC_) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_PV_ACC, \"w\") as outfile: \n",
    "    outfile.write(json_object_PV_ACC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_PV, p_PV, SIG_PV, NOS_PV = {},{},{},{}\n",
    "for pair in pair_keys_PV:\n",
    "    LR = [myf.Linear_Regr(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "    corr_PV[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_PV[pair] = stats.ttest_1samp(corr_PV[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_PV[pair] = [corr_PV[pair][j] for j in indSIG[0]]\n",
    "    NOS_PV[pair] = [corr_PV[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_PV,p_PV = {},{}\n",
    "for pair in pair_keys_PV:\n",
    "    corr_PV[pair] = [myf.Pearson_corr_coef(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "    p_PV[pair] = stats.ttest_1samp(corr_PV[pair],0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_p_PV = [myf.roundP(p_PV[(pair)]) for pair in pair_keys_PV]\n",
    "\n",
    "Mround_p_PV = myf.symmetrize(round_p_PV)\n",
    "\n",
    "p_value = [['p_value']+key_PV[:-3]]\n",
    "ind = -1\n",
    "for key in key_PV[:-3]:\n",
    "    ind += 1\n",
    "    p_value.append([key]+list(Mround_p_PV[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(p_value, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize=(18,6))\n",
    "plt.subplots_adjust(hspace = 1)  \n",
    "\n",
    "for ii in range(2):\n",
    "    for jj in range(3):\n",
    "        ax[ii,jj].hist([SIG_PV[pair_keys_PV2plot[ii][jj]],NOS_PV[pair_keys_PV2plot[ii][jj]]],bins=np.arange(-1,1,0.1),\\\n",
    "                        alpha=0.7,histtype='bar', stacked=True, \\\n",
    "                        color=['gray',[0.95,0.95,0.95]], edgecolor='gray', linewidth=2) \n",
    "        ax[ii,jj].text(-0.95,3.5,'ttest p: '+str(myf.roundP(p_PV[pair_keys_PV2plot[ii][jj]])), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].text(-0.95,5.5,'mean r: '+str(myf.roundP(np.nanmean(corr_PV[pair_keys_PV2plot[ii][jj]]))), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].set_title(pair_key_name_PV2plot[ii][jj])\n",
    "        ax[ii,jj].set_xlim(-1.1,1.1)\n",
    "        ax[ii,jj].set_ylim(0,9)\n",
    "        ax[ii,jj].axvline(0,color='k')\n",
    "        \n",
    "        \n",
    "        if ii==1:\n",
    "            ax[ii,jj].set_xlabel('Pearson corr coeff')\n",
    "        else:\n",
    "            ax[ii,jj].axes.get_xaxis().set_visible(False)\n",
    "        \n",
    "        if jj==0:\n",
    "            ax[ii,0].set_ylabel('counts')\n",
    "        else:\n",
    "            ax[ii,jj].axes.get_yaxis().set_visible(False)\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert key tuples into strings for saving the results as json dictionary\n",
    "\n",
    "for pair in pair_keys_PV:\n",
    "    new_key = pair[0]+'-'+pair[1]\n",
    "    corr_PV[new_key] = corr_PV.pop(pair)\n",
    "    p_PV[new_key] = p_PV.pop(pair)\n",
    "    SIG_PV[new_key] = SIG_PV.pop(pair)\n",
    "    NOS_PV[new_key] = NOS_PV.pop(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrPV2save = {'corr_PV':corr_PV, 'p_PV':p_PV, 'SIG_PV':SIG_PV, 'NOS_PV':NOS_PV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_corrPV=path_results+'corrPV.json'\n",
    "# Serializing json  \n",
    "json_object_corrPV = json.dumps(corrPV2save) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_corrPV, \"w\") as outfile: \n",
    "    outfile.write(json_object_corrPV) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-reports & Psychometric variables (figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_SR_PV,pair_SR_PV2plot = [],[]\n",
    "for pv in key_PV+key_LR:\n",
    "    aux = []\n",
    "    for sr in key_SR:\n",
    "        pair_SR_PV.append((sr,pv))\n",
    "        aux.append((sr,pv))\n",
    "    pair_SR_PV2plot.append(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_SR_PV, p_SR_PV, SIG_SR_PV, NOS_SR_PV = {},{},{},{}\n",
    "for pair in pair_SR_PV:\n",
    "    if 'sleep' in pair:  \n",
    "        LR = [myf.Linear_Regr(np.array(mdf[mdf['userID']==part][pair[0]]),\\\n",
    "                            np.array(mdf[mdf['userID']==part][pair[1]])) for part in userids]\n",
    "    else:\n",
    "        LR = [myf.Linear_Regr(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "    corr_SR_PV[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_SR_PV[pair] = stats.ttest_1samp(corr_SR_PV[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indSIG[0]]\n",
    "    NOS_SR_PV[pair] = [corr_SR_PV[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_p_PV = np.array([myf.roundP(p_SR_PV[(pair)]) for pair in pair_SR_PV])\n",
    "round_p_PV = np.reshape(round_p_PV,(13,4))\n",
    "p_value = [['p_value']+key_SR]\n",
    "ind = -1\n",
    "for key in key_PV+key_LR:\n",
    "    ind += 1\n",
    "    p_value.append([key]+list(round_p_PV[ind]))\n",
    "\n",
    "display(HTML(tabulate.tabulate(p_value, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(13,4,figsize=(22,30))\n",
    "plt.subplots_adjust(hspace = 1)  \n",
    "\n",
    "for ii in range(13):\n",
    "    for jj in range(4):\n",
    "        ax[ii,jj].hist([SIG_SR_PV[pair_SR_PV2plot[ii][jj]],NOS_SR_PV[pair_SR_PV2plot[ii][jj]]],bins=np.arange(-1,1,0.1),\\\n",
    "                        alpha=0.7,histtype='bar', stacked=True, \\\n",
    "                        color=['gray',[0.95,0.95,0.95]], edgecolor='gray', linewidth=2) \n",
    "        ax[ii,jj].text(-0.95,3.5,'ttest p: '+str(round_p_PV[ii][jj]), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].text(-0.95,5.5,'mean r: '+str(myf.roundP(np.nanmean(corr_SR_PV[pair_SR_PV2plot[ii][jj]]))), ha='left', wrap=True,fontsize=18)\n",
    "        ax[ii,jj].set_title(pair_SR_PV2plot[ii][jj][0])\n",
    "        ax[ii,jj].set_xlim(-1.1,1.1)\n",
    "        ax[ii,jj].set_ylim(0,11)\n",
    "        ax[ii,jj].axvline(0,color='k')\n",
    "        \n",
    "        \n",
    "        if ii==6:\n",
    "            ax[ii,jj].set_xlabel('Pearson corr coeff')\n",
    "        else:\n",
    "            ax[ii,jj].axes.get_xaxis().set_visible(False)\n",
    "        \n",
    "        if jj==0:\n",
    "            ax[ii,0].set_ylabel(pair_SR_PV2plot[ii][jj][1])\n",
    "        else:\n",
    "            ax[ii,jj].axes.get_yaxis().set_visible(False)\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert key tuples into strings for saving the results as json dictionary\n",
    "\n",
    "for pair in pair_SR_PV:\n",
    "    new_key = pair[0]+'-'+pair[1]\n",
    "    corr_SR_PV[new_key] = corr_SR_PV.pop(pair)\n",
    "    p_SR_PV[new_key] = p_SR_PV.pop(pair)\n",
    "    SIG_SR_PV[new_key] = SIG_SR_PV.pop(pair)\n",
    "    NOS_SR_PV[new_key] = NOS_SR_PV.pop(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrSR_PV2save = {'corr_SR_PV':corr_SR_PV, 'p_SR_PV':p_SR_PV, 'SIG_SR_PV':SIG_SR_PV, 'NOS_SR_PV':NOS_SR_PV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_corrSR_PV=path_results+'corrSR_PV.json'\n",
    "# Serializing json  \n",
    "json_object_corrSR_PV = json.dumps(corrSR_PV2save) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_corrSR_PV, \"w\") as outfile: \n",
    "    outfile.write(json_object_corrSR_PV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_keys_SR_PV = []\n",
    "for key1 in key_SR:\n",
    "    for key2 in key_PV[:4]:\n",
    "        pair_keys_SR_PV.append((key1,key2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_keys_SR_PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_SR_PV,mean_sem_p_SR_PV_CC = {},{}\n",
    "for pair in pair_keys_SR_PV:\n",
    "    if 'sleep' in pair:\n",
    "        if pair[0] is not 'sleep':\n",
    "            ap1 = ap[pair[0]][::2]\n",
    "            ap2 = ap[pair[1]]\n",
    "        else:\n",
    "            ap1 = ap[pair[0]]\n",
    "            ap2 = ap[pair[1]][::2]           \n",
    "        corr_SR_PV[pair] = [myf.finalCC(np.array(mdf[mdf['userID']==part][pair[0]]),ap1,\\\n",
    "                            np.array(mdf[mdf['userID']==part][pair[1]]),ap2) for part in userids]\n",
    "    else:\n",
    "        corr_SR_PV[pair] = [myf.finalCC(np.array(adf[adf['userID']==part][pair[0]]),ap[pair[0]],\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]]),ap[pair[1]]) for part in userids]\n",
    "    mean_sem_p_SR_PV_CC[pair] = myf.mean_sem_p_CC(corr_SR_PV[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_keys_SR_PV2plot = [pair_keys_SR_PV[:4],pair_keys_SR_PV[4:8],pair_keys_SR_PV[8:12],pair_keys_SR_PV[12:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,4,figsize=(12,8))\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "\n",
    "for ii in range(4):\n",
    "    for jj in range(4):\n",
    "        for j in range(len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)):\n",
    "            if mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].p_value[j]<0.05:\n",
    "                ax[ii,jj].scatter(j-len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)/2-1,\\\n",
    "                                  mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='k', zorder=3)\n",
    "        ax[ii,jj].plot(np.arange(-len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)/2,\\\n",
    "                                 len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)/2),\\\n",
    "                       mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean,c='k', zorder=2)\n",
    "        ax[ii,jj].fill_between(np.arange(-len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)/2,\\\n",
    "                                 len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)/2),\\\n",
    "                               np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)\\\n",
    "                            -np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].se),\\\n",
    "                               np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)\n",
    "                            +np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].se), color='k', alpha=0.2)\n",
    "        ax[ii,jj].set_title(pair_keys_SR_PV2plot[ii][jj][1])\n",
    "        ax[ii,jj].axhline(0.0,c='k')\n",
    "        ax[ii,jj].set_ylim(-0.25,0.25)\n",
    "        \n",
    "        if ii==2:\n",
    "            ax[ii,jj].set_xlabel('lag')\n",
    "    ax[ii,0].set_ylabel(pair_keys_SR_PV2plot[ii][0][0])\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,4,figsize=(12,8))\n",
    "plt.subplots_adjust(hspace = 0.4)  \n",
    "\n",
    "for ii in range(4):\n",
    "    for jj in range(4):\n",
    "        for j in range(1,len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)+1):\n",
    "            if mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].pgranger[j-1]<0.05:\n",
    "                ax[ii,jj].scatter(j,mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean[j-1],marker='*',s=300,c='#ffffff',edgecolors='k', zorder=3)\n",
    "        ax[ii,jj].plot(np.arange(1,len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)+1),\\\n",
    "                       mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean,c='k', zorder=2)\n",
    "        ax[ii,jj].fill_between(np.arange(1,len(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)+1),\\\n",
    "                               np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)\\\n",
    "                            -np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].se),\\\n",
    "                               np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].mean)\n",
    "                            +np.array(mean_sem_p_SR_PV_CC[pair_keys_SR_PV2plot[ii][jj]].se), color='k', alpha=0.2)\n",
    "        ax[ii,jj].set_title(pair_keys_SR_PV2plot[ii][jj][1])\n",
    "        ax[ii,jj].axhline(0.0,c='k')\n",
    "        ax[ii,jj].set_ylim(-0.25,0.25)\n",
    "        \n",
    "        if ii==2:\n",
    "            ax[ii,jj].set_xlabel('lag')\n",
    "    ax[ii,0].set_ylabel(pair_keys_SR_PV2plot[ii][0][0])\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sem_p_SR_PV_CC2save = {}\n",
    "for k,v in mean_sem_p_SR_PV_CC.items():\n",
    "    new_key = k[0]+'-'+k[1]\n",
    "    mean_sem_p_SR_PV_CC2save[new_key] = {'mean':list(mean_sem_p_SR_PV_CC[k].mean),'se':list(mean_sem_p_SR_PV_CC[k].se),\\\n",
    "                           'p_value':list(mean_sem_p_SR_PV_CC[k].p_value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN AGAIN !!!\n",
    "\n",
    "# write the result in file\n",
    "filename_PV_SR_CC=path_results+'PV_SR_CC.json'\n",
    "# Serializing json  \n",
    "json_object_PV_SR_CC = json.dumps(mean_sem_p_SR_PV_CC2save) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_PV_SR_CC, \"w\") as outfile: \n",
    "    outfile.write(json_object_PV_SR_CC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overconfidence & risk aversion (figure5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_BS = [('no_bias','HmiddleDO'),('no_bias','HmiddleSO'),('no_sigma','Dsigma_oo'),('no_sigma','Ssigma_oo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_BS, p_BS, SIG_BS, NOS_BS = {},{},{},{}\n",
    "for pair in pair_BS:\n",
    "    LR = [myf.Linear_Regr(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "    corr_BS[pair] = [LR[k].r_value for k in range(len(userids))]\n",
    "    p_BS[pair] = stats.ttest_1samp(corr_BS[pair],0)[1]\n",
    "    \n",
    "    LR_p_value = [LR[k].p_value for k in range(len(userids))]\n",
    "    LR_p_value = np.array(LR_p_value)\n",
    "    indSIG = np.where(LR_p_value<0.05)\n",
    "    indNOS = np.where(LR_p_value>=0.05)\n",
    "    SIG_BS[pair] = [corr_BS[pair][j] for j in indSIG[0]]\n",
    "    NOS_BS[pair] = [corr_BS[pair][j] for j in indNOS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_BS,p_BS = {},{}\n",
    "for pair in pair_BS:\n",
    "    corr_BS[pair] = [myf.Pearson_corr_coef(np.array(adf[adf['userID']==part][pair[0]]),\\\n",
    "                            np.array(adf[adf['userID']==part][pair[1]])) for part in userids]\n",
    "    p_BS[pair] = stats.ttest_1samp(corr_BS[pair],0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,figsize=(6,16))\n",
    "plt.subplots_adjust(hspace = 1)  \n",
    "\n",
    "for ii in range(4):\n",
    "    ax[ii].hist([SIG_BS[pair_BS[ii]],NOS_BS[pair_BS[ii]]],bins=np.arange(-1,1,0.1),\\\n",
    "                    alpha=0.7,histtype='bar', stacked=True, \\\n",
    "                    color=['gray',[0.95,0.95,0.95]], edgecolor='gray', linewidth=2) \n",
    "    ax[ii].text(-0.95,3.5,'ttest p: '+str(myf.roundP(p_BS[pair_BS[ii]])), ha='left', wrap=True,fontsize=18)\n",
    "    ax[ii].text(-0.95,5.5,'mean r: '+str(myf.roundP(np.nanmean(corr_BS[pair_BS[ii]]))), ha='left', wrap=True,fontsize=18)\n",
    "    ax[ii].set_title(pair_BS[ii])\n",
    "    ax[ii].set_xlim(-1.1,1.1)\n",
    "    ax[ii].set_ylim(0,9)\n",
    "    ax[ii].axvline(0,color='k')\n",
    "    ax[ii].set_ylabel('counts')\n",
    "\n",
    "    if ii==3:\n",
    "        ax[ii].set_xlabel('Pearson corr coeff')\n",
    "    else:\n",
    "        ax[ii].axes.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert key tuples into strings for saving the results as json dictionary\n",
    "\n",
    "for pair in pair_BS:\n",
    "    new_key = pair[0]+'-'+pair[1]\n",
    "    corr_BS[new_key] = corr_BS.pop(pair)\n",
    "    p_BS[new_key] = p_BS.pop(pair)\n",
    "    SIG_BS[new_key] = SIG_BS.pop(pair)\n",
    "    NOS_BS[new_key] = NOS_BS.pop(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrBS2save = {'corr_BS':corr_BS, 'p_BS':p_BS, 'SIG_BS':SIG_BS, 'NOS_BS':NOS_BS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN\n",
    "\n",
    "# write the result in file\n",
    "filename_corrBS=path_results+'corrBS.json'\n",
    "# Serializing json  \n",
    "json_object_corrBS = json.dumps(corrBS2save) \n",
    "\n",
    "# Writing to sample.json \n",
    "with open(filename_corrBS, \"w\") as outfile: \n",
    "    outfile.write(json_object_corrBS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
