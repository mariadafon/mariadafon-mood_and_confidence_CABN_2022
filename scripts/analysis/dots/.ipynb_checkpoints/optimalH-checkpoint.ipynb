{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal bias \n",
    "\n",
    "Script to calculate the optimal decision boundary for all participants in all sessions. Results are stored in subdiretories named '/dayxx/sessionxx/' into files 'optimalH_Subxxxx_Dayxx_Sessxx.json'. This script should be run after running the single_session_analysis for every session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non optout trials\n",
    "\n",
    "Proportion of right answers vs. signed stimuli. \n",
    "\n",
    "$y = \\frac{1}{1+\\exp{-(\\beta_0+\\beta_1 x)}}$\n",
    "\n",
    "Sigmoid function as $sigmoid(z)$. \n",
    "\n",
    "- Bias: $\\beta_0$\n",
    "\n",
    "- Sensitivity: $ \\beta_1 $\n",
    "\n",
    "If $\\beta_0=0$ (no bias), then $y(x=0)=1/2$. If $\\beta_0>0$, then then $y(x=0)>1/2$ exposing a bias to rightward answers. Otherwise, there is a bias toward the left option. \n",
    "\n",
    "Under the assumption that we have the good stimulus scale, we can estimate the noise in the internal response $\\sigma^2$ and the decision boundary $H$ with the non-optout trials.\n",
    "\n",
    "If $x$ is the stimulus strength (i.e. signed signal), the participant observes $\\hat{x} = x + \\eta$, where $\\eta ~ N(0,\\sigma^2)$, and the participant answers to the right if $\\hat{x}>H$.\n",
    "\n",
    "Thus, we have $p(rightward|x) = \\int _{[H,+ \\infty ]} (x+ \\eta) d \\eta = \\int _{[H-x,+\\infty]} \\eta d \\eta = \\Phi(\\frac{x-H}{\\sigma})$ with $\\Phi$ as the standard normal cumulative.\n",
    "\n",
    "By fitting the psychometric curve we could estimate the noise $\\sigma$ and the decision boundary $H$. \n",
    "\n",
    "$p(rightward|x) = \\Phi(\\beta_0 + \\beta_1 x)$, with $\\beta_1=1/\\sigma$ and $\\beta_0=-H/\\sigma$\n",
    "\n",
    "We fitted the psychometric curve with the logistic regression:\n",
    "\n",
    "$p(rightward|x) = \\frac{1}{1+e^{-(\\beta_0+\\beta_1 x)}}$, \n",
    "\n",
    "with $\\sigma=1/\\beta_1$ and $H=-\\beta_0\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt-out trials\n",
    "\n",
    "In these trials, the participant has 3 options: L (leftward), R (rightward) and O (opt-out), where the proportion of rightward (leftward) answers vs. the signed stimuli is plotted as psychometric curves. The noise model is assumed to be multinomial, that is:\n",
    "\n",
    "$p(y_R,y_L,y_O,p_R,p_L,p_O) = \\frac{n!}{(y_Ln)!(y_Rn)!(y_On)!}p_L^{y_Ln}p_R^{y_Rn}p_O^{y_On}$, with $y_L+y_R+y_O=1$ and $y_k=\\frac{n_k}{n}$ are the fraction of trials where the participant chose each type of response.\n",
    "\n",
    "Assuming that $p_L \\sim 1-\\Phi(\\frac{x-H_L}{\\sigma})$, $p_R \\sim \\Phi(\\frac{x-H_R}{\\sigma})$ and $p_O = 1-p_L-p_R$. The stimulus was re-escaled to be bounded within the range $[-1,1]$.\n",
    "\n",
    "We are going to estimate $H_L,H_R$ and $\\sigma$ with maximum likelihood.\n",
    "\n",
    "### Logistic regression when the participant did not choose the optout\n",
    "\n",
    "Finally, if the participant did not choose the optout option, then $p_O \\sim 0$ and the multinomial probability distribution tend to be binomial. Thus, if the mean optout elections over all the stim is zero, we fit the psychometric curves with the logistic regression over the points where the participant did not choose the optout option.\n",
    "\n",
    "The x-axis: The 6 presented stimuli ordered as *[l1,l2,l3,r3,r2,r1]*, where 'l' means left, 'r' means right, and the numbers are the corresponding values for difficulty. Right stimuli are positive, while left stimuli are negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal decision boundary in opt-out trials\n",
    "\n",
    "In the deterministic stage, the participant receives $3$ points as reward in every correct trial, $2$ points if she opts out, and $0$ points for incorrect answers. In these trials, the participant has the possibility to opt out when she has not a certain answer. Thus, she would have a more conservative criterion to choose between left or right responses. The rightward decision boundary ($H_R$) is defined as the $\\hat{x}$ where $p(x>0|\\hat{x})=2/3$. That is when the probability of obtaining $3$ points as reward, if the stimulus was rightward, is equal or larger than $2/3$, otherwise, it is more convenient to opt-out and collect $2$ points. Thus, the participant is going to choose when the probability of answering correctly doubles the probability of making a mistake, if the presented stimulus was rightward, then \n",
    "\n",
    "$\\frac{p(x>0|\\hat{x})}{p(x<0|\\hat{x})}=\\\n",
    "\\frac{\\sum_{x>0}p(x|\\hat{x})}{\\sum_{x<0}p(x|\\hat{x})}=\\\n",
    "\\frac{\\sum_{x>0}p(\\hat{x}|x)p(x)}{\\sum_{x<0}p(\\hat{x}|x)p(x)}=2$.$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  $ (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual bias and continous stimuli\n",
    "\n",
    "Assuming that, the bias exposes by the participant in the trials without the optout option is a perceptual bias, then\n",
    "\n",
    "$p(\\hat{x}|x)=\\it{N}(\\hat{x}|x-H,\\sigma^2)=\\it{N}(\\hat{x}+H|x,\\sigma^2)$,\n",
    "\n",
    "where $\\sigma$ is obtained from the resulting fit of the psychometric curves and $x$ corresponds to the presented stimulus.\n",
    "\n",
    "If the participant does not know there are 6 stimulus values, then \n",
    "\n",
    "$p(x)=\\it{N}(\\hat{x}|0,\\epsilon^2)$,\n",
    "\n",
    "where $\\epsilon=std(\\textbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "from IPython.display import HTML, display, Image\n",
    "import tabulate\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "#mpl.rcParams['xtick.major.size'] = 20\n",
    "mpl.rcParams['xtick.major.width'] = 4\n",
    "#mpl.rcParams['xtick.minor.size'] = 10\n",
    "mpl.rcParams['xtick.minor.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 4\n",
    "mpl.rcParams['ytick.minor.width'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "grand_parent_path = os.path.abspath(os.path.join(parent_path, os.pardir))\n",
    "main_path = os.path.abspath(os.path.join(grand_parent_path, os.pardir))\n",
    "\n",
    "path_results = main_path+'/results/dots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumul_norm(x,H,s):\n",
    "    # cdf = (1/(s*sqrt(2*pi)))*int_-inf^x(exp(-((t-H)/s)^2/2)dt)\n",
    "    return norm.cdf((x-H)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_HR4(xhat,xstims,sigma,H,exp_points):\n",
    "    epsilon = np.std(xstims)\n",
    "    e2 = epsilon*epsilon\n",
    "    s2 = sigma*sigma\n",
    "    mu_ = (xhat+H)*e2/(s2+e2)\n",
    "    s_ = np.sqrt(s2*e2/(s2+e2))\n",
    "    ncdf = cumul_norm(0,mu_,s_)\n",
    "    return (1-ncdf)/ncdf-exp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pR4(xhat,xstims,sigma,H):\n",
    "    epsilon = np.std(xstims)\n",
    "    e2 = epsilon*epsilon\n",
    "    s2 = sigma*sigma\n",
    "    mu_ = (xhat+H)*e2/(s2+e2)\n",
    "    s_ = np.sqrt(s2*e2/(s2+e2))\n",
    "    ncdf = cumul_norm(0,mu_,s_)\n",
    "    ctte = scipy.stats.norm(xhat,np.sqrt(e2+s2)).pdf(0)\n",
    "    return ctte*(1-ncdf)\n",
    "\n",
    "def pL4(xhat,xstims,sigma,H):\n",
    "    epsilon = np.std(xstims)\n",
    "    e2 = epsilon*epsilon\n",
    "    s2 = sigma*sigma\n",
    "    mu_ = (xhat+H)*e2/(s2+e2)\n",
    "    s_ = np.sqrt(s2*e2/(s2+e2))\n",
    "    ncdf = cumul_norm(0,mu_,s_)\n",
    "    ctte = scipy.stats.norm(xhat,np.sqrt(e2+s2)).pdf(0)\n",
    "    return ctte*(ncdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fday = [1,2,3,4,5,6,7,8,9,10]\n",
    "fsession = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = np.arange(-0.2,0.2,0.05)\n",
    "for Day in fday:\n",
    "    for Ses in fsession:\n",
    "        sessionid = 2*Day-2+Ses\n",
    "        path = path_results+'day'+str(Day)+'/session'+str(Ses)+'/'\n",
    "        # sort files\n",
    "        NOfit_files = [f for f in os.listdir(path) if f.startswith('NO_fit')]\n",
    "        subj_NOfit = [int(re.search('%s(.*)%s' % ('NO_fit_Sub', '_Day'), f).group(1)) for f in NOfit_files]\n",
    "        sorted_subj_NOfit = sorted(subj_NOfit)\n",
    "        index_subj_NOfit = [subj_NOfit.index(elem) for elem in sorted_subj_NOfit]\n",
    "        sorted_NOfit_files = [NOfit_files[i] for i in index_subj_NOfit]\n",
    "        \n",
    "        theo_pR = np.zeros(len(xhat))\n",
    "        ind = -1\n",
    "        for part in sorted_NOfit_files:\n",
    "            ind += 1\n",
    "            partid = sorted_subj_NOfit[ind]\n",
    "            part_sessid = str(partid)+'_'+str(sessionid)\n",
    "            # psychometric curve NON-optout\n",
    "            f = sorted_NOfit_files[ind]\n",
    "            filename=path+f\n",
    "            with open(filename) as f:\n",
    "                data = json.load(f)\n",
    "            for k, v in data.items():\n",
    "                globals()[k]=v\n",
    "            HRopt_ = scipy.optimize.fsolve(find_HR4,x0=[0.1],args=(signed_st,Sigma,Hno,2))\n",
    "            SO_HRopt_ = scipy.optimize.fsolve(find_HR4,x0=[0.1],args=(signed_st,Sigma,Hno,4))\n",
    "            for h in range(len(xhat)):\n",
    "                theo_pR[h]=pR4(xhat[h],signed_st,Sigma,Hno)/\\\n",
    "                        (pL4(xhat[h],signed_st,Sigma,Hno)+pR4(xhat[h],signed_st,Sigma,Hno))               \n",
    "                \n",
    "            # write the result in file\n",
    "            filename=path+'optimalH_Sub'+str(partid)+'_Day'+str(Day)+'_Sess'+str(Ses)+'.json'\n",
    "            dict_ = {\n",
    "                \"HRopt_\":HRopt_[0],\n",
    "                \"SO_HRopt_\":SO_HRopt_[0],\n",
    "                \"xhat\":list(xhat),\n",
    "                \"theo_pR\":list(theo_pR),\n",
    "                \"partid\": partid,\n",
    "                \"sessionid\":sessionid,\n",
    "                \"part_sessid\":part_sessid                \n",
    "            }\n",
    "            # Serializing json  \n",
    "            json_object = json.dumps(dict_) \n",
    "\n",
    "            # Writing to sample.json \n",
    "            with open(filename, \"w\") as outfile: \n",
    "                outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat = np.arange(-0.2,0.2,0.05)\n",
    "path = path_results+'day'+str(10)+'/session'+str(2)+'/'\n",
    "sessionid = 2*10-2+2\n",
    "# sort files\n",
    "NOfit_files = [f for f in os.listdir(path) if f.startswith('NO_fit')]\n",
    "subj_NOfit = [int(re.search('%s(.*)%s' % ('NO_fit_Sub', '_Day'), f).group(1)) for f in NOfit_files]\n",
    "sorted_subj_NOfit = sorted(subj_NOfit)\n",
    "index_subj_NOfit = [subj_NOfit.index(elem) for elem in sorted_subj_NOfit]\n",
    "sorted_NOfit_files = [NOfit_files[i] for i in index_subj_NOfit]\n",
    "\n",
    "theo_pR = np.zeros(len(xhat))\n",
    "theo_pL = np.zeros(len(xhat))\n",
    "ind = -1\n",
    "for part in sorted_NOfit_files:\n",
    "    ind += 1\n",
    "    partid = sorted_subj_NOfit[ind]\n",
    "    part_sessid = str(partid)+'_'+str(sessionid)\n",
    "    # psychometric curve NON-optout\n",
    "    f = sorted_NOfit_files[ind]\n",
    "    filename=path+f\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for k, v in data.items():\n",
    "        globals()[k]=v\n",
    "    HRopt_ = scipy.optimize.fsolve(find_HR4,x0=[0.1],args=(signed_st,Sigma,Hno))\n",
    "    if part == 'NO_fit_Sub3060_Day10_Sess2.json':\n",
    "        print(part)\n",
    "        for h in range(len(xhat)):\n",
    "            theo_pR[h]=pR4(xhat[h],signed_st,Sigma,Hno)/\\\n",
    "                    (pL4(xhat[h],signed_st,Sigma,Hno)+pR4(xhat[h],signed_st,Sigma,Hno))\n",
    "            theo_pL[h]=pL4(xhat[h],signed_st,Sigma,Hno)/\\\n",
    "                    (pL4(xhat[h],signed_st,Sigma,Hno)+pR4(xhat[h],signed_st,Sigma,Hno))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theo_pL+theo_pR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRopt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xhat,theo_pR)\n",
    "plt.plot(xhat,theo_pL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
